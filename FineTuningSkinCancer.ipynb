{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Fine Tuning Bert using Skin Cancer Data</center>\n",
    "\n",
    "The code in this notebook is adopted from: https://colab.research.google.com/drive/1ywsvwO6thOVOrfagjjfuxEf6xVRxbUNO#scrollTo=IUM0UA1qJaVB\n",
    "\n",
    "Skin cancer data (big and little) can be found in the wiki: https://knowledge.depaul.edu/display/DNLP/Tasks+and+Data\n",
    "\n",
    "For this notebook, TensorFlow 1.15 is required\n",
    "\n",
    "Date: 24 August 2020\n",
    "This is a collaboration between Keith Cochran and Clayton Cohn where Skin Cancer essays can be classified.  This builds on the work from Simon Hughes involving causal reasoning chains. {Doctoral Dissertation: \"Automatic Inference of Causal Reasoning Chains from Student Essays\", 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2391,
     "status": "ok",
     "timestamp": 1587144224293,
     "user": {
      "displayName": "Clayton Cohn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiR5T0VrYZ_A0_satvSE1jZbcVxmApPyylw8Q-uxoo=s64",
      "userId": "10103672487987981310"
     },
     "user_tz": 300
    },
    "id": "pxGVOeMQOAfs",
    "outputId": "ea10eee9-a1aa-4fe0-883e-40075d3ce079"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version 1.5.1\n",
      "Tensorflow version 1.15.0\n",
      "pandas version 1.0.5.\n",
      "numpy version 1.18.5.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import os\n",
    "from pytorch_pretrained_bert.convert_tf_checkpoint_to_pytorch import convert_tf_checkpoint_to_pytorch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from skopt import dump\n",
    "from skopt import gp_minimize\n",
    "from skopt import load\n",
    "from skopt.plots import plot_evaluations\n",
    "from skopt.plots import plot_objective\n",
    "from skopt.space import Categorical\n",
    "from skopt.space import Integer\n",
    "from skopt.space import Real\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.set_cmap(\"viridis\")\n",
    "\n",
    "# If using Google Colab, uncomment this line to make matplotlib inline\n",
    "#% matplotlib inline\n",
    "\n",
    "print(\"Torch version {}\".format(torch.__version__))\n",
    "print(\"Tensorflow version {}\".format(tf.__version__))\n",
    "print('pandas version {}.'.format(pd.__version__))\n",
    "print('numpy version {}.'.format(np.__version__))\n",
    "\n",
    "# Get date and time\n",
    "import datetime\n",
    "import pytz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>To use the GPU, do the following</center>\n",
    "\n",
    "<table><tr><th>Environment</th><th>Instruction</th></tr><tr><td>Colab</td><td>Edit->Notebook Settings->Hardware Accelerator and select GPU</td></tr>\n",
    "    <tr><td>ML PC</td><td>Device is found using the provided libraries</td></tr></table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10509,
     "status": "ok",
     "timestamp": 1587144232544,
     "user": {
      "displayName": "Clayton Cohn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiR5T0VrYZ_A0_satvSE1jZbcVxmApPyylw8Q-uxoo=s64",
      "userId": "10103672487987981310"
     },
     "user_tz": 300
    },
    "id": "HTpUC6-8UKsN",
    "outputId": "0526d979-63af-4726-f2e6-5428dae4951a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n",
      "Cuda Device: GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print('Cuda Device: {}'.format(torch.cuda.get_device_name(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Manual Parameters</center>\n",
    "\n",
    "| Hyper Parameter | Recommended Values         \n",
    "| :- | :-------------\n",
    "|EPOCHS| 2, 3, 4\n",
    "|BATCH_SIZE| 16, 32\n",
    "|MAX_LEN|Length of longest sentence\n",
    "|LEARNING_RATE|2e-5, 3e-5, 5e-5\n",
    "|WARMUP|.1\n",
    "|MODEL_PATH| The path to the model to use (i.e. 'bert-base-uncased')\n",
    "|COST_SENSITIVITY|0 if unused\n",
    "|KFOLD|0 or a value for kfold cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "reOH412ibrsp"
   },
   "outputs": [],
   "source": [
    "# define the various dimensions we want to test the range of to find the optimal set.\n",
    "dimensions = [\n",
    "    Real(low=2e-5, high=5e-5, prior='log-uniform', name='learning_rate'),\n",
    "]\n",
    "\n",
    "# To modify values here, uncomment the value desired and comment the others with the same name.\n",
    "EPOCHS = [2, 3, 4]\n",
    "BATCH_SIZE = [16, 32]\n",
    "MAX_LEN = 128\n",
    "WARMUP = 0.1\n",
    "MODEL_PATH_PREFIX = 'pre-trained_models/'\n",
    "MODEL_PATH = ['bert_base_uncased', \n",
    "              'scibert_scivocab_uncased', \n",
    "              'biobert_v1.1_pubmed']\n",
    "MODEL_NAME = ['BERT', 'SCIBERT', 'BIOBERT']\n",
    "DATA_PATH = \"data\"\n",
    "STATS_PATH = \"stats\"\n",
    "PRETRAINING_MODEL_ID = \"none\"\n",
    "PRETRAINING_MODEL_TYPE = \"none\"\n",
    "COST_SENSITIVITY = 0\n",
    "KFOLD = 0\n",
    "\n",
    "DATA_TYPE =  ['skin', 'coral']\n",
    "NOTES =      ['Skin Cancer', 'Coral Bleaching']\n",
    "STATS_FILE = ['skin_cancer_fine_tuning_stats.csv', 'coral_bleaching_fine_tuning_stats.csv']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16306,
     "status": "ok",
     "timestamp": 1587144238396,
     "user": {
      "displayName": "Clayton Cohn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiR5T0VrYZ_A0_satvSE1jZbcVxmApPyylw8Q-uxoo=s64",
      "userId": "10103672487987981310"
     },
     "user_tz": 300
    },
    "id": "Y8fXOdJIULEO",
    "outputId": "85fdb01a-a3a6-49b0-cdea-a923ba4213eb"
   },
   "source": [
    "Make sure PyTorch is installed - will use with Hugging Face Transformers\n",
    "<br>Hugging Face library currently accepted as most powerful PyTorch interface with BERT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-pretrained-bert in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (0.6.2)\n",
      "Requirement already satisfied: pytorch-nlp in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from pytorch-pretrained-bert) (2.21.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from pytorch-pretrained-bert) (1.18.5)\n",
      "Requirement already satisfied: boto3 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from pytorch-pretrained-bert) (1.14.21)\n",
      "Requirement already satisfied: tqdm in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from pytorch-pretrained-bert) (4.31.1)\n",
      "Requirement already satisfied: torch>=0.4.1 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from pytorch-pretrained-bert) (1.5.1)\n",
      "Requirement already satisfied: regex in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from pytorch-pretrained-bert) (2017.4.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from pytorch-nlp) (1.0.5)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from requests->pytorch-pretrained-bert) (2020.6.20)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.21 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from boto3->pytorch-pretrained-bert) (1.17.21)\n",
      "Requirement already satisfied: future in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.18.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from pandas->pytorch-nlp) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from pandas->pytorch-nlp) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from botocore<1.18.0,>=1.17.21->boto3->pytorch-pretrained-bert) (0.15.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from python-dateutil>=2.6.1->pandas->pytorch-nlp) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "# Install\n",
    "!pip install pytorch-pretrained-bert pytorch-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Zf9TEVWWUow",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "      <th>relation</th>\n",
       "      <th>s_num</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This essay is about skin damage, latitude and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The skin damage is on our bodies that have num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>3.0</td>\n",
       "      <td>There are three main varieties of skin cancer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>4.0</td>\n",
       "      <td>That would be what skin damage is.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>R-1-2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Latitude and direct sunlight would be the cols...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>R-1-2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>The most yearound direct sunlight occurs betwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>7.0</td>\n",
       "      <td>That would be latitude and direct sunlight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Your skin protects you is that it acts as a wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>R-12-3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Your skin does have some denses against solar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>10.0</td>\n",
       "      <td>That would be your skin protects you.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        essay relation  s_num  \\\n",
       "0  EBA1415_TFHC_1_SC_ES-05947        O    1.0   \n",
       "1  EBA1415_TFHC_1_SC_ES-05947        O    2.0   \n",
       "2  EBA1415_TFHC_1_SC_ES-05947        O    3.0   \n",
       "3  EBA1415_TFHC_1_SC_ES-05947        O    4.0   \n",
       "4  EBA1415_TFHC_1_SC_ES-05947    R-1-2    5.0   \n",
       "5  EBA1415_TFHC_1_SC_ES-05947    R-1-2    6.0   \n",
       "6  EBA1415_TFHC_1_SC_ES-05947        O    7.0   \n",
       "7  EBA1415_TFHC_1_SC_ES-05947        O    8.0   \n",
       "8  EBA1415_TFHC_1_SC_ES-05947   R-12-3    9.0   \n",
       "9  EBA1415_TFHC_1_SC_ES-05947        O   10.0   \n",
       "\n",
       "                                            sentence  \n",
       "0  This essay is about skin damage, latitude and ...  \n",
       "1  The skin damage is on our bodies that have num...  \n",
       "2  There are three main varieties of skin cancer ...  \n",
       "3                 That would be what skin damage is.  \n",
       "4  Latitude and direct sunlight would be the cols...  \n",
       "5  The most yearound direct sunlight occurs betwe...  \n",
       "6        That would be latitude and direct sunlight.  \n",
       "7  Your skin protects you is that it acts as a wa...  \n",
       "8  Your skin does have some denses against solar ...  \n",
       "9              That would be your skin protects you.  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_TYPE_TO_USE = DATA_TYPE[0]\n",
    "DATA_NAME = \"\"\n",
    "\n",
    "if DATA_TYPE_TO_USE == \"skin\":\n",
    "    DATA_NAME = \"EBA1415-SkinCancer-big-sentences.tsv\"\n",
    "elif DATA_TYPE_TO_USE == \"coral\":\n",
    "    DATA_NAME = \"EBA1415-CoralBleaching-big-sentences.tsv\"\n",
    "else:\n",
    "    print(\"DATA_TYPE_TO_USE must be set to either 'coral' or 'skin.'\")\n",
    "\n",
    "h = 0 if DATA_TYPE_TO_USE == \"skin\" else None\n",
    "df = pd.read_csv(DATA_PATH + \"/\" + DATA_NAME, delimiter='\\t', header=h, names=['essay', 'relation', 's_num', 'sentence'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Must transform relation labels to binary labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 unique coral bleaching relations\n",
      "26 unique skin cancer relations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "      <th>relation</th>\n",
       "      <th>s_num</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This essay is about skin damage, latitude and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The skin damage is on our bodies that have num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>3.0</td>\n",
       "      <td>There are three main varieties of skin cancer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>4.0</td>\n",
       "      <td>That would be what skin damage is.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>R-1-2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Latitude and direct sunlight would be the cols...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>R-1-2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>The most yearound direct sunlight occurs betwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>7.0</td>\n",
       "      <td>That would be latitude and direct sunlight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Your skin protects you is that it acts as a wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>R-12-3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Your skin does have some denses against solar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>10.0</td>\n",
       "      <td>That would be your skin protects you.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        essay relation  s_num  \\\n",
       "0  EBA1415_TFHC_1_SC_ES-05947        O    1.0   \n",
       "1  EBA1415_TFHC_1_SC_ES-05947        O    2.0   \n",
       "2  EBA1415_TFHC_1_SC_ES-05947        O    3.0   \n",
       "3  EBA1415_TFHC_1_SC_ES-05947        O    4.0   \n",
       "4  EBA1415_TFHC_1_SC_ES-05947    R-1-2    5.0   \n",
       "5  EBA1415_TFHC_1_SC_ES-05947    R-1-2    6.0   \n",
       "6  EBA1415_TFHC_1_SC_ES-05947        O    7.0   \n",
       "7  EBA1415_TFHC_1_SC_ES-05947        O    8.0   \n",
       "8  EBA1415_TFHC_1_SC_ES-05947   R-12-3    9.0   \n",
       "9  EBA1415_TFHC_1_SC_ES-05947        O   10.0   \n",
       "\n",
       "                                            sentence  \n",
       "0  This essay is about skin damage, latitude and ...  \n",
       "1  The skin damage is on our bodies that have num...  \n",
       "2  There are three main varieties of skin cancer ...  \n",
       "3                 That would be what skin damage is.  \n",
       "4  Latitude and direct sunlight would be the cols...  \n",
       "5  The most yearound direct sunlight occurs betwe...  \n",
       "6        That would be latitude and direct sunlight.  \n",
       "7  Your skin protects you is that it acts as a wa...  \n",
       "8  Your skin does have some denses against solar ...  \n",
       "9              That would be your skin protects you.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations_pd = df.relation.copy(deep=True)\n",
    "\n",
    "coral_relations = [\n",
    "                   \"1,2\", \"1,3\", \"1,4\", \"1,5\", \"1,5B\", \"1,14\", \"1,6\", \"1,7\", \"1,50\",\n",
    "                   \"2,3\", \"2,4\", \"2,5\", \"2,5B\", \"2,14\", \"2,6\", \"2,7\", \"2,50\",\n",
    "                   \"3,4\", \"3,5\", \"3,5B\", \"3,14\", \"3,6\", \"3,7\", \"3,50\",\n",
    "                   \"4,5\", \"4,5B\", \"4,14\", \"4,6\", \"4,7\", \"4,50\",\n",
    "                   \"5,5B\", \"5,14\", \"5,6\", \"5,7\", \"5,50\",\n",
    "                   \"5B,14\", \"5B,6\", \"5B,7\", \"5B,50\",\n",
    "                   \"11,12\", \"11,13\", \"11,14\", \"11,6\", \"11,7\", \"11,50\",\n",
    "                   \"12,13\", \"12,14\", \"12,6\", \"12,7\", \"12,50\",\n",
    "                   \"13,14\", \"13,6\", \"13,7\",\"13,50\",\n",
    "                   \"14,6\", \"14,7\", \"14,50\",\n",
    "                   \"6,7\", \"6,50\",\n",
    "                   \"7,50\"\n",
    "                  ]\n",
    "print(\"{} unique coral bleaching relations\".format(len(coral_relations)))\n",
    "\n",
    "skin_relations = [\n",
    "                  \"1,2\", \"1,3\", \"1,4\", \"1,5\", \"1,6\", \"1,50\",\n",
    "                  \"2,3\", \"2,4\", \"2,5\", \"2,6\", \"2,50\",\n",
    "                  \"3,4\", \"3,5\", \"3,6\", \"3,50\",\n",
    "                  \"4,5\", \"4,6\", \"4,50\",\n",
    "                  \"5,6\", \"5,50\",\n",
    "                  \"11,12\", \"11,6\", \"11,50\",\n",
    "                  \"12,6\", \"12,50\",\n",
    "                  \"6,50\"     \n",
    "                 ]\n",
    "\n",
    "print(\"{} unique skin cancer relations\".format(len(skin_relations)))\n",
    "\n",
    "for i, rel in relations_pd.items():\n",
    "    chain = rel.split(\"-\")\n",
    "    if chain[0] != \"O\":\n",
    "        chain = chain[1] + \",\" + chain[2]\n",
    "        \n",
    "        if DATA_TYPE == \"coral\":\n",
    "            if chain in coral_relations:\n",
    "                relations_pd.at[i] = 1\n",
    "                continue\n",
    "\n",
    "        elif DATA_TYPE == \"skin\":\n",
    "            if chain in skin_relations:\n",
    "                relations_pd.at[i] = 1\n",
    "                continue\n",
    "            \n",
    "    relations_pd.at[i] = 0\n",
    "\n",
    "df_binary = df.copy(deep=True)\n",
    "df_binary.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "      <th>relation</th>\n",
       "      <th>s_num</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This essay is about skin damage, latitude and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The skin damage is on our bodies that have num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>There are three main varieties of skin cancer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>That would be what skin damage is.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Latitude and direct sunlight would be the cols...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>The most yearound direct sunlight occurs betwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>That would be latitude and direct sunlight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Your skin protects you is that it acts as a wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Your skin does have some denses against solar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>That would be your skin protects you.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        essay relation  s_num  \\\n",
       "0  EBA1415_TFHC_1_SC_ES-05947        0    1.0   \n",
       "1  EBA1415_TFHC_1_SC_ES-05947        0    2.0   \n",
       "2  EBA1415_TFHC_1_SC_ES-05947        0    3.0   \n",
       "3  EBA1415_TFHC_1_SC_ES-05947        0    4.0   \n",
       "4  EBA1415_TFHC_1_SC_ES-05947        0    5.0   \n",
       "5  EBA1415_TFHC_1_SC_ES-05947        0    6.0   \n",
       "6  EBA1415_TFHC_1_SC_ES-05947        0    7.0   \n",
       "7  EBA1415_TFHC_1_SC_ES-05947        0    8.0   \n",
       "8  EBA1415_TFHC_1_SC_ES-05947        0    9.0   \n",
       "9  EBA1415_TFHC_1_SC_ES-05947        0   10.0   \n",
       "\n",
       "                                            sentence  \n",
       "0  This essay is about skin damage, latitude and ...  \n",
       "1  The skin damage is on our bodies that have num...  \n",
       "2  There are three main varieties of skin cancer ...  \n",
       "3                 That would be what skin damage is.  \n",
       "4  Latitude and direct sunlight would be the cols...  \n",
       "5  The most yearound direct sunlight occurs betwe...  \n",
       "6        That would be latitude and direct sunlight.  \n",
       "7  Your skin protects you is that it acts as a wa...  \n",
       "8  Your skin does have some denses against solar ...  \n",
       "9              That would be your skin protects you.  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_binary.relation = relations_pd\n",
    "df_binary.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we must address the issue that some sentences have multiple relations. This could be a problem if a sentence has one valid relation and one invalid one (the same sentence will be labeled True in one instance and False in another instance). To correct this, we will remove the duplicate instances and define each sentence to be True if it contains *at least one* causal relation.\n",
    "\n",
    "The parse was provided by @TrentonMcKinney on StackOverflow:\n",
    "https://stackoverflow.com/questions/63697275/regex-string-for-different-versions/63697498#63697498"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "      <th>relation</th>\n",
       "      <th>s_num</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>EBA1415_SDMK_6_SC_ES-06292</td>\n",
       "      <td>0</td>\n",
       "      <td>26.1</td>\n",
       "      <td>If you are between the Tropics of Cancer and c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>EBA1415_SDMK_6_SC_ES-06292</td>\n",
       "      <td>0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>If you are between the Tropics of Cancer and c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>EBA1415_KYNS_4_SC_ES-05404</td>\n",
       "      <td>0</td>\n",
       "      <td>70.1</td>\n",
       "      <td>With more consisten sunlight, Out skinwill bur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>EBA1415_KYNS_4_SC_ES-05404</td>\n",
       "      <td>0</td>\n",
       "      <td>70.2</td>\n",
       "      <td>With more consisten sunlight, Out skinwill bur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>EBA1415_TFBM_1_SC_ES-05442</td>\n",
       "      <td>0</td>\n",
       "      <td>79.1</td>\n",
       "      <td>Latitude and direct sunlight also has to do wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>EBA1415_TFBM_1_SC_ES-05442</td>\n",
       "      <td>0</td>\n",
       "      <td>79.2</td>\n",
       "      <td>Latitude and direct sunlight also has to do wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>EBA1415_TWMD_6-7_SC_ES-05001</td>\n",
       "      <td>0</td>\n",
       "      <td>127.1</td>\n",
       "      <td>Some things that may lead to skin cancer would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>EBA1415_TWMD_6-7_SC_ES-05001</td>\n",
       "      <td>0</td>\n",
       "      <td>127.2</td>\n",
       "      <td>Some things that may lead to skin cancer would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EBA1415_TWMD_6-7_SC_ES-05001</td>\n",
       "      <td>0</td>\n",
       "      <td>127.3</td>\n",
       "      <td>Some things that may lead to skin cancer would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>EBA1415_TWMD_6-7_SC_ES-05001</td>\n",
       "      <td>0</td>\n",
       "      <td>129.1</td>\n",
       "      <td>Another way would be by laditude and direct su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>EBA1415_TWMD_6-7_SC_ES-05001</td>\n",
       "      <td>0</td>\n",
       "      <td>129.2</td>\n",
       "      <td>Another way would be by laditude and direct su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>EBA1415_TWMD_6-7_SC_ES-05001</td>\n",
       "      <td>0</td>\n",
       "      <td>130.1</td>\n",
       "      <td>Some location where you might be at Risk is No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>EBA1415_TWMD_6-7_SC_ES-05001</td>\n",
       "      <td>0</td>\n",
       "      <td>130.2</td>\n",
       "      <td>Some location where you might be at Risk is No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>EBA1415_TWMD_6-7_SC_ES-05001</td>\n",
       "      <td>0</td>\n",
       "      <td>132.1</td>\n",
       "      <td>Some thing Else that may lead to it is sunburn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>EBA1415_TWMD_6-7_SC_ES-05001</td>\n",
       "      <td>0</td>\n",
       "      <td>132.2</td>\n",
       "      <td>Some thing Else that may lead to it is sunburn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>EBA1415_SEAL_7_SC_ES-04804</td>\n",
       "      <td>0</td>\n",
       "      <td>136.1</td>\n",
       "      <td>Skin cancer is caused by sunburn, exposure, al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>EBA1415_SEAL_7_SC_ES-04804</td>\n",
       "      <td>0</td>\n",
       "      <td>136.2</td>\n",
       "      <td>Skin cancer is caused by sunburn, exposure, al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>EBA1415_SEAL_7_SC_ES-04804</td>\n",
       "      <td>0</td>\n",
       "      <td>146.1</td>\n",
       "      <td>Solar comes from light, so if you have exposur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>EBA1415_SEAL_7_SC_ES-04804</td>\n",
       "      <td>0</td>\n",
       "      <td>146.2</td>\n",
       "      <td>Solar comes from light, so if you have exposur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>EBA1415_SEAL_7_SC_ES-04804</td>\n",
       "      <td>0</td>\n",
       "      <td>148.1</td>\n",
       "      <td>Things that cause cancer is sunburn, exposure,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>EBA1415_SEAL_7_SC_ES-04804</td>\n",
       "      <td>0</td>\n",
       "      <td>148.2</td>\n",
       "      <td>Things that cause cancer is sunburn, exposure,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>EBA1415_TWJB_5_SC_ES-05071</td>\n",
       "      <td>0</td>\n",
       "      <td>153.1</td>\n",
       "      <td>If you have sunburn, and the sunburned cells a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>EBA1415_TWJB_5_SC_ES-05071</td>\n",
       "      <td>0</td>\n",
       "      <td>153.2</td>\n",
       "      <td>If you have sunburn, and the sunburned cells a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>EBA1415_SEKL_1_SC_ES-04817</td>\n",
       "      <td>0</td>\n",
       "      <td>177.1</td>\n",
       "      <td>This is because the sun's direct rays can harm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>EBA1415_SEKL_1_SC_ES-04817</td>\n",
       "      <td>0</td>\n",
       "      <td>177.2</td>\n",
       "      <td>This is because the sun's direct rays can harm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            essay relation  s_num  \\\n",
       "25     EBA1415_SDMK_6_SC_ES-06292        0   26.1   \n",
       "26     EBA1415_SDMK_6_SC_ES-06292        0   26.2   \n",
       "70     EBA1415_KYNS_4_SC_ES-05404        0   70.1   \n",
       "71     EBA1415_KYNS_4_SC_ES-05404        0   70.2   \n",
       "80     EBA1415_TFBM_1_SC_ES-05442        0   79.1   \n",
       "81     EBA1415_TFBM_1_SC_ES-05442        0   79.2   \n",
       "90   EBA1415_TWMD_6-7_SC_ES-05001        0  127.1   \n",
       "91   EBA1415_TWMD_6-7_SC_ES-05001        0  127.2   \n",
       "92   EBA1415_TWMD_6-7_SC_ES-05001        0  127.3   \n",
       "94   EBA1415_TWMD_6-7_SC_ES-05001        0  129.1   \n",
       "95   EBA1415_TWMD_6-7_SC_ES-05001        0  129.2   \n",
       "96   EBA1415_TWMD_6-7_SC_ES-05001        0  130.1   \n",
       "97   EBA1415_TWMD_6-7_SC_ES-05001        0  130.2   \n",
       "99   EBA1415_TWMD_6-7_SC_ES-05001        0  132.1   \n",
       "100  EBA1415_TWMD_6-7_SC_ES-05001        0  132.2   \n",
       "104    EBA1415_SEAL_7_SC_ES-04804        0  136.1   \n",
       "105    EBA1415_SEAL_7_SC_ES-04804        0  136.2   \n",
       "115    EBA1415_SEAL_7_SC_ES-04804        0  146.1   \n",
       "116    EBA1415_SEAL_7_SC_ES-04804        0  146.2   \n",
       "118    EBA1415_SEAL_7_SC_ES-04804        0  148.1   \n",
       "119    EBA1415_SEAL_7_SC_ES-04804        0  148.2   \n",
       "124    EBA1415_TWJB_5_SC_ES-05071        0  153.1   \n",
       "125    EBA1415_TWJB_5_SC_ES-05071        0  153.2   \n",
       "149    EBA1415_SEKL_1_SC_ES-04817        0  177.1   \n",
       "150    EBA1415_SEKL_1_SC_ES-04817        0  177.2   \n",
       "\n",
       "                                              sentence  \n",
       "25   If you are between the Tropics of Cancer and c...  \n",
       "26   If you are between the Tropics of Cancer and c...  \n",
       "70   With more consisten sunlight, Out skinwill bur...  \n",
       "71   With more consisten sunlight, Out skinwill bur...  \n",
       "80   Latitude and direct sunlight also has to do wi...  \n",
       "81   Latitude and direct sunlight also has to do wi...  \n",
       "90   Some things that may lead to skin cancer would...  \n",
       "91   Some things that may lead to skin cancer would...  \n",
       "92   Some things that may lead to skin cancer would...  \n",
       "94   Another way would be by laditude and direct su...  \n",
       "95   Another way would be by laditude and direct su...  \n",
       "96   Some location where you might be at Risk is No...  \n",
       "97   Some location where you might be at Risk is No...  \n",
       "99   Some thing Else that may lead to it is sunburn...  \n",
       "100  Some thing Else that may lead to it is sunburn...  \n",
       "104  Skin cancer is caused by sunburn, exposure, al...  \n",
       "105  Skin cancer is caused by sunburn, exposure, al...  \n",
       "115  Solar comes from light, so if you have exposur...  \n",
       "116  Solar comes from light, so if you have exposur...  \n",
       "118  Things that cause cancer is sunburn, exposure,...  \n",
       "119  Things that cause cancer is sunburn, exposure,...  \n",
       "124  If you have sunburn, and the sunburned cells a...  \n",
       "125  If you have sunburn, and the sunburned cells a...  \n",
       "149  This is because the sun's direct rays can harm...  \n",
       "150  This is because the sun's direct rays can harm...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_duplicate_sentences = df_binary[df_binary.s_num.astype(str).str.split('.', expand=True)[1] != '0']\n",
    "df_duplicate_sentences.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the duplicates are isolated, they need to be evaluated. If there is at least one relation, one copy of the sentence will be kept as true. If there are no relations, one copy will be kept as false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "      <th>relation</th>\n",
       "      <th>s_num</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This essay is about skin damage, latitude and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The skin damage is on our bodies that have num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>There are three main varieties of skin cancer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>That would be what skin damage is.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Latitude and direct sunlight would be the cols...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>The most yearound direct sunlight occurs betwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>That would be latitude and direct sunlight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Your skin protects you is that it acts as a wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Your skin does have some denses against solar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>That would be your skin protects you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Sunburn can happen when the body directs blood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>There are severe sunburn is called sun poisoning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Sun poisoning can lead to infection and shock.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>In extreme cases, it can never cause death to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>That would be sunburn.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>That would be all about your body and about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>But there are many things that can happen to y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>I do have a question what can skin cance reall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>That is all I will say about Skin's and Sunlig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EBA1415_SDMK_6_SC_ES-06292</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Every person is at some risk of developing ski...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EBA1415_SDMK_6_SC_ES-06292</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>In the U.S. skin cancer is the most common for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>EBA1415_SDMK_6_SC_ES-06292</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>There are three main types of skin cancer: bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>EBA1415_SDMK_6_SC_ES-06292</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Squamous cell carcinomas and basal make up 95%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EBA1415_SDMK_6_SC_ES-06292</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Malignant melanoma occurs in the other 5% but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>EBA1415_SDMK_6_SC_ES-06292</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Where you are located can tell how much of a r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         essay relation  s_num  \\\n",
       "0   EBA1415_TFHC_1_SC_ES-05947        0    1.0   \n",
       "1   EBA1415_TFHC_1_SC_ES-05947        0    2.0   \n",
       "2   EBA1415_TFHC_1_SC_ES-05947        0    3.0   \n",
       "3   EBA1415_TFHC_1_SC_ES-05947        0    4.0   \n",
       "4   EBA1415_TFHC_1_SC_ES-05947        0    5.0   \n",
       "5   EBA1415_TFHC_1_SC_ES-05947        0    6.0   \n",
       "6   EBA1415_TFHC_1_SC_ES-05947        0    7.0   \n",
       "7   EBA1415_TFHC_1_SC_ES-05947        0    8.0   \n",
       "8   EBA1415_TFHC_1_SC_ES-05947        0    9.0   \n",
       "9   EBA1415_TFHC_1_SC_ES-05947        0   10.0   \n",
       "10  EBA1415_TFHC_1_SC_ES-05947        0   11.0   \n",
       "11  EBA1415_TFHC_1_SC_ES-05947        0   12.0   \n",
       "12  EBA1415_TFHC_1_SC_ES-05947        0   13.0   \n",
       "13  EBA1415_TFHC_1_SC_ES-05947        0   14.0   \n",
       "14  EBA1415_TFHC_1_SC_ES-05947        0   15.0   \n",
       "15  EBA1415_TFHC_1_SC_ES-05947        0   16.0   \n",
       "16  EBA1415_TFHC_1_SC_ES-05947        0   17.0   \n",
       "17  EBA1415_TFHC_1_SC_ES-05947        0   18.0   \n",
       "18  EBA1415_TFHC_1_SC_ES-05947        0   19.0   \n",
       "19  EBA1415_SDMK_6_SC_ES-06292        0   20.0   \n",
       "20  EBA1415_SDMK_6_SC_ES-06292        0   21.0   \n",
       "21  EBA1415_SDMK_6_SC_ES-06292        0   22.0   \n",
       "22  EBA1415_SDMK_6_SC_ES-06292        0   23.0   \n",
       "23  EBA1415_SDMK_6_SC_ES-06292        0   24.0   \n",
       "24  EBA1415_SDMK_6_SC_ES-06292        0   25.0   \n",
       "\n",
       "                                             sentence  \n",
       "0   This essay is about skin damage, latitude and ...  \n",
       "1   The skin damage is on our bodies that have num...  \n",
       "2   There are three main varieties of skin cancer ...  \n",
       "3                  That would be what skin damage is.  \n",
       "4   Latitude and direct sunlight would be the cols...  \n",
       "5   The most yearound direct sunlight occurs betwe...  \n",
       "6         That would be latitude and direct sunlight.  \n",
       "7   Your skin protects you is that it acts as a wa...  \n",
       "8   Your skin does have some denses against solar ...  \n",
       "9               That would be your skin protects you.  \n",
       "10  Sunburn can happen when the body directs blood...  \n",
       "11  There are severe sunburn is called sun poisoning.  \n",
       "12     Sun poisoning can lead to infection and shock.  \n",
       "13  In extreme cases, it can never cause death to ...  \n",
       "14                             That would be sunburn.  \n",
       "15  That would be all about your body and about th...  \n",
       "16  But there are many things that can happen to y...  \n",
       "17  I do have a question what can skin cance reall...  \n",
       "18  That is all I will say about Skin's and Sunlig...  \n",
       "19  Every person is at some risk of developing ski...  \n",
       "20  In the U.S. skin cancer is the most common for...  \n",
       "21  There are three main types of skin cancer: bas...  \n",
       "22  Squamous cell carcinomas and basal make up 95%...  \n",
       "23  Malignant melanoma occurs in the other 5% but ...  \n",
       "24  Where you are located can tell how much of a r...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current = -1\n",
    "same_arr_inds = []\n",
    "drop_list = []\n",
    "\n",
    "for i, row in df_duplicate_sentences.iterrows():\n",
    "    s_num = str(df_duplicate_sentences.loc[i].s_num)\n",
    "    first_num, second_num = s_num.split(\".\")\n",
    "\n",
    "    if first_num != current:\n",
    "        current = first_num\n",
    "\n",
    "    if len(same_arr_inds) > 1:\n",
    "        flag = False\n",
    "        for n in same_arr_inds:\n",
    "            if df_duplicate_sentences.loc[n].relation == True:\n",
    "                flag = True\n",
    "                break\n",
    "\n",
    "        left = same_arr_inds[0]\n",
    "        right = same_arr_inds[1:]\n",
    "\n",
    "        if flag == True:\n",
    "            df_duplicate_sentences.loc[left].relation = 1\n",
    "        else:\n",
    "            df_duplicate_sentences.loc[left].relation = 0\n",
    "\n",
    "        drop_list += right   \n",
    "\n",
    "        same_arr_inds = []\n",
    "        same_arr_inds.append(i)\n",
    "\n",
    "df_binary.drop(drop_list, inplace=True)   \n",
    "df_binary.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is prepped and cleaned at this point. Next is implementation. Extract sentences and labels from DataFrame. Must also add special [CLS] and [SEP] tokens for BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize sentences for BERT.\n",
    "For each tokenized input sentence, we need to create:\n",
    "\n",
    "1. input ids:\n",
    "    a sequence of integers identifying each input token to its index number \n",
    "    in the BERT tokenizer vocabulary\n",
    "\n",
    "2. segment mask: (optional) a sequence of 1s and 0s used to identify whether the input is one \n",
    "    sentence or two sentences long. For one sentence inputs, this is simply a sequence of 0s. \n",
    "    For two sentence inputs, there is a 0 for each token of the first sentence, followed by a \n",
    "    1 for each token of the second sentence\n",
    "\n",
    "3. attention mask: (optional) \n",
    "    a sequence of 1s and 0s, with 1s for all input tokens and 0s for all padding tokens \n",
    "\n",
    "4. labels: based on the labels from the data set\n",
    "\n",
    "Additionally, we will get rid of the sentences greater than MAX_LEN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentences(tokenizer, sentences):\n",
    "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "    print (\"First sentence tokenized: \", tokenized_texts[0])\n",
    "    \n",
    "    original_length = len(tokenized_texts)\n",
    "    labels = df_binary.relation.values\n",
    "    labels = [labels[i] for i in range(len(tokenized_texts)) if len(tokenized_texts[i]) <= MAX_LEN]\n",
    "    tokenized_texts = [tokenized_texts[i] for i in range(len(tokenized_texts)) if len(tokenized_texts[i]) <= MAX_LEN]\n",
    "    print(\"Removed {0} sentences greater than {1}\".format(original_length - len(tokenized_texts),MAX_LEN))\n",
    "    \n",
    "    # Convert BERT tokens to corresponding ID numbers in BERT vocabulary. After conversion, pad the sequences.\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "    \n",
    "    # Create attention masks.\n",
    "    attention_masks = []\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i>0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "\n",
    "    return input_ids, labels, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GANGNKH7jbd2"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bqqQCDEWs0oN"
   },
   "outputs": [],
   "source": [
    "def getLastModelNumber(stats_file):\n",
    "    try:\n",
    "        with open(STATS_PATH + \"/\" + stats_file, \"r\") as f:\n",
    "            f_list = list(f)\n",
    "            latest = f_list[-1].split(',')\n",
    "            return int(latest[0])\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_validate_model(epochs, batch_size, notes, data_type, stats_file, sentences, tokenizer):\n",
    "    LEARNING_RATE = 2e-5\n",
    "    \n",
    "    for model_index, model_path in enumerate(MODEL_PATH):\n",
    "        # having issues with BERT, use the others.\n",
    "        if (model_index == 0): \n",
    "            continue\n",
    "            \n",
    "        start_date_raw = datetime.datetime.now(tz = pytz.timezone('US/Central'))\n",
    "        start_date = str(start_date_raw)\n",
    "        date = start_date.split(' ')\n",
    "        time = date[1]\n",
    "        date = date[0]\n",
    "        h, m = [time.split(':')[0], time.split(':')[1]]\n",
    "\n",
    "        DATE_TIME = date + ' ' + h + ':' + m + \" CT\"\n",
    "        #print(DATE_TIME)\n",
    "\n",
    "        input_ids, labels, attention_masks = tokenize_sentences(tokenizer, sentences)\n",
    "\n",
    "        # Split data into train, validation, test.\n",
    "        train_inputs, validation_inputs, train_labels, validation_labels = \\\n",
    "            train_test_split(input_ids, labels, random_state=2018, test_size=0.1)\n",
    "        train_masks, validation_masks, _, _ = \\\n",
    "            train_test_split(attention_masks, input_ids, random_state=2018, test_size=0.1)\n",
    "\n",
    "        # Convert sets into Torch tensors.\n",
    "        train_inputs = torch.tensor(train_inputs)\n",
    "        validation_inputs = torch.tensor(validation_inputs)\n",
    "        train_labels = torch.tensor(train_labels)\n",
    "        validation_labels = torch.tensor(validation_labels)\n",
    "        train_masks = torch.tensor(train_masks)\n",
    "        validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "        # Create an iterator of our data with torch DataLoader. This helps save on memory during training because, \n",
    "        # unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "        train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "        train_sampler = RandomSampler(train_data)\n",
    "        train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "        validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "        validation_sampler = SequentialSampler(validation_data)\n",
    "        validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "        # If the model is not compiled, use PyTorch to create a pytorch_model.bin\n",
    "        path_bert = MODEL_PATH_PREFIX + model_path + '/'\n",
    "        path_bin = path_bert + 'pytorch_model.bin'\n",
    "        if (not os.path.exists(path_bin)):\n",
    "            if (model_index == 0) :\n",
    "                model_ckpt = \"bert_model.ckpt.data-00000-of-00001\"\n",
    "            else:\n",
    "                model_ckpt = \"model.ckpt-1000000\"\n",
    "            convert_tf_checkpoint_to_pytorch(path_bert + model_ckpt, \n",
    "                                             path_bert + \"bert_config.json\", \n",
    "                                             path_bert + \"pytorch_model.bin\")\n",
    "\n",
    "        # This is where the fine-tuning comes in. We must train the model for our specific task.\n",
    "        # We will first modify pre-trained BERT for our specific task, then continue training on our data until the entire model\n",
    "        # is well-suited for our task.\n",
    "        model = BertForSequenceClassification.from_pretrained(MODEL_PATH_PREFIX + model_path, num_labels=len(labels))\n",
    "        model.cuda()\n",
    "\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'gamma', 'beta']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "             'weight_decay_rate': 0.01},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "             'weight_decay_rate': 0.0}\n",
    "        ]\n",
    "        optimizer = BertAdam(optimizer_grouped_parameters, lr=2e-5, warmup=WARMUP)\n",
    "\n",
    "        t = [] \n",
    "        train_loss_set = [] # Store our loss and accuracy for plotting\n",
    "\n",
    "        # trange is a tqdm wrapper around the normal python range\n",
    "        for _ in trange(epochs, desc=\"Epoch\"):\n",
    "            # **************** Training ****************\n",
    "            # Set our model to training mode (as opposed to evaluation mode)\n",
    "            model.train()\n",
    "\n",
    "            # Tracking variables\n",
    "            tr_loss = 0\n",
    "            nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "            # Train the data for one epoch\n",
    "            for step, batch in enumerate(train_dataloader):\n",
    "                # Add batch to GPU\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                # Unpack the inputs from our dataloader\n",
    "                b_input_ids, b_input_mask, b_labels = batch\n",
    "                b_input_ids = torch.tensor(b_input_ids).to(torch.int64) # from https://github.com/huggingface/transformers/issues/2952\n",
    "                # Clear out the gradients (by default they accumulate)\n",
    "                optimizer.zero_grad()\n",
    "                # Forward pass\n",
    "                loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "                train_loss_set.append(loss.item())    \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                # Update parameters and take a step using the computed gradient\n",
    "                optimizer.step()\n",
    "\n",
    "                # Update tracking variables\n",
    "                tr_loss += loss.item()\n",
    "                nb_tr_examples += b_input_ids.size(0)\n",
    "                nb_tr_steps += 1\n",
    "\n",
    "            print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "\n",
    "            # **************** Validation ****************\n",
    "\n",
    "            # Put model in evaluation mode to evaluate loss on the validation set\n",
    "            model.eval()\n",
    "\n",
    "            # Tracking variables \n",
    "            eval_loss, eval_accuracy = 0, 0\n",
    "            nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "            # Evaluate data for one epoch\n",
    "            for batch in validation_dataloader:\n",
    "                # Add batch to GPU\n",
    "                batch = tuple(t.to(device) for t in batch)\n",
    "                # Unpack the inputs from our dataloader\n",
    "                b_input_ids, b_input_mask, b_labels = batch\n",
    "                b_input_ids = torch.tensor(b_input_ids).to(torch.int64) # from https://github.com/huggingface/transformers/issues/2952\n",
    "                # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "                with torch.no_grad():\n",
    "                    # Forward pass, calculate logit predictions\n",
    "                    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "                # Move logits and labels to CPU\n",
    "                logits = logits.detach().cpu().numpy()\n",
    "                label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "                tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "                eval_accuracy += tmp_eval_accuracy\n",
    "                nb_eval_steps += 1\n",
    "\n",
    "            print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "\n",
    "        # Now we will validate on our testing data\n",
    "        if DATA_TYPE_TO_USE == \"skin\":\n",
    "            DATA_NAME = \"EBA1415-SkinCancer-little-sentences.tsv\"\n",
    "        elif DATA_TYPE_TO_USER == \"coral\":\n",
    "            DATA_NAME = \"EBA1415-CoralBleaching-little-sentences.tsv\"\n",
    "        else:\n",
    "            print(\"DATA_TYPE_TO_USER must be set to either 'coral' or 'skin'\")\n",
    "\n",
    "        h = 0 if DATA_TYPE == DATA_TYPE_TO_USE else None\n",
    "        df_test = pd.read_csv(DATA_PATH  + \"/\" + DATA_NAME, delimiter='\\t', header=h, names=['essay', 'relation', 's_num', 'sentence'])\n",
    "\n",
    "        # Create sentence and label lists\n",
    "        sentences_test = df_test.sentence.values\n",
    "\n",
    "        # We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
    "        sentences_test = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences_test]\n",
    "\n",
    "        tokenized_texts_test = [tokenizer.tokenize(sentence) for sentence in sentences_test]\n",
    "\n",
    "        # Get labels\n",
    "        input_ids_test, labels_test, attention_masks_test = tokenize_sentences(tokenizer, sentences_test)\n",
    "\n",
    "        prediction_inputs = torch.tensor(input_ids_test)\n",
    "        prediction_masks = torch.tensor(attention_masks_test)\n",
    "        prediction_labels = torch.tensor(labels_test)\n",
    "        prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "        prediction_sampler = SequentialSampler(prediction_data)\n",
    "        prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
    "\n",
    "        # *************************** Prediction on test set ***************************\n",
    "        # Put model in evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # Tracking variables \n",
    "        predictions_test, true_labels_test = [], []\n",
    "\n",
    "        # Predict \n",
    "        for batch in prediction_dataloader:\n",
    "            # Add batch to GPU\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            # Unpack the inputs from our dataloader\n",
    "            b_input_ids, b_input_mask, b_labels = batch\n",
    "            b_input_ids = torch.tensor(b_input_ids).to(torch.int64) # from https://github.com/huggingface/transformers/issues/2952\n",
    "            # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n",
    "            with torch.no_grad():\n",
    "                # Forward pass, calculate logit predictions\n",
    "                logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits_test = logits.detach().cpu().numpy()\n",
    "            label_ids_test = b_labels.to('cpu').numpy()\n",
    "\n",
    "            # Store predictions and true labels\n",
    "            predictions_test.append(logits_test)\n",
    "            true_labels_test.append(label_ids_test)\n",
    "\n",
    "\n",
    "        # Flatten the predictions and true values\n",
    "        flat_predictions_test = [item for sublist in predictions_test for item in sublist]\n",
    "        flat_predictions_test = np.argmax(flat_predictions_test, axis=1).flatten()\n",
    "        flat_true_labels_test = [item for sublist in true_labels_test for item in sublist]\n",
    "\n",
    "        # Create the file to store the stats of the model if it doesn't already exist\n",
    "        f = None\n",
    "        if not os.path.isfile(STATS_PATH + \"/\" + stats_file):\n",
    "            f = open(STATS_PATH + \"/\" + stats_file, \"w\")\n",
    "            f.write(\"number,datetime,bert_model,hugging_face,max_len,epochs,batch_size,\\\n",
    "                optimizer,learning_rate,warmup,pretraining_model_id,pretraining_model_type,\\\n",
    "                cost_sensitivity,accuracy,macro_prec,macro_recall,macro_f1,macro_support,\\\n",
    "                weighted_prec,weighted_recall,weighted_f1,weighted_support,kfold,notes\\n\")\n",
    "            print(\"skin_cancer_stats.csv NOT found - creating\")\n",
    "            f.close()\n",
    "\n",
    "        y_pred = flat_predictions_test\n",
    "        y = flat_true_labels_test\n",
    "\n",
    "        classification_dict = classification_report(y, y_pred, labels=None, target_names=None, \\\n",
    "                                                    sample_weight=None, digits=2, output_dict=True, zero_division=1)\n",
    "\n",
    "        # Create arrays of precisions, recalls, f1s to recalculate average\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        f1s = []\n",
    "        supports = []\n",
    "\n",
    "        # We must alter the classification dictionary to update the f1_score and recall keys to be 1 instead of 0\n",
    "        # In this example, precision/recall/f1 scores of 0 are ignored\n",
    "\n",
    "        classification_dict_stripped = {}\n",
    "\n",
    "        # First we are going to create an array of all possible labels\n",
    "        label_types = {}\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] not in label_types:\n",
    "                label_types.update({labels[i] : len(label_types)})\n",
    "    \n",
    "        for k,v in classification_dict.items():\n",
    "            if k.isdigit():\n",
    "                if float(v['precision']) != 0.0 and float(v['recall']) != 0.0 and float(v['f1-score']) != 0.0:\n",
    "                    recalls.append(v['recall'])\n",
    "                    f1s.append(v['f1-score'])\n",
    "                    precisions.append(v['precision'])\n",
    "                    supports.append(v['support'])\n",
    "\n",
    "                    # Convert dictionary keys back to our original labels\n",
    "                    original_key = next((key for key in label_types if label_types[key] == int(k)), None)\n",
    "                    classification_dict_stripped.update({ original_key : v })\n",
    "\n",
    "            # Otherwise, we are at the end of the dict and edit the averages to account for the newly replaced 0s\n",
    "            else:\n",
    "                if k == 'macro avg':\n",
    "                    precision = sum(precisions)/len(precisions)\n",
    "                    recall = sum(recalls)/len(recalls)\n",
    "                    f1 = sum(f1s)/len(f1s)\n",
    "\n",
    "                    v['precision'] = precision\n",
    "                    v['recall'] = recall\n",
    "                    v['f1-score'] = f1\n",
    "\n",
    "                if k == 'weighted avg':\n",
    "                    weighted_precisions = [precisions[i]*supports[i] for i in range(len(precisions))]\n",
    "                    weighted_recalls = [recalls[i]*supports[i] for i in range(len(recalls))]\n",
    "                    weighted_f1s = [f1s[i]*supports[i] for i in range(len(f1s))]\n",
    "\n",
    "                    total_supports = sum(supports)\n",
    "\n",
    "                    precision = sum(weighted_precisions)/total_supports\n",
    "                    recall = sum(weighted_recalls)/total_supports\n",
    "                    f1 = sum(weighted_f1s)/total_supports\n",
    "\n",
    "                    v['precision'] = precision\n",
    "                    v['recall'] = recall\n",
    "                    v['f1-score'] = f1\n",
    "                    v['support'] = total_supports\n",
    "\n",
    "                classification_dict_stripped.update({ k : v })\n",
    "\n",
    "        ACCURACY = classification_dict_stripped['accuracy']\n",
    "\n",
    "        macro = classification_dict_stripped[\"macro avg\"]\n",
    "        MACRO_F1 = macro[\"f1-score\"]\n",
    "        MACRO_PREC = macro[\"precision\"]\n",
    "        MACRO_RECALL = macro[\"recall\"]\n",
    "        MACRO_SUPPORT = macro[\"support\"]\n",
    "\n",
    "        weighted = classification_dict_stripped[\"weighted avg\"]\n",
    "        WEIGHTED_F1 = weighted[\"f1-score\"]\n",
    "        WEIGHTED_PREC = weighted[\"precision\"]\n",
    "        WEIGHTED_RECALL = weighted[\"recall\"]\n",
    "        WEIGHTED_SUPPORT = weighted[\"support\"]\n",
    "\n",
    "        # Capture HuggingFace type\n",
    "        hf_arr = str(type(model)).split('.')\n",
    "        HF_TYPE = hf_arr[2]\n",
    "        HF_TYPE = ''.join(filter(str.isalnum, HF_TYPE))\n",
    "        HF_TYPE\n",
    "\n",
    "        # Capture optimizer type\n",
    "        opt_arr = str(type(optimizer)).split('.')\n",
    "        OPTIMIZER_TYPE = opt_arr[2]\n",
    "        OPTIMIZER_TYPE = ''.join(filter(str.isalnum, OPTIMIZER_TYPE))\n",
    "        OPTIMIZER_TYPE\n",
    "\n",
    "        date_raw = datetime.datetime.now(tz = pytz.timezone('US/Central'))\n",
    "        date = str(date_raw)\n",
    "        date = date.split(' ')\n",
    "        time = date[1]\n",
    "        date = date[0]\n",
    "        h, m = [time.split(':')[0], time.split(':')[1]]\n",
    "\n",
    "        DATE_TIME = date + ' ' + h + ':' + m + \" CT\"\n",
    "        print(DATE_TIME)\n",
    "\n",
    "        elapsedTime = date_raw - start_date_raw\n",
    "        minutes, seconds = divmod(elapsedTime.total_seconds(), 60)\n",
    "        print(\"minutes {}: seconds {}\".format(minutes, seconds))\n",
    "\n",
    "        current_file_n_str = str(getLastModelNumber(stats_file) + 1)\n",
    "        NUM = int(current_file_n_str)\n",
    "\n",
    "        # Add line to stats, then save and close\n",
    "        with open(STATS_PATH + \"/\" + stats_file, \"a\") as f:\n",
    "            f.write(\"{0},{1},{2},{3},{4},{5},{6},{7},{8},\\\n",
    "            {9},{10},{11},{12},{13},{14},{15},{16},{17},\\\n",
    "            {18},{19},{20},{21},{22},{23}\\n\".format(NUM,DATE_TIME,model_path,HF_TYPE,MAX_LEN,epochs,batch_size,\n",
    "                                                  OPTIMIZER_TYPE,LEARNING_RATE,WARMUP,PRETRAINING_MODEL_ID,PRETRAINING_MODEL_TYPE,\n",
    "                                                  COST_SENSITIVITY,ACCURACY,MACRO_PREC,MACRO_RECALL,MACRO_F1,MACRO_SUPPORT,\n",
    "                                                  WEIGHTED_PREC,WEIGHTED_RECALL,WEIGHTED_F1,WEIGHTED_SUPPORT,KFOLD,notes))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sentence tokenized:  ['[CLS]', 'this', 'essay', 'is', 'about', 'skin', 'damage', ',', 'latitude', 'and', 'direct', 'sunlight', ',', 'skin', 'cancer', 'and', 'latitude', ',', 'your', 'skin', 'protects', 'you', 'and', 'about', 'sun', '##burn', '##s', '.', '[SEP]']\n",
      "Removed 12 sentences greater than 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n",
      "Epoch:   0%|                                                                                     | 0/2 [00:00<?, ?it/s]C:\\Users\\Keith\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\ipykernel_launcher.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "..\\torch\\csrc\\utils\\python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.09808169248883727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Keith\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\ipykernel_launcher.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|                                      | 1/2 [04:11<04:11, 251.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0002579906134530325\n",
      "Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|| 2/2 [08:24<00:00, 252.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sentence tokenized:  ['[CLS]', 'sentence', '[SEP]']\n",
      "Removed 0 sentences greater than 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Keith\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\ipykernel_launcher.py:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-17 10:19 CT\n",
      "minutes 8.0: seconds 46.43265699999995\n",
      "First sentence tokenized:  ['[CLS]', 'this', 'essay', 'is', 'about', 'skin', 'damage', ',', 'latitude', 'and', 'direct', 'sunlight', ',', 'skin', 'cancer', 'and', 'latitude', ',', 'your', 'skin', 'protects', 'you', 'and', 'about', 'sun', '##burn', '##s', '.', '[SEP]']\n",
      "Removed 12 sentences greater than 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n",
      "Epoch:   0%|                                                                                     | 0/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-2c6b6e53d39e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mtrain_test_validate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNOTES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDATA_TYPE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTATS_FILE\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-03da4d88b68c>\u001b[0m in \u001b[0;36mtrain_test_validate_model\u001b[1;34m(epochs, batch_size, notes, data_type, stats_file, sentences, tokenizer)\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m                 \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_input_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb_input_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m                 \u001b[0mtrain_loss_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                 \u001b[1;31m# Backward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, token_type_ids, attention_mask, labels)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 989\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    990\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[0;32m    731\u001b[0m         encoded_layers = self.encoder(embedding_output,\n\u001b[0;32m    732\u001b[0m                                       \u001b[0mextended_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 733\u001b[1;33m                                       output_all_encoded_layers=output_all_encoded_layers)\n\u001b[0m\u001b[0;32m    734\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoded_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[0mall_encoder_layers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m             \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    407\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                 \u001b[0mall_encoder_layers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m         \u001b[0mintermediate_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\pytorch_pretrained_bert\\modeling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1612\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1614\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1615\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1616\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "sentences = df_binary.sentence.values\n",
    "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Main processing loop\n",
    "for i, data_type in enumerate(DATA_TYPE):\n",
    "    for epochs in EPOCHS:\n",
    "        for batch_size in BATCH_SIZE:\n",
    "            train_test_validate_model(epochs, batch_size, NOTES[i], DATA_TYPE[i], STATS_FILE[i], sentences, tokenizer)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN4zHUSrA3c97XwpVIADdwZ",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Fine-Tuning Skin Cancer",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
