{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/claytoncohn/CoralBleaching_SkinCancer/blob/master/DetectingCausalRelations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CysJq2mMRvr8"
   },
   "outputs": [],
   "source": [
    "DATA_TYPE = \"skin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "erJHJpl3RO4E"
   },
   "source": [
    "This notebook is created by Clayton Cohn for the purposes of detecting the existence of causal chains in the Coral Bleaching and Skin Cancer datasets using BERT.\n",
    "\n",
    "BERT will be fine-tuned for binary classification: 0 indicating the absense of a causal relation and 1 indicating the presence of a causal relation.\n",
    "\n",
    "The code in this notebook is originally adopted from:\n",
    "\n",
    "https://colab.research.google.com/drive/1ywsvwO6thOVOrfagjjfuxEf6xVRxbUNO#scrollTo=IUM0UA1qJaVB\n",
    "\n",
    "I have adapted it for use with the Skin Cancer and Coral Bleaching datasets below:\n",
    "\n",
    "https://knowledge.depaul.edu/display/DNLP/Tasks+and+Data\n",
    "\n",
    "**Make sure to define the DATA_TYPE constant at the top as either \"coral\" or \"skin\" prior to running this notebook.**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-sIkXqo1TP-D"
   },
   "source": [
    "Mount Drive to Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "3_c3XEJBTpRV",
    "outputId": "058af777-dd7d-4bbb-80c5-c9d6e618c2b2"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4hxMggnJU1VX"
   },
   "source": [
    "Import the desired dataset.\n",
    "\n",
    "**Note: the Coral Bleaching data had to be preprocessed to remove extraneous \"did not finish\" notations. Otherwise, Pandas would not be able to properly import it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "zZ0A4ZXpRDuV",
    "outputId": "f22deab4-adb5-4858-eb91-6c97f10a867b"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File drive/My Drive/colab/data/EBA1415-SkinCancer-big-sentences.tsv does not exist: 'drive/My Drive/colab/data/EBA1415-SkinCancer-big-sentences.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-789c1b484bbd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mDATA_TYPE\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"skin\"\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mDATA_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'essay'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'relation'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m's_num'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sentence'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File drive/My Drive/colab/data/EBA1415-SkinCancer-big-sentences.tsv does not exist: 'drive/My Drive/colab/data/EBA1415-SkinCancer-big-sentences.tsv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = \"drive/My Drive/colab/data/\"\n",
    "DATA_NAME = \"\"\n",
    "\n",
    "if DATA_TYPE == \"skin\":\n",
    "  DATA_NAME = \"EBA1415-SkinCancer-big-sentences.tsv\"\n",
    "elif DATA_TYPE == \"coral\":\n",
    "  DATA_NAME = \"EBA1415-CoralBleaching-big-sentences.tsv\"\n",
    "else:\n",
    "  print(\"DATA_TYPE must be set to either 'coral' or 'skin.'\\nThe DATA_TYPE variable is the first line in this notebook.\")\n",
    "\n",
    "h = 0 if DATA_TYPE == \"skin\" else None\n",
    "\n",
    "df = pd.read_csv(DATA_PATH + DATA_NAME, delimiter='\\t', header=h, names=['essay', 'relation', 's_num', 'sentence'])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zHshYuNpgq9o"
   },
   "source": [
    "Must transform relation labels to binary labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "colab_type": "code",
    "id": "JcYIL8FWgzJs",
    "outputId": "109e7cf1-f26b-45aa-a706-5d8c3d8ea9e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 unique coral bleaching relations\n",
      "26 unique skin cancer relations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "      <th>relation</th>\n",
       "      <th>s_num</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This essay is about skin damage, latitude and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The skin damage is on our bodies that have num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>3.0</td>\n",
       "      <td>There are three main varieties of skin cancer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>4.0</td>\n",
       "      <td>That would be what skin damage is.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>R-1-2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Latitude and direct sunlight would be the cols...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>R-1-2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>The most yearound direct sunlight occurs betwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>7.0</td>\n",
       "      <td>That would be latitude and direct sunlight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Your skin protects you is that it acts as a wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>R-12-3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Your skin does have some denses against solar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>10.0</td>\n",
       "      <td>That would be your skin protects you.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        essay  ...                                           sentence\n",
       "0  EBA1415_TFHC_1_SC_ES-05947  ...  This essay is about skin damage, latitude and ...\n",
       "1  EBA1415_TFHC_1_SC_ES-05947  ...  The skin damage is on our bodies that have num...\n",
       "2  EBA1415_TFHC_1_SC_ES-05947  ...  There are three main varieties of skin cancer ...\n",
       "3  EBA1415_TFHC_1_SC_ES-05947  ...                 That would be what skin damage is.\n",
       "4  EBA1415_TFHC_1_SC_ES-05947  ...  Latitude and direct sunlight would be the cols...\n",
       "5  EBA1415_TFHC_1_SC_ES-05947  ...  The most yearound direct sunlight occurs betwe...\n",
       "6  EBA1415_TFHC_1_SC_ES-05947  ...        That would be latitude and direct sunlight.\n",
       "7  EBA1415_TFHC_1_SC_ES-05947  ...  Your skin protects you is that it acts as a wa...\n",
       "8  EBA1415_TFHC_1_SC_ES-05947  ...  Your skin does have some denses against solar ...\n",
       "9  EBA1415_TFHC_1_SC_ES-05947  ...              That would be your skin protects you.\n",
       "\n",
       "[10 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relations_pd = df.relation.copy(deep=True)\n",
    "\n",
    "coral_relations = [\n",
    "                   \"1,2\", \"1,3\", \"1,4\", \"1,5\", \"1,5B\", \"1,14\", \"1,6\", \"1,7\", \"1,50\",\n",
    "                   \"2,3\", \"2,4\", \"2,5\", \"2,5B\", \"2,14\", \"2,6\", \"2,7\", \"2,50\",\n",
    "                   \"3,4\", \"3,5\", \"3,5B\", \"3,14\", \"3,6\", \"3,7\", \"3,50\",\n",
    "                   \"4,5\", \"4,5B\", \"4,14\", \"4,6\", \"4,7\", \"4,50\",\n",
    "                   \"5,5B\", \"5,14\", \"5,6\", \"5,7\", \"5,50\",\n",
    "                   \"5B,14\", \"5B,6\", \"5B,7\", \"5B,50\",\n",
    "                   \"11,12\", \"11,13\", \"11,14\", \"11,6\", \"11,7\", \"11,50\",\n",
    "                   \"12,13\", \"12,14\", \"12,6\", \"12,7\", \"12,50\",\n",
    "                   \"13,14\", \"13,6\", \"13,7\",\"13,50\",\n",
    "                   \"14,6\", \"14,7\", \"14,50\",\n",
    "                   \"6,7\", \"6,50\",\n",
    "                   \"7,50\"\n",
    "                  ]\n",
    "print(\"{} unique coral bleaching relations\".format(len(coral_relations)))\n",
    "\n",
    "skin_relations = [\n",
    "                  \"1,2\", \"1,3\", \"1,4\", \"1,5\", \"1,6\", \"1,50\",\n",
    "                  \"2,3\", \"2,4\", \"2,5\", \"2,6\", \"2,50\",\n",
    "                  \"3,4\", \"3,5\", \"3,6\", \"3,50\",\n",
    "                  \"4,5\", \"4,6\", \"4,50\",\n",
    "                  \"5,6\", \"5,50\",\n",
    "                  \"11,12\", \"11,6\", \"11,50\",\n",
    "                  \"12,6\", \"12,50\",\n",
    "                  \"6,50\"     \n",
    "                 ]\n",
    "\n",
    "print(\"{} unique skin cancer relations\".format(len(skin_relations)))\n",
    "\n",
    "for i, rel in relations_pd.items():\n",
    "  chain = rel.split(\"-\")\n",
    "  if chain[0] != \"O\":\n",
    "\n",
    "    chain = chain[1] + \",\" + chain[2]\n",
    "\n",
    "    if DATA_TYPE == \"coral\":\n",
    "      if chain in coral_relations:\n",
    "        relations_pd.at[i] = 1\n",
    "        continue\n",
    "    \n",
    "    elif DATA_TYPE == \"skin\":\n",
    "      if chain in skin_relations:\n",
    "        relations_pd.at[i] = 1\n",
    "        continue\n",
    "    \n",
    "  relations_pd.at[i] = 0\n",
    "\n",
    "df_binary = df.copy(deep=True)\n",
    "df_binary.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "ME4ZcO_Wt2Ij",
    "outputId": "acbd8ca5-f763-4a54-d689-14be60165c85"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "      <th>relation</th>\n",
       "      <th>s_num</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This essay is about skin damage, latitude and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The skin damage is on our bodies that have num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>There are three main varieties of skin cancer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>That would be what skin damage is.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Latitude and direct sunlight would be the cols...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>The most yearound direct sunlight occurs betwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>That would be latitude and direct sunlight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Your skin protects you is that it acts as a wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Your skin does have some denses against solar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>That would be your skin protects you.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        essay  ...                                           sentence\n",
       "0  EBA1415_TFHC_1_SC_ES-05947  ...  This essay is about skin damage, latitude and ...\n",
       "1  EBA1415_TFHC_1_SC_ES-05947  ...  The skin damage is on our bodies that have num...\n",
       "2  EBA1415_TFHC_1_SC_ES-05947  ...  There are three main varieties of skin cancer ...\n",
       "3  EBA1415_TFHC_1_SC_ES-05947  ...                 That would be what skin damage is.\n",
       "4  EBA1415_TFHC_1_SC_ES-05947  ...  Latitude and direct sunlight would be the cols...\n",
       "5  EBA1415_TFHC_1_SC_ES-05947  ...  The most yearound direct sunlight occurs betwe...\n",
       "6  EBA1415_TFHC_1_SC_ES-05947  ...        That would be latitude and direct sunlight.\n",
       "7  EBA1415_TFHC_1_SC_ES-05947  ...  Your skin protects you is that it acts as a wa...\n",
       "8  EBA1415_TFHC_1_SC_ES-05947  ...  Your skin does have some denses against solar ...\n",
       "9  EBA1415_TFHC_1_SC_ES-05947  ...              That would be your skin protects you.\n",
       "\n",
       "[10 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_binary.relation = relations_pd\n",
    "df_binary.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eukpkXF6vdeT"
   },
   "source": [
    "Next, we must address the issue that some sentences have multiple relations. This could be a problem if a sentence has one valid relation and one invalid one (the same sentence will be labeled True in one instance and False in another instance). To correct this, we will remove the duplicate instances and define each sentence to be True if it contains *at least one* causal relation.\n",
    "\n",
    "The parse was provided by @TrentonMcKinney on StackOverflow:\n",
    "https://stackoverflow.com/questions/63697275/regex-string-for-different-versions/63697498#63697498"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 824
    },
    "colab_type": "code",
    "id": "xTpiRii5wNJs",
    "outputId": "356727b0-318d-4278-b8e9-6aa461614cf1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "      <th>relation</th>\n",
       "      <th>s_num</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>EBA1415_SDMK_6_SC_ES-06292</td>\n",
       "      <td>1</td>\n",
       "      <td>26.1</td>\n",
       "      <td>If you are between the Tropics of Cancer and c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>EBA1415_SDMK_6_SC_ES-06292</td>\n",
       "      <td>1</td>\n",
       "      <td>26.2</td>\n",
       "      <td>If you are between the Tropics of Cancer and c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>EBA1415_KYNS_4_SC_ES-05404</td>\n",
       "      <td>1</td>\n",
       "      <td>70.1</td>\n",
       "      <td>With more consisten sunlight, Out skinwill bur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>EBA1415_KYNS_4_SC_ES-05404</td>\n",
       "      <td>1</td>\n",
       "      <td>70.2</td>\n",
       "      <td>With more consisten sunlight, Out skinwill bur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>EBA1415_TFBM_1_SC_ES-05442</td>\n",
       "      <td>1</td>\n",
       "      <td>79.1</td>\n",
       "      <td>Latitude and direct sunlight also has to do wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>EBA1415_TFBM_1_SC_ES-05442</td>\n",
       "      <td>1</td>\n",
       "      <td>79.2</td>\n",
       "      <td>Latitude and direct sunlight also has to do wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>EBA1415_TWMD_6-7_SC_ES-05001</td>\n",
       "      <td>1</td>\n",
       "      <td>127.1</td>\n",
       "      <td>Some things that may lead to skin cancer would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>EBA1415_TWMD_6-7_SC_ES-05001</td>\n",
       "      <td>1</td>\n",
       "      <td>127.2</td>\n",
       "      <td>Some things that may lead to skin cancer would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>EBA1415_TWMD_6-7_SC_ES-05001</td>\n",
       "      <td>1</td>\n",
       "      <td>127.3</td>\n",
       "      <td>Some things that may lead to skin cancer would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>EBA1415_TWMD_6-7_SC_ES-05001</td>\n",
       "      <td>1</td>\n",
       "      <td>129.1</td>\n",
       "      <td>Another way would be by laditude and direct su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>EBA1415_TWMD_6-7_SC_ES-05001</td>\n",
       "      <td>1</td>\n",
       "      <td>129.2</td>\n",
       "      <td>Another way would be by laditude and direct su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>EBA1415_TWMD_6-7_SC_ES-05001</td>\n",
       "      <td>1</td>\n",
       "      <td>130.1</td>\n",
       "      <td>Some location where you might be at Risk is No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>EBA1415_TWMD_6-7_SC_ES-05001</td>\n",
       "      <td>1</td>\n",
       "      <td>130.2</td>\n",
       "      <td>Some location where you might be at Risk is No...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>EBA1415_TWMD_6-7_SC_ES-05001</td>\n",
       "      <td>1</td>\n",
       "      <td>132.1</td>\n",
       "      <td>Some thing Else that may lead to it is sunburn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>EBA1415_TWMD_6-7_SC_ES-05001</td>\n",
       "      <td>1</td>\n",
       "      <td>132.2</td>\n",
       "      <td>Some thing Else that may lead to it is sunburn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>EBA1415_SEAL_7_SC_ES-04804</td>\n",
       "      <td>1</td>\n",
       "      <td>136.1</td>\n",
       "      <td>Skin cancer is caused by sunburn, exposure, al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>EBA1415_SEAL_7_SC_ES-04804</td>\n",
       "      <td>1</td>\n",
       "      <td>136.2</td>\n",
       "      <td>Skin cancer is caused by sunburn, exposure, al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>EBA1415_SEAL_7_SC_ES-04804</td>\n",
       "      <td>1</td>\n",
       "      <td>146.1</td>\n",
       "      <td>Solar comes from light, so if you have exposur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>EBA1415_SEAL_7_SC_ES-04804</td>\n",
       "      <td>1</td>\n",
       "      <td>146.2</td>\n",
       "      <td>Solar comes from light, so if you have exposur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>EBA1415_SEAL_7_SC_ES-04804</td>\n",
       "      <td>1</td>\n",
       "      <td>148.1</td>\n",
       "      <td>Things that cause cancer is sunburn, exposure,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>EBA1415_SEAL_7_SC_ES-04804</td>\n",
       "      <td>1</td>\n",
       "      <td>148.2</td>\n",
       "      <td>Things that cause cancer is sunburn, exposure,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>EBA1415_TWJB_5_SC_ES-05071</td>\n",
       "      <td>1</td>\n",
       "      <td>153.1</td>\n",
       "      <td>If you have sunburn, and the sunburned cells a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>EBA1415_TWJB_5_SC_ES-05071</td>\n",
       "      <td>1</td>\n",
       "      <td>153.2</td>\n",
       "      <td>If you have sunburn, and the sunburned cells a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>EBA1415_SEKL_1_SC_ES-04817</td>\n",
       "      <td>1</td>\n",
       "      <td>177.1</td>\n",
       "      <td>This is because the sun's direct rays can harm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>EBA1415_SEKL_1_SC_ES-04817</td>\n",
       "      <td>1</td>\n",
       "      <td>177.2</td>\n",
       "      <td>This is because the sun's direct rays can harm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            essay  ...                                           sentence\n",
       "25     EBA1415_SDMK_6_SC_ES-06292  ...  If you are between the Tropics of Cancer and c...\n",
       "26     EBA1415_SDMK_6_SC_ES-06292  ...  If you are between the Tropics of Cancer and c...\n",
       "70     EBA1415_KYNS_4_SC_ES-05404  ...  With more consisten sunlight, Out skinwill bur...\n",
       "71     EBA1415_KYNS_4_SC_ES-05404  ...  With more consisten sunlight, Out skinwill bur...\n",
       "80     EBA1415_TFBM_1_SC_ES-05442  ...  Latitude and direct sunlight also has to do wi...\n",
       "81     EBA1415_TFBM_1_SC_ES-05442  ...  Latitude and direct sunlight also has to do wi...\n",
       "90   EBA1415_TWMD_6-7_SC_ES-05001  ...  Some things that may lead to skin cancer would...\n",
       "91   EBA1415_TWMD_6-7_SC_ES-05001  ...  Some things that may lead to skin cancer would...\n",
       "92   EBA1415_TWMD_6-7_SC_ES-05001  ...  Some things that may lead to skin cancer would...\n",
       "94   EBA1415_TWMD_6-7_SC_ES-05001  ...  Another way would be by laditude and direct su...\n",
       "95   EBA1415_TWMD_6-7_SC_ES-05001  ...  Another way would be by laditude and direct su...\n",
       "96   EBA1415_TWMD_6-7_SC_ES-05001  ...  Some location where you might be at Risk is No...\n",
       "97   EBA1415_TWMD_6-7_SC_ES-05001  ...  Some location where you might be at Risk is No...\n",
       "99   EBA1415_TWMD_6-7_SC_ES-05001  ...  Some thing Else that may lead to it is sunburn...\n",
       "100  EBA1415_TWMD_6-7_SC_ES-05001  ...  Some thing Else that may lead to it is sunburn...\n",
       "104    EBA1415_SEAL_7_SC_ES-04804  ...  Skin cancer is caused by sunburn, exposure, al...\n",
       "105    EBA1415_SEAL_7_SC_ES-04804  ...  Skin cancer is caused by sunburn, exposure, al...\n",
       "115    EBA1415_SEAL_7_SC_ES-04804  ...  Solar comes from light, so if you have exposur...\n",
       "116    EBA1415_SEAL_7_SC_ES-04804  ...  Solar comes from light, so if you have exposur...\n",
       "118    EBA1415_SEAL_7_SC_ES-04804  ...  Things that cause cancer is sunburn, exposure,...\n",
       "119    EBA1415_SEAL_7_SC_ES-04804  ...  Things that cause cancer is sunburn, exposure,...\n",
       "124    EBA1415_TWJB_5_SC_ES-05071  ...  If you have sunburn, and the sunburned cells a...\n",
       "125    EBA1415_TWJB_5_SC_ES-05071  ...  If you have sunburn, and the sunburned cells a...\n",
       "149    EBA1415_SEKL_1_SC_ES-04817  ...  This is because the sun's direct rays can harm...\n",
       "150    EBA1415_SEKL_1_SC_ES-04817  ...  This is because the sun's direct rays can harm...\n",
       "\n",
       "[25 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_duplicate_sentences = df_binary[df_binary.s_num.astype(str).str.split('.', expand=True)[1] != '0']\n",
    "df_duplicate_sentences.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5T1KuyexCk6l"
   },
   "source": [
    "Now that the duplicates are isolated, they need to be evaluated. If there is at least one relation, one copy of the sentence will be kept as true. If there are no relations, one copy will be kept as false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 929
    },
    "colab_type": "code",
    "id": "7EVJKEEGCjy3",
    "outputId": "4d37db09-ee11-46d7-f044-5f53ee08f70d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "      <th>relation</th>\n",
       "      <th>s_num</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This essay is about skin damage, latitude and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The skin damage is on our bodies that have num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>There are three main varieties of skin cancer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>That would be what skin damage is.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Latitude and direct sunlight would be the cols...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>The most yearound direct sunlight occurs betwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>That would be latitude and direct sunlight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Your skin protects you is that it acts as a wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Your skin does have some denses against solar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>That would be your skin protects you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Sunburn can happen when the body directs blood...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>There are severe sunburn is called sun poisoning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Sun poisoning can lead to infection and shock.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>In extreme cases, it can never cause death to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>That would be sunburn.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>That would be all about your body and about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>But there are many things that can happen to y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>I do have a question what can skin cance reall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>That is all I will say about Skin's and Sunlig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EBA1415_SDMK_6_SC_ES-06292</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Every person is at some risk of developing ski...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EBA1415_SDMK_6_SC_ES-06292</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>In the U.S. skin cancer is the most common for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>EBA1415_SDMK_6_SC_ES-06292</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>There are three main types of skin cancer: bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>EBA1415_SDMK_6_SC_ES-06292</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Squamous cell carcinomas and basal make up 95%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EBA1415_SDMK_6_SC_ES-06292</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Malignant melanoma occurs in the other 5% but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>EBA1415_SDMK_6_SC_ES-06292</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Where you are located can tell how much of a r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         essay  ...                                           sentence\n",
       "0   EBA1415_TFHC_1_SC_ES-05947  ...  This essay is about skin damage, latitude and ...\n",
       "1   EBA1415_TFHC_1_SC_ES-05947  ...  The skin damage is on our bodies that have num...\n",
       "2   EBA1415_TFHC_1_SC_ES-05947  ...  There are three main varieties of skin cancer ...\n",
       "3   EBA1415_TFHC_1_SC_ES-05947  ...                 That would be what skin damage is.\n",
       "4   EBA1415_TFHC_1_SC_ES-05947  ...  Latitude and direct sunlight would be the cols...\n",
       "5   EBA1415_TFHC_1_SC_ES-05947  ...  The most yearound direct sunlight occurs betwe...\n",
       "6   EBA1415_TFHC_1_SC_ES-05947  ...        That would be latitude and direct sunlight.\n",
       "7   EBA1415_TFHC_1_SC_ES-05947  ...  Your skin protects you is that it acts as a wa...\n",
       "8   EBA1415_TFHC_1_SC_ES-05947  ...  Your skin does have some denses against solar ...\n",
       "9   EBA1415_TFHC_1_SC_ES-05947  ...              That would be your skin protects you.\n",
       "10  EBA1415_TFHC_1_SC_ES-05947  ...  Sunburn can happen when the body directs blood...\n",
       "11  EBA1415_TFHC_1_SC_ES-05947  ...  There are severe sunburn is called sun poisoning.\n",
       "12  EBA1415_TFHC_1_SC_ES-05947  ...     Sun poisoning can lead to infection and shock.\n",
       "13  EBA1415_TFHC_1_SC_ES-05947  ...  In extreme cases, it can never cause death to ...\n",
       "14  EBA1415_TFHC_1_SC_ES-05947  ...                             That would be sunburn.\n",
       "15  EBA1415_TFHC_1_SC_ES-05947  ...  That would be all about your body and about th...\n",
       "16  EBA1415_TFHC_1_SC_ES-05947  ...  But there are many things that can happen to y...\n",
       "17  EBA1415_TFHC_1_SC_ES-05947  ...  I do have a question what can skin cance reall...\n",
       "18  EBA1415_TFHC_1_SC_ES-05947  ...  That is all I will say about Skin's and Sunlig...\n",
       "19  EBA1415_SDMK_6_SC_ES-06292  ...  Every person is at some risk of developing ski...\n",
       "20  EBA1415_SDMK_6_SC_ES-06292  ...  In the U.S. skin cancer is the most common for...\n",
       "21  EBA1415_SDMK_6_SC_ES-06292  ...  There are three main types of skin cancer: bas...\n",
       "22  EBA1415_SDMK_6_SC_ES-06292  ...  Squamous cell carcinomas and basal make up 95%...\n",
       "23  EBA1415_SDMK_6_SC_ES-06292  ...  Malignant melanoma occurs in the other 5% but ...\n",
       "24  EBA1415_SDMK_6_SC_ES-06292  ...  Where you are located can tell how much of a r...\n",
       "\n",
       "[25 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "current = -1\n",
    "\n",
    "same_arr_inds = []\n",
    "drop_list = []\n",
    "\n",
    "for i, row in df_duplicate_sentences.iterrows():\n",
    "  s_num = str(df_duplicate_sentences.loc[i].s_num)\n",
    "  first_num, second_num = s_num.split(\".\")\n",
    "\n",
    "  if first_num != current:\n",
    "    current = first_num\n",
    "\n",
    "    if len(same_arr_inds) > 1:\n",
    "      flag = False\n",
    "      for n in same_arr_inds:\n",
    "        if df_duplicate_sentences.loc[n].relation == True:\n",
    "          flag = True\n",
    "          break\n",
    "\n",
    "      left = same_arr_inds[0]\n",
    "      right = same_arr_inds[1:]\n",
    "\n",
    "      if flag == True:\n",
    "       df_duplicate_sentences.loc[left].relation = 1\n",
    "      else:\n",
    "       df_duplicate_sentences.loc[left].relation = 0\n",
    "\n",
    "      drop_list += right   \n",
    "\n",
    "    same_arr_inds = []\n",
    "  same_arr_inds.append(i)\n",
    "\n",
    "df_binary.drop(drop_list, inplace=True)   \n",
    "\n",
    "df_binary.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NlaxtpXCJOsD"
   },
   "source": [
    "Data is prepped and cleaned at this point. Next is implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IcLd8RGsKMDp"
   },
   "source": [
    "Make sure PyTorch is installed - will use with Hugging Face Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "id": "5F-hxvOQKEXU",
    "outputId": "1a49601d-be52-4301-bc5b-2ff5820065f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-pretrained-bert\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
      "\r",
      "\u001b[K     |                             | 10kB 25.0MB/s eta 0:00:01\r",
      "\u001b[K     |                          | 20kB 6.4MB/s eta 0:00:01\r",
      "\u001b[K     |                        | 30kB 7.5MB/s eta 0:00:01\r",
      "\u001b[K     |                     | 40kB 8.1MB/s eta 0:00:01\r",
      "\u001b[K     |                  | 51kB 7.2MB/s eta 0:00:01\r",
      "\u001b[K     |                | 61kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |             | 71kB 8.5MB/s eta 0:00:01\r",
      "\u001b[K     |          | 81kB 8.7MB/s eta 0:00:01\r",
      "\u001b[K     |        | 92kB 8.1MB/s eta 0:00:01\r",
      "\u001b[K     |     | 102kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     |  | 112kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     || 122kB 8.4MB/s eta 0:00:01\r",
      "\u001b[K     || 133kB 8.4MB/s \n",
      "\u001b[?25hCollecting pytorch-nlp\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n",
      "\u001b[K     || 92kB 7.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.14.48)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.6.0+cu101)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.5)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.41.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.48 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.17.48)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.16.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->pytorch-pretrained-bert) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.48->boto3->pytorch-pretrained-bert) (0.15.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.18.0,>=1.17.48->boto3->pytorch-pretrained-bert) (1.15.0)\n",
      "Installing collected packages: pytorch-pretrained-bert, pytorch-nlp\n",
      "Successfully installed pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-pretrained-bert pytorch-nlp\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B_1Hz8o0Kfxf"
   },
   "source": [
    "Set up GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "jlm1ouSfB2SF",
    "outputId": "da32b5e7-310f-4ee8-c248-e6152adad9d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "Found GPU at: /device:GPU:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Tesla V100-SXM2-16GB'"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Colab currenly defaults to TensorFlow 1.15, but we need 2.0 or greater\n",
    "\n",
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "URhQvinCK2Ql"
   },
   "source": [
    "Extract sentences and labels from DataFrame. Must also add special [CLS] and [SEP] tokens for BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zpdHxLWxK582"
   },
   "outputs": [],
   "source": [
    "sentences = df_binary.sentence.values\n",
    "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
    "\n",
    "labels = df_binary.relation.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tcOIwLrnNlX_"
   },
   "source": [
    "Tokenize sentences for BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "OExIMOaGNmvn",
    "outputId": "59601645-b27b-4977-cc7f-07fd8d2ac823"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 231508/231508 [00:00<00:00, 901242.54B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sentence tokenized:  ['[CLS]', 'this', 'essay', 'is', 'about', 'skin', 'damage', ',', 'latitude', 'and', 'direct', 'sunlight', ',', 'skin', 'cancer', 'and', 'latitude', ',', 'your', 'skin', 'protects', 'you', 'and', 'about', 'sun', '##burn', '##s', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "print (\"First sentence tokenized: \",tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rnmI0gzNN3Vq"
   },
   "source": [
    "For each tokenized input sentence, we need to create:\n",
    "\n",
    "1. input ids:\n",
    "    a sequence of integers identifying each input token to its index number \n",
    "    in the BERT tokenizer vocabulary\n",
    "\n",
    "2. segment mask: (optional) a sequence of 1s and 0s used to identify whether the input is one \n",
    "    sentence or two sentences long. For one sentence inputs, this is simply a sequence of 0s. \n",
    "    For two sentence inputs, there is a 0 for each token of the first sentence, followed by a \n",
    "    1 for each token of the second sentence\n",
    "\n",
    "3. attention mask: (optional) \n",
    "    a sequence of 1s and 0s, with 1s for all input tokens and 0s for all padding tokens \n",
    "\n",
    "4. labels: based on the labels from the data set\n",
    "\n",
    "Additionally, we will get rid of the sentences greater than MAX_LEN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ugn41x7EN4pR",
    "outputId": "0473a882-f12c-454e-ba6a-11a3755001c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 10 sentences greater than 128\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 128\n",
    "\n",
    "original_length = len(tokenized_texts)\n",
    "\n",
    "labels = [labels[i] for i in range(len(tokenized_texts)) if len(tokenized_texts[i]) <= MAX_LEN]\n",
    "tokenized_texts = [tokenized_texts[i] for i in range(len(tokenized_texts)) if len(tokenized_texts[i]) <= MAX_LEN]\n",
    "print(\"Removed {0} sentences greater than {1}\".format(original_length - len(tokenized_texts),MAX_LEN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EHuInneMOJjZ"
   },
   "source": [
    "Convert BERT tokens to corresponding ID numbers in BERT vocabulary.\n",
    "After conversion, pad the sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GIAxr7uHONoj"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-3kqp7kuPSdu"
   },
   "source": [
    "Create attention masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQoscnkCPG3x"
   },
   "outputs": [],
   "source": [
    "attention_masks = []\n",
    "\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Pb-muSYO1Nv"
   },
   "source": [
    "Split data into train, validation, test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hcbb-2F-O3Da"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=2018, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4joL_R9rPjNE"
   },
   "source": [
    "Convert sets into Torch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nl-2-b_oPlJ7"
   },
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lxaO7WoRPqMq"
   },
   "source": [
    "Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "the entire dataset does not need to be loaded into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hBbQRbq-PxMt"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zyd5a3FmQqSb"
   },
   "source": [
    "Create model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "T9tTfNw-Qpsa",
    "outputId": "470daf38-40dc-412b-8c7d-f681514984d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 407873900/407873900 [00:16<00:00, 24766772.91B/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=8458, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(labels))\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4vGJNoJ9Rfqd"
   },
   "source": [
    "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
    "\n",
    "For the purposes of fine-tuning, the authors recommend the following hyperparameter ranges:\n",
    "\n",
    "*   Batch size: 16, 32\n",
    "*    Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
    "*    Number of epochs: 2, 3, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KgwH7ustRiOI",
    "outputId": "76ad102b-3882-40ba-ba9e-402d90a445ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 2e-5\n",
    "WARMUP = .1\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                     lr=LEARNING_RATE,\n",
    "                     warmup=WARMUP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i5259TkfSK9s"
   },
   "source": [
    "Time for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "HwfUmMUFSMTk",
    "outputId": "9e139aac-6b70-4f8d-d170-7053256cdb64"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  next_m.mul_(beta1).add_(1 - beta1, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.023992325641027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  17%|        | 1/6 [01:18<06:33, 78.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9017857142857143\n",
      "Train loss: 0.21801997622584596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|      | 2/6 [02:37<05:14, 78.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9168320105820106\n",
      "Train loss: 0.15827412727218465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|     | 3/6 [03:55<03:55, 78.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9156746031746031\n",
      "Train loss: 0.10924360563806376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|   | 4/6 [05:13<02:37, 78.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.919973544973545\n",
      "Train loss: 0.0776149426555621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  83%| | 5/6 [06:32<01:18, 78.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9179894179894179\n",
      "Train loss: 0.051761809920406895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|| 6/6 [07:50<00:00, 78.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9052579365079365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "EPOCHS = 6\n",
    "\n",
    "t = [] \n",
    "\n",
    "# Store our loss and accuracy for plotting\n",
    "train_loss_set = []\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for _ in trange(EPOCHS, desc=\"Epoch\"):\n",
    "  \n",
    "  # Training\n",
    "  \n",
    "  # Set our model to training mode (as opposed to evaluation mode)\n",
    "  model.train()\n",
    "  \n",
    "  # Tracking variables\n",
    "  tr_loss = 0\n",
    "  nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  \n",
    "  # Train the data for one epoch\n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # Clear out the gradients (by default they accumulate)\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "    train_loss_set.append(loss.item())    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Update parameters and take a step using the computed gradient\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Update tracking variables\n",
    "    tr_loss += loss.item()\n",
    "    nb_tr_examples += b_input_ids.size(0)\n",
    "    nb_tr_steps += 1\n",
    "\n",
    "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    \n",
    "    \n",
    "  # Validation\n",
    "\n",
    "  # Put model in evaluation mode to evaluate loss on the validation set\n",
    "  model.eval()\n",
    "\n",
    "  # Tracking variables \n",
    "  eval_loss, eval_accuracy = 0, 0\n",
    "  nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "  # Evaluate data for one epoch\n",
    "  for batch in validation_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "    with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "    \n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    \n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNJwo9COC/x3rwJ+aZzBMC9",
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "DetectingCausalRelations.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
