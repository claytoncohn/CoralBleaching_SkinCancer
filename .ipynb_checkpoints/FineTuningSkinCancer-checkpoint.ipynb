{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Fine Tuning Bert using Skin Cancer Data</center>\n",
    "\n",
    "The code in this notebook is adopted from: https://colab.research.google.com/drive/1ywsvwO6thOVOrfagjjfuxEf6xVRxbUNO#scrollTo=IUM0UA1qJaVB\n",
    "\n",
    "Skin cancer data (big and little) can be found in the wiki: https://knowledge.depaul.edu/display/DNLP/Tasks+and+Data\n",
    "\n",
    "For this notebook, TensorFlow 1.15 is required\n",
    "\n",
    "Date: 24 August 2020\n",
    "This is a collaboration between Keith Cochran and Clayton Cohn where Skin Cancer essays can be classified.  This builds on the work from Simon Hughes involving causal reasoning chains. {Doctoral Dissertation: \"Automatic Inference of Causal Reasoning Chains from Student Essays\", 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2391,
     "status": "ok",
     "timestamp": 1587144224293,
     "user": {
      "displayName": "Clayton Cohn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiR5T0VrYZ_A0_satvSE1jZbcVxmApPyylw8Q-uxoo=s64",
      "userId": "10103672487987981310"
     },
     "user_tz": 300
    },
    "id": "pxGVOeMQOAfs",
    "outputId": "ea10eee9-a1aa-4fe0-883e-40075d3ce079"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version 1.5.1\n",
      "Tensorflow version 1.15.0\n",
      "pandas version 1.0.5.\n",
      "numpy version 1.18.5.\n",
      "2020-09-09 23:12 CT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# If using Google Colab, uncomment this line to make matplotlib inline\n",
    "#% matplotlib inline\n",
    "\n",
    "print(\"Torch version {}\".format(torch.__version__))\n",
    "print(\"Tensorflow version {}\".format(tf.__version__))\n",
    "print('pandas version {}.'.format(pd.__version__))\n",
    "print('numpy version {}.'.format(np.__version__))\n",
    "\n",
    "# Get date and time\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "start_date_raw = datetime.datetime.now(tz = pytz.timezone('US/Central'))\n",
    "start_date = str(start_date_raw)\n",
    "date = start_date.split(' ')\n",
    "time = date[1]\n",
    "date = date[0]\n",
    "h, m = [time.split(':')[0], time.split(':')[1]]\n",
    "\n",
    "DATE_TIME = date + ' ' + h + ':' + m + \" CT\"\n",
    "print(DATE_TIME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>To use the GPU, do the following</center>\n",
    "\n",
    "<table><tr><th>Environment</th><th>Instruction</th></tr><tr><td>Colab</td><td>Edit->Notebook Settings->Hardware Accelerator and select GPU</td></tr>\n",
    "    <tr><td>ML PC</td><td>Device is found using the provided libraries</td></tr></table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10509,
     "status": "ok",
     "timestamp": 1587144232544,
     "user": {
      "displayName": "Clayton Cohn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiR5T0VrYZ_A0_satvSE1jZbcVxmApPyylw8Q-uxoo=s64",
      "userId": "10103672487987981310"
     },
     "user_tz": 300
    },
    "id": "HTpUC6-8UKsN",
    "outputId": "0526d979-63af-4726-f2e6-5428dae4951a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n",
      "Cuda Device: GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print('Cuda Device: {}'.format(torch.cuda.get_device_name(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Manual Parameters</center>\n",
    "\n",
    "| Hyper Parameter | Recommended Values         \n",
    "| :- | :-------------\n",
    "|EPOCHS| 2, 3, 4\n",
    "|BATCH_SIZE| 16, 32\n",
    "|MAX_LEN|Length of longest sentence\n",
    "|LEARNING_RATE|2e-5, 3e-5, 5e-5\n",
    "|WARMUP|.1\n",
    "|MODEL_TYPE| The model to use (i.e. 'bert-base-uncased')\n",
    "|BERT_PATH| The path to BERT\n",
    "|COST_SENSITIVITY|0 if unused\n",
    "|KFOLD|0 or a value for kfold cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "reOH412ibrsp"
   },
   "outputs": [],
   "source": [
    "# To modify values here, uncomment the value desired and comment the others with the same name.\n",
    "\n",
    "EPOCHS = 2\n",
    "#EPOCHS = 3\n",
    "#EPOCHS = 4\n",
    "\n",
    "#BATCH_SIZE = 16\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "LEARNING_RATE = 2e-5\n",
    "#LEARNING_RATE = 3e-5\n",
    "#LEARNING_RATE = 5e-5\n",
    "\n",
    "MAX_LEN = 128\n",
    "WARMUP = .1\n",
    "\n",
    "# Model which is the target of fine-tuning\n",
    "#MODEL_TYPE = 'pre-trained_models/bert-base-uncased'\n",
    "#MODEL_TYPE = 'pre-trained_models/scibert_scivocab_uncased'\n",
    "MODEL_TYPE = 'pre-trained_models/biobert_v1.1_pubmed'\n",
    "\n",
    "BERT_PATH = MODEL_TYPE\n",
    "DATA_PATH = \"data\"\n",
    "STATS_PATH = \"stats\"\n",
    "\n",
    "PRETRAINING_MODEL_ID = \"none\"\n",
    "\n",
    "# Type of pretraining\n",
    "PRETRAINING_MODEL_TYPE = \"none\"\n",
    "#PRETRAINING_MODEL_TYPE = \"mlmnsp\"\n",
    "#PRETRAINING_MODEL_TYPE = \"nspmlm\"\n",
    "#PRETRAINING_MODEL_TYPE = \"both\"\n",
    "\n",
    "# Cost sensitivity\n",
    "COST_SENSITIVITY = 0\n",
    "\n",
    "# Set to do cross-validation\n",
    "KFOLD = 0\n",
    "\n",
    "NOTES = \"Initial skin cancer dataset fine-tuning\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16306,
     "status": "ok",
     "timestamp": 1587144238396,
     "user": {
      "displayName": "Clayton Cohn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiR5T0VrYZ_A0_satvSE1jZbcVxmApPyylw8Q-uxoo=s64",
      "userId": "10103672487987981310"
     },
     "user_tz": 300
    },
    "id": "Y8fXOdJIULEO",
    "outputId": "85fdb01a-a3a6-49b0-cdea-a923ba4213eb"
   },
   "source": [
    "Make sure PyTorch is installed - will use with Hugging Face Transformers\n",
    "<br>Hugging Face library currently accepted as most powerful PyTorch interface with BERT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-pretrained-bert in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (0.6.2)\n",
      "Requirement already satisfied: pytorch-nlp in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (0.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from pytorch-pretrained-bert) (2.21.0)\n",
      "Requirement already satisfied: regex in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from pytorch-pretrained-bert) (2017.4.5)\n",
      "Requirement already satisfied: boto3 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from pytorch-pretrained-bert) (1.14.21)\n",
      "Requirement already satisfied: torch>=0.4.1 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from pytorch-pretrained-bert) (1.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from pytorch-pretrained-bert) (1.18.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from pytorch-pretrained-bert) (4.31.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from pytorch-nlp) (1.0.5)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from requests->pytorch-pretrained-bert) (2020.6.20)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.21 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from boto3->pytorch-pretrained-bert) (1.17.21)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
      "Requirement already satisfied: future in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from torch>=0.4.1->pytorch-pretrained-bert) (0.18.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from pandas->pytorch-nlp) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from pandas->pytorch-nlp) (2020.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from botocore<1.18.0,>=1.17.21->boto3->pytorch-pretrained-bert) (0.15.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\keith\\anaconda3\\envs\\pythongpu\\lib\\site-packages (from python-dateutil>=2.6.1->pandas->pytorch-nlp) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "# Install\n",
    "!pip install pytorch-pretrained-bert pytorch-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 79471,
     "status": "ok",
     "timestamp": 1587144301710,
     "user": {
      "displayName": "Clayton Cohn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiR5T0VrYZ_A0_satvSE1jZbcVxmApPyylw8Q-uxoo=s64",
      "userId": "10103672487987981310"
     },
     "user_tz": 300
    },
    "id": "tRZI3iBRWUsP",
    "outputId": "af32e2d9-33aa-49e0-8a92-8ba913cb0f13"
   },
   "outputs": [],
   "source": [
    "# Before importing the data, we must mount Google Drive to Colab notebook.\n",
    "\n",
    "# Each time the notebook is run, Colab must request authorization to remount to Google Drive.\n",
    "# I have not found a way arouund this yet. Even though I am a pro (paying) user, Colab\n",
    "#   will not allow me to let datasets persist after runtime ceases.\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Zf9TEVWWUow",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data from the DeepNLP Wiki \n",
    "DATA_NAME = \"EBA1415-SkinCancer-big-sentences.tsv\"\n",
    "df = pd.read_csv(DATA_PATH + \"/\" + DATA_NAME, delimiter='\\t', header=0, names=['file', 'relation', 's_num', 'sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 81007,
     "status": "ok",
     "timestamp": 1587144303346,
     "user": {
      "displayName": "Clayton Cohn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiR5T0VrYZ_A0_satvSE1jZbcVxmApPyylw8Q-uxoo=s64",
      "userId": "10103672487987981310"
     },
     "user_tz": 300
    },
    "id": "3DE3EqboWUmc",
    "outputId": "9e2d1a3d-e53e-4afa-b56a-45b249fc8c12"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>relation</th>\n",
       "      <th>s_num</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This essay is about skin damage, latitude and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>The skin damage is on our bodies that have num...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>3.0</td>\n",
       "      <td>There are three main varieties of skin cancer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>4.0</td>\n",
       "      <td>That would be what skin damage is.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>R-1-2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Latitude and direct sunlight would be the cols...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>R-1-2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>The most yearound direct sunlight occurs betwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>7.0</td>\n",
       "      <td>That would be latitude and direct sunlight.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Your skin protects you is that it acts as a wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>R-12-3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Your skin does have some denses against solar ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EBA1415_TFHC_1_SC_ES-05947</td>\n",
       "      <td>O</td>\n",
       "      <td>10.0</td>\n",
       "      <td>That would be your skin protects you.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         file relation  s_num  \\\n",
       "0  EBA1415_TFHC_1_SC_ES-05947        O    1.0   \n",
       "1  EBA1415_TFHC_1_SC_ES-05947        O    2.0   \n",
       "2  EBA1415_TFHC_1_SC_ES-05947        O    3.0   \n",
       "3  EBA1415_TFHC_1_SC_ES-05947        O    4.0   \n",
       "4  EBA1415_TFHC_1_SC_ES-05947    R-1-2    5.0   \n",
       "5  EBA1415_TFHC_1_SC_ES-05947    R-1-2    6.0   \n",
       "6  EBA1415_TFHC_1_SC_ES-05947        O    7.0   \n",
       "7  EBA1415_TFHC_1_SC_ES-05947        O    8.0   \n",
       "8  EBA1415_TFHC_1_SC_ES-05947   R-12-3    9.0   \n",
       "9  EBA1415_TFHC_1_SC_ES-05947        O   10.0   \n",
       "\n",
       "                                            sentence  \n",
       "0  This essay is about skin damage, latitude and ...  \n",
       "1  The skin damage is on our bodies that have num...  \n",
       "2  There are three main varieties of skin cancer ...  \n",
       "3                 That would be what skin damage is.  \n",
       "4  Latitude and direct sunlight would be the cols...  \n",
       "5  The most yearound direct sunlight occurs betwe...  \n",
       "6        That would be latitude and direct sunlight.  \n",
       "7  Your skin protects you is that it acts as a wa...  \n",
       "8  Your skin does have some denses against solar ...  \n",
       "9              That would be your skin protects you.  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a peak\n",
    "df.shape\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A8ylllfyWUid"
   },
   "outputs": [],
   "source": [
    "# Create sentence and label lists\n",
    "sentences = df.sentence.values\n",
    "\n",
    "# Add special tokens at the beginning and end of each sentence to comply with BERT\n",
    "sentences = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences]\n",
    "labels = df.relation.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 86299,
     "status": "ok",
     "timestamp": 1587144308722,
     "user": {
      "displayName": "Clayton Cohn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiR5T0VrYZ_A0_satvSE1jZbcVxmApPyylw8Q-uxoo=s64",
      "userId": "10103672487987981310"
     },
     "user_tz": 300
    },
    "id": "9zkVE9ymZFOL",
    "outputId": "3ee271a2-c01d-4179-88da-539f2a73d0cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sentence tokenized:  ['[CLS]', 'this', 'essay', 'is', 'about', 'skin', 'damage', ',', 'latitude', 'and', 'direct', 'sunlight', ',', 'skin', 'cancer', 'and', 'latitude', ',', 'your', 'skin', 'protects', 'you', 'and', 'about', 'sun', '##burn', '##s', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Now that our [CLS] and [SEP] tokens are in place, we are ready for tokenization\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_TYPE, do_lower_case=True)\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "print (\"First sentence tokenized: \",tokenized_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 86264,
     "status": "ok",
     "timestamp": 1587144308723,
     "user": {
      "displayName": "Clayton Cohn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiR5T0VrYZ_A0_satvSE1jZbcVxmApPyylw8Q-uxoo=s64",
      "userId": "10103672487987981310"
     },
     "user_tz": 300
    },
    "id": "6Lf1BD3oZFRR",
    "outputId": "a4035353-1444-4548-9b41-282c62e37dad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 13 sentences greater than 128\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "For each tokenized input sentence, we need to create:\n",
    "\n",
    "1. input ids:\n",
    "    a sequence of integers identifying each input token to its index number \n",
    "    in the BERT tokenizer vocabulary\n",
    "\n",
    "2. segment mask: (optional) a sequence of 1s and 0s used to identify whether the input is one \n",
    "    sentence or two sentences long. For one sentence inputs, this is simply a sequence of 0s. \n",
    "    For two sentence inputs, there is a 0 for each token of the first sentence, followed by a \n",
    "    1 for each token of the second sentence\n",
    "\n",
    "3. attention mask: (optional) \n",
    "    a sequence of 1s and 0s, with 1s for all input tokens and 0s for all padding tokens \n",
    "\n",
    "4. labels: based on the labels from the data set\n",
    "'''\n",
    "\n",
    "# For now, we will simply delete the tokenized_texts greater than MAX_LEN.\n",
    "\n",
    "# We need to strip out the sentences greater than MAX_LEN tokens\n",
    "original_length = len(tokenized_texts)\n",
    "\n",
    "labels = [labels[i] for i in range(len(tokenized_texts)) if len(tokenized_texts[i]) <= MAX_LEN]\n",
    "tokenized_texts = [tokenized_texts[i] for i in range(len(tokenized_texts)) if len(tokenized_texts[i]) <= MAX_LEN]\n",
    "print(\"Removed {0} sentences greater than {1}\".format(original_length - len(tokenized_texts),MAX_LEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qr-MfjBVZFZ3"
   },
   "outputs": [],
   "source": [
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oc2YEZ2gZFXF"
   },
   "outputs": [],
   "source": [
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "--O5pAmKZFUu"
   },
   "outputs": [],
   "source": [
    "# Create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 86444,
     "status": "ok",
     "timestamp": 1587144309193,
     "user": {
      "displayName": "Clayton Cohn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiR5T0VrYZ_A0_satvSE1jZbcVxmApPyylw8Q-uxoo=s64",
      "userId": "10103672487987981310"
     },
     "user_tz": 300
    },
    "id": "XUv2hrecsjkm",
    "outputId": "0cd3aed5-56e7-4618-d550-d40d6d5c8e4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total labels_types: 51\n",
      "Labels: {'O': 0, 'R-1-2': 1, 'R-12-3': 2, 'R-1-50': 3, 'R-2-3': 4, 'R-3-4': 5, 'R-5-6': 6, 'R-2-50': 7, 'R-4-5': 8, 'R-3-50': 9, 'R-2-5': 10, 'R-5-50': 11, 'R-4-50': 12, 'R-6-50': 13, 'R-2-4': 14, 'R-1-5': 15, 'R-11-50': 16, 'R-11-12': 17, 'R-4-4': 18, 'R-5-4': 19, 'R-4-6': 20, 'R-12-2': 21, 'R-3-6': 22, 'R-3-5': 23, 'R-1-3': 24, 'R-6-5': 25, 'R-5-5': 26, 'R-1-4': 27, 'R-12-12': 28, 'R-11-3': 29, 'R-12-5': 30, 'R-11-5': 31, 'R-12-50': 32, 'R-50-2': 33, 'R-2-2': 34, 'R-11-4': 35, 'R-6-4': 36, 'R-50-5': 37, 'R-12-4': 38, 'R-5-11': 39, 'R-50-4': 40, 'R-6-3': 41, 'R-2-6': 42, 'R-4-11': 43, 'R-2-1': 44, 'R-50-3': 45, 'R-5-12': 46, 'R-2-11': 47, 'R-3-11': 48, 'R-3-2': 49, 'R-50-1': 50}\n"
     ]
    }
   ],
   "source": [
    "# At this point we must convert our labels from strings to ints (required for tensorization)\n",
    "\n",
    "# First we are going to create an array of all possible labels\n",
    "label_types = {}\n",
    "for i in range(len(labels)):\n",
    "  if labels[i] not in label_types:\n",
    "    label_types.update({labels[i] : len(label_types)})\n",
    "print(\"Total labels_types: {0}\\nLabels: {1}\".format(len(label_types),str(label_types)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 86409,
     "status": "ok",
     "timestamp": 1587144309194,
     "user": {
      "displayName": "Clayton Cohn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiR5T0VrYZ_A0_satvSE1jZbcVxmApPyylw8Q-uxoo=s64",
      "userId": "10103672487987981310"
     },
     "user_tz": 300
    },
    "id": "-BwKmV_V9l7C",
    "outputId": "aaed07d2-8389-4dcb-8976-6bcce7aa6152"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old labels:  ['O', 'O', 'O', 'O', 'R-1-2', 'R-1-2', 'O', 'O', 'R-12-3', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-1-2', 'R-2-3', 'O', 'R-3-4', 'O', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-2-50', 'R-1-2', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-6', 'R-4-5', 'O', 'O', 'R-1-2', 'R-1-2', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-50', 'O', 'R-1-2', 'R-2-5', 'R-5-50', 'O', 'R-2-3', 'O', 'R-3-4', 'O', 'R-5-50', 'O', 'R-3-50', 'R-1-50', 'R-2-50', 'O', 'O', 'O', 'R-1-50', 'O', 'O', 'O', 'R-4-50', 'R-1-50', 'R-2-50', 'O', 'R-1-50', 'R-2-50', 'R-1-50', 'R-5-50', 'O', 'R-5-50', 'R-4-5', 'O', 'O', 'O', 'R-5-50', 'R-3-50', 'O', 'R-5-6', 'R-2-5', 'O', 'R-2-5', 'R-1-2', 'O', 'R-3-4', 'O', 'R-2-3', 'R-2-5', 'O', 'R-3-50', 'R-5-50', 'R-5-50', 'R-5-50', 'O', 'O', 'R-5-6', 'R-6-50', 'R-5-6', 'O', 'R-4-5', 'R-4-5', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'O', 'R-1-2', 'R-2-50', 'R-2-4', 'R-1-2', 'R-5-50', 'R-1-5', 'O', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'R-1-50', 'R-2-50', 'R-1-2', 'R-2-50', 'R-2-3', 'R-11-50', 'R-11-12', 'R-12-3', 'R-11-50', 'R-5-50', 'R-5-6', 'R-4-5', 'R-4-5', 'R-5-6', 'O', 'O', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-4-50', 'R-4-50', 'O', 'O', 'O', 'O', 'R-1-2', 'R-2-3', 'R-3-4', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-2-50', 'R-2-3', 'R-3-50', 'R-3-4', 'R-4-4', 'R-3-4', 'R-5-50', 'R-5-50', 'O', 'R-2-50', 'R-2-50', 'R-2-50', 'R-2-4', 'R-1-50', 'R-3-50', 'O', 'O', 'O', 'O', 'R-5-50', 'O', 'O', 'O', 'R-2-50', 'R-5-50', 'R-1-2', 'R-5-6', 'R-6-50', 'O', 'R-5-50', 'R-5-50', 'R-2-50', 'O', 'R-2-50', 'R-4-5', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'O', 'R-2-50', 'O', 'R-12-3', 'O', 'R-1-2', 'R-2-50', 'O', 'R-2-3', 'R-1-2', 'R-5-50', 'R-5-6', 'R-4-5', 'R-5-6', 'O', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'R-4-5', 'O', 'O', 'R-5-50', 'R-3-50', 'O', 'O', 'O', 'R-6-50', 'O', 'R-5-50', 'R-5-50', 'R-4-5', 'O', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'R-1-50', 'R-3-50', 'R-5-50', 'R-2-3', 'R-1-2', 'R-2-3', 'O', 'R-5-50', 'O', 'O', 'O', 'O', 'R-5-4', 'R-5-6', 'R-5-50', 'R-1-50', 'R-2-50', 'R-5-50', 'R-2-4', 'R-4-6', 'R-6-50', 'R-5-6', 'R-2-50', 'O', 'O', 'R-1-2', 'R-2-50', 'R-2-50', 'O', 'R-2-50', 'R-2-3', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-1-50', 'R-3-4', 'O', 'R-5-50', 'R-6-50', 'O', 'R-5-6', 'R-6-50', 'O', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'R-6-50', 'R-5-6', 'R-5-6', 'O', 'R-5-50', 'O', 'R-2-50', 'R-1-2', 'O', 'O', 'O', 'O', 'R-3-4', 'R-5-50', 'R-3-50', 'O', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-4-5', 'R-5-6', 'O', 'O', 'R-5-6', 'R-6-50', 'R-4-6', 'R-5-50', 'R-4-5', 'R-5-50', 'O', 'R-3-50', 'R-4-5', 'O', 'O', 'O', 'O', 'R-1-50', 'R-2-4', 'R-4-50', 'O', 'O', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'R-5-50', 'R-5-4', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-12-3', 'O', 'O', 'O', 'R-5-50', 'R-5-50', 'R-4-5', 'R-4-5', 'R-5-50', 'O', 'O', 'R-5-50', 'R-5-4', 'R-5-4', 'R-2-5', 'R-3-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'O', 'R-2-50', 'R-1-2', 'R-1-2', 'R-2-5', 'R-12-2', 'O', 'O', 'R-5-50', 'R-2-5', 'O', 'O', 'O', 'O', 'R-5-50', 'R-5-6', 'O', 'O', 'O', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'O', 'R-4-50', 'R-2-3', 'R-3-4', 'R-3-4', 'R-1-2', 'O', 'O', 'R-2-50', 'R-2-50', 'R-5-6', 'R-6-50', 'R-5-6', 'R-2-5', 'R-6-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-3-50', 'R-3-4', 'O', 'O', 'R-3-50', 'R-5-6', 'R-6-50', 'O', 'R-5-6', 'R-6-50', 'R-6-50', 'O', 'O', 'O', 'R-3-50', 'R-5-50', 'R-3-50', 'R-2-50', 'O', 'R-3-50', 'R-2-50', 'O', 'R-2-3', 'O', 'R-5-6', 'O', 'R-5-4', 'R-3-4', 'R-4-6', 'O', 'O', 'R-3-4', 'R-4-5', 'R-4-50', 'O', 'O', 'R-6-50', 'R-5-6', 'O', 'R-5-50', 'R-4-5', 'R-5-6', 'R-6-50', 'R-5-6', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-3-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-11-12', 'R-12-3', 'R-4-5', 'R-5-6', 'O', 'O', 'O', 'O', 'R-2-50', 'R-3-50', 'O', 'O', 'O', 'R-3-4', 'R-5-50', 'R-5-50', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'R-11-50', 'R-5-50', 'R-1-50', 'R-1-50', 'R-1-50', 'R-11-50', 'R-5-50', 'R-5-50', 'R-11-50', 'R-11-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-1-50', 'R-2-50', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'R-5-6', 'R-5-50', 'R-5-50', 'R-3-50', 'R-3-4', 'O', 'R-1-50', 'R-1-2', 'O', 'O', 'O', 'R-3-50', 'R-2-50', 'R-2-50', 'R-6-50', 'O', 'R-1-2', 'O', 'O', 'O', 'R-1-2', 'R-2-50', 'R-2-3', 'R-12-3', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-4', 'O', 'O', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-5-50', 'R-5-50', 'R-3-5', 'R-4-5', 'O', 'O', 'R-5-6', 'R-6-50', 'O', 'R-5-50', 'R-1-50', 'R-1-2', 'R-1-2', 'O', 'R-2-3', 'R-3-4', 'O', 'R-5-50', 'R-1-50', 'R-2-5', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-50', 'R-1-3', 'R-2-3', 'O', 'R-1-2', 'R-1-3', 'R-1-2', 'R-6-5', 'R-5-50', 'R-6-50', 'R-4-6', 'R-1-2', 'R-1-3', 'R-2-50', 'O', 'R-5-6', 'R-6-50', 'O', 'R-5-50', 'R-2-5', 'R-2-3', 'R-1-2', 'R-1-50', 'O', 'R-1-50', 'R-3-50', 'R-5-50', 'O', 'R-1-50', 'R-3-50', 'R-5-50', 'R-1-50', 'R-3-50', 'R-1-2', 'R-2-3', 'R-3-50', 'R-5-50', 'R-3-50', 'R-2-3', 'R-3-4', 'R-5-50', 'R-5-4', 'R-4-6', 'R-5-6', 'R-5-6', 'R-5-50', 'R-5-6', 'O', 'O', 'O', 'O', 'R-1-2', 'R-1-2', 'R-1-50', 'R-2-50', 'R-2-50', 'O', 'R-2-50', 'R-3-50', 'O', 'O', 'O', 'O', 'R-6-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-3', 'R-1-2', 'R-1-2', 'R-2-3', 'R-3-5', 'R-4-5', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-4-5', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'R-4-5', 'O', 'R-2-50', 'R-1-2', 'R-1-2', 'R-5-6', 'R-6-50', 'R-1-50', 'R-2-50', 'R-5-50', 'R-5-50', 'R-5-50', 'O', 'O', 'R-1-50', 'R-1-3', 'R-1-2', 'R-3-4', 'R-4-6', 'R-5-50', 'O', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'R-1-50', 'R-3-4', 'R-1-3', 'R-2-3', 'R-1-2', 'R-2-50', 'R-3-5', 'R-3-4', 'R-5-6', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-11-12', 'R-12-3', 'R-11-12', 'R-11-12', 'R-12-3', 'O', 'O', 'R-5-6', 'R-4-5', 'R-5-6', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'R-5-6', 'O', 'R-2-50', 'R-2-3', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-2', 'O', 'R-1-2', 'R-1-2', 'R-1-2', 'R-2-50', 'O', 'R-11-12', 'R-11-12', 'R-12-3', 'R-1-50', 'R-1-50', 'O', 'O', 'O', 'O', 'R-12-3', 'O', 'R-3-4', 'O', 'R-2-50', 'R-2-50', 'R-3-50', 'O', 'R-3-4', 'O', 'R-2-50', 'R-5-6', 'R-4-5', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'R-1-2', 'O', 'R-1-2', 'R-1-50', 'R-1-2', 'R-11-12', 'R-12-3', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-50', 'R-1-3', 'O', 'O', 'O', 'O', 'O', 'O', 'R-6-50', 'R-2-50', 'R-1-50', 'R-2-50', 'O', 'O', 'R-2-50', 'R-1-2', 'R-1-2', 'R-2-50', 'O', 'R-1-2', 'R-5-50', 'R-5-6', 'R-6-50', 'O', 'O', 'R-3-50', 'O', 'R-2-50', 'R-1-2', 'O', 'R-5-50', 'R-12-3', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'O', 'R-3-4', 'R-3-6', 'R-5-6', 'R-6-50', 'O', 'R-5-6', 'R-2-50', 'R-4-50', 'O', 'R-4-6', 'R-6-50', 'R-2-50', 'R-2-50', 'R-1-2', 'O', 'R-5-50', 'O', 'O', 'O', 'R-1-2', 'O', 'R-2-50', 'R-2-3', 'R-3-4', 'O', 'R-3-4', 'R-4-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-11-12', 'R-12-3', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'O', 'O', 'O', 'R-1-50', 'R-5-50', 'R-11-12', 'R-12-3', 'R-3-5', 'R-5-6', 'R-5-6', 'R-6-50', 'R-2-4', 'R-4-5', 'R-5-50', 'R-5-5', 'O', 'R-1-50', 'R-1-50', 'R-2-50', 'R-2-3', 'R-3-4', 'R-4-50', 'O', 'R-1-50', 'R-1-2', 'R-1-2', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'O', 'R-4-5', 'R-2-4', 'R-2-4', 'O', 'O', 'O', 'R-5-50', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'R-1-50', 'O', 'R-1-50', 'R-11-50', 'R-1-2', 'R-2-5', 'R-2-5', 'R-5-6', 'R-1-50', 'R-12-3', 'O', 'O', 'R-1-50', 'O', 'O', 'R-11-50', 'R-5-50', 'R-1-50', 'R-3-50', 'R-2-50', 'R-1-50', 'O', 'O', 'O', 'O', 'R-3-50', 'R-3-4', 'O', 'R-5-50', 'R-5-4', 'R-5-4', 'R-5-50', 'O', 'O', 'O', 'R-1-50', 'R-2-50', 'R-2-4', 'O', 'R-3-4', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'O', 'R-5-6', 'R-5-50', 'R-5-50', 'O', 'R-4-5', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'O', 'O', 'R-3-4', 'R-4-5', 'O', 'O', 'O', 'O', 'R-4-5', 'R-5-6', 'R-1-50', 'R-2-50', 'R-1-2', 'R-1-2', 'R-1-2', 'O', 'O', 'O', 'O', 'O', 'R-12-3', 'O', 'R-12-3', 'O', 'O', 'O', 'O', 'O', 'R-3-50', 'R-3-50', 'O', 'R-1-2', 'R-2-3', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-1-4', 'R-2-4', 'R-1-2', 'R-5-50', 'O', 'R-12-3', 'R-11-12', 'R-5-50', 'O', 'R-3-50', 'O', 'R-3-4', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'R-5-50', 'R-3-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-12-3', 'R-11-12', 'R-12-12', 'O', 'O', 'R-4-5', 'R-5-6', 'O', 'O', 'O', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-4-5', 'R-5-6', 'O', 'O', 'R-5-6', 'R-6-50', 'R-1-50', 'R-1-2', 'R-2-50', 'R-1-50', 'R-2-3', 'R-3-4', 'R-6-50', 'R-11-3', 'R-3-5', 'R-3-50', 'O', 'R-2-3', 'R-3-4', 'R-12-3', 'O', 'O', 'R-2-50', 'R-1-50', 'R-5-50', 'R-3-4', 'R-5-50', 'O', 'O', 'R-1-50', 'R-3-50', 'R-2-50', 'R-1-50', 'R-1-2', 'R-1-3', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'O', 'R-1-2', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-5-50', 'R-11-50', 'R-1-50', 'R-11-50', 'R-5-50', 'O', 'R-2-50', 'R-11-12', 'R-2-50', 'R-12-2', 'R-12-3', 'R-12-5', 'O', 'R-1-5', 'O', 'R-1-2', 'R-11-5', 'R-2-5', 'R-5-50', 'R-5-50', 'O', 'R-6-50', 'O', 'R-11-50', 'R-1-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-50', 'R-3-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-2-50', 'R-12-50', 'R-5-50', 'R-5-50', 'R-1-50', 'O', 'O', 'O', 'O', 'R-5-50', 'O', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-1-2', 'R-1-2', 'O', 'O', 'R-2-5', 'R-4-5', 'O', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-4-5', 'O', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'R-11-50', 'R-1-50', 'R-1-50', 'R-1-50', 'R-11-50', 'R-11-12', 'R-12-3', 'R-11-50', 'R-5-50', 'R-5-50', 'R-5-50', 'R-11-50', 'R-1-50', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-4-5', 'R-5-50', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'R-4-5', 'R-5-6', 'R-5-50', 'O', 'O', 'O', 'R-3-50', 'R-5-50', 'R-3-4', 'R-3-4', 'R-4-6', 'R-3-50', 'R-3-4', 'R-5-50', 'R-5-6', 'R-6-50', 'R-6-50', 'O', 'O', 'R-2-3', 'R-1-3', 'R-3-4', 'O', 'R-3-4', 'R-3-6', 'R-2-5', 'R-5-50', 'R-5-6', 'R-4-5', 'R-5-6', 'O', 'R-5-6', 'R-6-50', 'R-5-6', 'R-5-50', 'R-2-50', 'R-3-50', 'R-2-3', 'R-3-4', 'R-2-5', 'O', 'R-6-50', 'R-2-50', 'R-5-50', 'R-5-50', 'R-5-50', 'R-5-50', 'R-1-50', 'R-1-50', 'R-1-50', 'R-3-50', 'R-2-50', 'R-5-50', 'O', 'O', 'O', 'R-3-50', 'R-12-3', 'R-2-3', 'R-11-12', 'R-4-6', 'O', 'O', 'R-1-50', 'R-1-2', 'R-2-3', 'R-2-4', 'R-4-5', 'R-5-6', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'O', 'O', 'R-5-50', 'R-5-6', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'R-1-50', 'R-2-50', 'R-4-50', 'R-1-2', 'R-1-50', 'R-4-5', 'O', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-11-50', 'R-2-50', 'R-1-2', 'R-11-3', 'R-3-50', 'R-1-2', 'R-2-3', 'R-3-4', 'R-4-50', 'R-5-6', 'R-6-50', 'O', 'R-2-50', 'R-3-50', 'O', 'R-1-50', 'R-2-50', 'R-1-2', 'R-1-50', 'R-11-12', 'R-12-50', 'R-11-12', 'R-12-3', 'R-11-50', 'R-5-4', 'R-5-4', 'R-6-50', 'R-5-50', 'R-2-50', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-11-12', 'R-12-3', 'O', 'O', 'R-11-50', 'R-11-12', 'R-12-3', 'R-11-50', 'R-11-50', 'R-5-50', 'R-5-50', 'R-6-50', 'O', 'O', 'R-1-2', 'R-1-2', 'R-1-2', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-5-50', 'R-6-50', 'R-5-6', 'R-1-2', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'R-3-50', 'R-3-50', 'R-1-3', 'R-1-50', 'R-12-3', 'R-3-4', 'O', 'O', 'O', 'R-1-2', 'R-1-2', 'O', 'O', 'R-2-5', 'R-4-5', 'R-4-5', 'O', 'R-5-6', 'R-6-50', 'R-2-50', 'R-50-2', 'R-1-2', 'R-50-2', 'R-2-3', 'R-1-3', 'R-1-2', 'R-2-50', 'R-3-50', 'O', 'O', 'O', 'R-4-5', 'R-3-4', 'R-5-6', 'R-6-50', 'O', 'R-2-3', 'R-1-2', 'R-3-4', 'R-4-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'O', 'R-1-50', 'O', 'O', 'O', 'R-12-3', 'R-11-12', 'R-11-12', 'R-12-3', 'R-5-6', 'R-5-50', 'R-5-6', 'O', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-2-2', 'O', 'O', 'R-3-4', 'R-11-12', 'R-12-3', 'R-4-5', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-6-50', 'O', 'O', 'O', 'O', 'R-1-2', 'R-2-50', 'R-2-50', 'O', 'R-3-4', 'R-11-12', 'R-12-3', 'O', 'R-4-5', 'R-5-6', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-4-5', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-2-3', 'R-3-4', 'R-1-2', 'R-1-50', 'R-2-3', 'O', 'R-11-12', 'R-12-3', 'R-11-50', 'R-11-4', 'R-6-50', 'R-4-50', 'O', 'O', 'O', 'O', 'R-5-50', 'R-5-50', 'R-5-50', 'O', 'O', 'R-2-50', 'O', 'R-5-50', 'R-2-3', 'R-3-4', 'R-3-50', 'R-2-4', 'R-5-50', 'O', 'O', 'O', 'R-2-50', 'R-1-2', 'O', 'R-2-4', 'R-4-5', 'R-5-6', 'R-1-50', 'R-3-50', 'R-1-3', 'R-11-50', 'O', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'R-2-4', 'R-2-50', 'R-5-6', 'R-6-50', 'O', 'R-5-50', 'O', 'R-1-2', 'R-1-2', 'O', 'O', 'R-12-3', 'O', 'O', 'R-5-50', 'R-1-50', 'R-2-5', 'R-5-50', 'R-4-50', 'R-2-4', 'R-5-6', 'R-6-50', 'R-1-50', 'R-3-50', 'R-3-50', 'R-2-3', 'O', 'R-2-50', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-6-50', 'O', 'O', 'O', 'R-2-50', 'R-1-2', 'O', 'O', 'R-12-3', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'R-4-5', 'R-5-50', 'O', 'R-1-50', 'R-1-2', 'R-1-2', 'R-2-3', 'R-5-50', 'R-4-5', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-4-5', 'O', 'O', 'R-3-50', 'R-3-50', 'R-3-50', 'R-12-3', 'R-11-50', 'R-2-50', 'R-1-2', 'R-5-50', 'R-4-50', 'O', 'O', 'O', 'O', 'O', 'R-3-4', 'O', 'R-6-4', 'R-6-50', 'R-6-50', 'O', 'O', 'O', 'O', 'R-1-2', 'O', 'R-5-50', 'O', 'R-5-50', 'O', 'R-1-2', 'R-2-50', 'R-2-5', 'O', 'R-11-12', 'R-12-3', 'O', 'R-5-50', 'R-6-50', 'R-5-6', 'O', 'R-2-50', 'R-1-50', 'R-1-50', 'R-2-50', 'R-5-50', 'O', 'O', 'R-1-2', 'O', 'O', 'R-3-50', 'R-5-50', 'R-1-50', 'R-2-50', 'R-2-50', 'R-1-2', 'O', 'O', 'O', 'R-2-50', 'R-3-4', 'R-5-50', 'R-3-5', 'R-6-50', 'R-2-50', 'R-2-3', 'O', 'R-3-4', 'R-3-6', 'R-6-5', 'R-5-50', 'R-5-50', 'R-5-50', 'R-5-50', 'O', 'R-5-6', 'R-6-50', 'R-5-6', 'O', 'R-2-50', 'R-2-50', 'R-2-50', 'R-3-50', 'R-3-4', 'R-3-50', 'R-11-3', 'O', 'R-5-50', 'R-3-50', 'O', 'R-3-4', 'O', 'O', 'O', 'O', 'O', 'R-5-4', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-12-3', 'O', 'O', 'O', 'O', 'O', 'O', 'R-4-5', 'R-5-6', 'R-2-3', 'R-3-50', 'R-2-3', 'R-5-50', 'R-2-5', 'R-5-50', 'O', 'R-2-3', 'R-2-5', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-2-50', 'O', 'R-11-3', 'R-3-50', 'R-1-2', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'O', 'R-1-2', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-3', 'O', 'O', 'O', 'R-4-5', 'R-4-6', 'O', 'R-4-6', 'R-6-50', 'R-6-50', 'R-5-50', 'R-5-50', 'R-3-50', 'R-5-50', 'R-3-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-11-12', 'R-11-12', 'R-12-3', 'R-11-12', 'R-12-3', 'R-5-50', 'O', 'R-4-5', 'O', 'R-1-50', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-2', 'R-2-5', 'R-4-5', 'O', 'O', 'R-5-6', 'R-6-50', 'R-5-6', 'R-2-50', 'R-2-50', 'R-1-2', 'O', 'O', 'R-2-5', 'R-5-6', 'R-6-50', 'O', 'R-3-6', 'R-5-50', 'R-3-50', 'O', 'R-3-50', 'R-2-3', 'R-2-5', 'O', 'O', 'O', 'O', 'R-5-4', 'R-2-4', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-2-50', 'R-1-2', 'R-1-5', 'R-1-2', 'R-2-3', 'R-3-50', 'R-1-2', 'O', 'R-12-3', 'R-11-12', 'R-12-3', 'R-11-12', 'R-12-3', 'R-5-50', 'R-4-5', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'R-5-50', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'O', 'R-3-50', 'R-2-50', 'R-2-50', 'R-1-50', 'O', 'R-11-12', 'R-11-12', 'R-12-3', 'R-6-50', 'R-4-6', 'R-5-4', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-5-50', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-4-5', 'R-5-6', 'R-6-50', 'O', 'R-12-3', 'O', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-2-50', 'R-4-50', 'O', 'O', 'R-1-2', 'R-2-2', 'O', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'R-5-50', 'O', 'R-2-5', 'R-5-50', 'R-2-5', 'O', 'R-1-50', 'R-1-2', 'R-1-2', 'R-1-50', 'O', 'O', 'R-1-50', 'R-2-50', 'R-2-50', 'R-1-2', 'R-2-50', 'R-2-50', 'R-5-50', 'R-2-50', 'R-1-50', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-2', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-50', 'O', 'R-1-2', 'R-1-2', 'R-1-2', 'R-2-50', 'R-5-50', 'O', 'R-5-4', 'R-4-6', 'R-5-6', 'R-6-50', 'R-5-50', 'R-5-50', 'R-4-5', 'O', 'O', 'R-2-50', 'O', 'R-3-50', 'R-3-4', 'R-2-3', 'R-2-3', 'R-1-3', 'R-1-2', 'R-2-50', 'R-5-50', 'R-5-4', 'R-4-50', 'R-4-50', 'R-4-5', 'R-6-50', 'R-3-50', 'R-2-3', 'O', 'R-3-50', 'R-1-50', 'R-5-50', 'R-3-50', 'R-1-50', 'R-5-50', 'R-1-2', 'R-3-4', 'R-5-6', 'R-6-50', 'R-5-50', 'R-3-50', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'R-4-5', 'R-5-6', 'R-5-4', 'R-3-4', 'R-3-4', 'R-4-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-2-3', 'R-3-50', 'R-3-50', 'O', 'O', 'O', 'R-3-5', 'R-3-5', 'R-2-5', 'O', 'R-2-3', 'R-3-50', 'R-3-5', 'R-11-50', 'O', 'R-11-50', 'R-2-50', 'O', 'O', 'R-1-50', 'R-1-50', 'R-5-50', 'R-1-50', 'R-1-50', 'R-5-50', 'R-5-50', 'R-5-50', 'R-1-50', 'R-5-50', 'R-2-50', 'R-1-2', 'R-2-50', 'R-2-50', 'O', 'R-1-2', 'R-2-3', 'R-3-4', 'R-3-50', 'R-11-12', 'R-12-50', 'R-1-5', 'R-5-50', 'R-5-6', 'R-6-50', 'R-3-50', 'R-1-50', 'O', 'R-2-3', 'R-1-50', 'R-11-12', 'R-12-3', 'R-11-12', 'R-12-3', 'R-5-6', 'R-6-50', 'O', 'R-50-2', 'R-2-4', 'R-3-50', 'R-3-4', 'O', 'O', 'O', 'O', 'R-5-50', 'R-4-5', 'O', 'O', 'R-5-6', 'R-5-50', 'R-5-50', 'R-5-50', 'O', 'O', 'R-1-2', 'R-2-50', 'R-5-50', 'O', 'R-11-12', 'R-12-2', 'O', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-3-50', 'R-3-50', 'R-2-3', 'R-1-2', 'O', 'O', 'O', 'O', 'R-12-3', 'R-11-12', 'R-12-3', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'O', 'O', 'R-12-3', 'O', 'O', 'O', 'R-12-3', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-1-2', 'R-1-2', 'R-2-3', 'R-3-50', 'R-5-50', 'R-5-50', 'R-4-5', 'R-2-4', 'R-6-50', 'R-5-6', 'R-5-50', 'O', 'O', 'R-1-50', 'R-2-50', 'R-5-50', 'O', 'R-1-50', 'R-2-50', 'R-5-50', 'R-1-2', 'O', 'R-1-2', 'R-2-3', 'R-3-50', 'R-5-50', 'O', 'O', 'O', 'R-6-50', 'R-5-50', 'O', 'R-3-4', 'R-2-3', 'R-4-6', 'R-5-6', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'O', 'O', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-1-2', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-1-2', 'R-2-3', 'R-5-50', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'O', 'R-2-50', 'R-5-50', 'O', 'O', 'O', 'O', 'R-2-50', 'R-3-50', 'R-3-4', 'R-4-5', 'R-5-6', 'R-3-50', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-6-50', 'R-6-5', 'R-3-5', 'R-3-4', 'O', 'R-1-50', 'O', 'O', 'O', 'O', 'R-3-50', 'O', 'O', 'R-6-50', 'R-5-50', 'R-4-5', 'R-3-50', 'O', 'O', 'R-5-50', 'O', 'O', 'O', 'O', 'R-1-2', 'O', 'O', 'R-4-5', 'R-2-4', 'R-5-50', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-11-50', 'R-2-50', 'R-1-50', 'R-5-50', 'R-11-50', 'R-2-50', 'R-1-50', 'R-1-50', 'O', 'R-11-50', 'R-5-50', 'R-5-50', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-5', 'R-5-50', 'R-1-3', 'R-1-2', 'R-1-3', 'R-1-2', 'R-2-3', 'O', 'O', 'O', 'O', 'R-11-50', 'R-1-50', 'R-1-50', 'R-1-2', 'R-3-50', 'O', 'R-11-12', 'R-11-12', 'R-12-3', 'R-3-50', 'R-2-3', 'R-3-50', 'R-3-4', 'O', 'R-5-50', 'R-4-6', 'O', 'O', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-12-3', 'R-4-5', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-2-50', 'R-1-50', 'R-2-50', 'R-5-50', 'R-5-6', 'R-5-50', 'O', 'R-2-50', 'O', 'R-2-50', 'R-2-3', 'R-3-4', 'O', 'R-11-12', 'R-12-2', 'R-1-50', 'R-1-2', 'R-2-50', 'O', 'O', 'R-5-50', 'R-3-50', 'R-1-50', 'R-5-6', 'R-6-50', 'O', 'R-5-50', 'R-3-4', 'O', 'R-1-2', 'R-2-50', 'R-2-3', 'R-3-4', 'R-1-50', 'O', 'O', 'R-1-2', 'R-1-2', 'R-2-50', 'R-3-4', 'R-4-50', 'R-4-50', 'R-11-12', 'R-12-3', 'O', 'R-5-6', 'R-6-50', 'R-6-50', 'O', 'O', 'O', 'O', 'R-2-50', 'O', 'R-3-5', 'O', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-1-2', 'R-2-50', 'O', 'O', 'O', 'R-5-50', 'O', 'O', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'R-2-3', 'O', 'O', 'O', 'O', 'R-2-3', 'O', 'R-11-3', 'R-11-3', 'R-11-12', 'R-11-12', 'R-12-3', 'O', 'O', 'R-5-50', 'R-5-50', 'R-5-50', 'R-5-50', 'R-5-50', 'R-1-50', 'R-1-3', 'R-3-4', 'R-1-2', 'R-1-2', 'O', 'O', 'O', 'O', 'O', 'R-4-50', 'R-3-4', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-12-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'R-4-5', 'R-2-4', 'R-2-4', 'R-4-50', 'O', 'R-1-50', 'R-1-2', 'R-2-4', 'R-4-50', 'R-1-2', 'O', 'R-6-50', 'R-5-50', 'O', 'O', 'R-2-50', 'R-2-5', 'R-50-5', 'R-5-4', 'R-1-50', 'R-2-50', 'R-1-50', 'R-2-4', 'R-4-50', 'O', 'O', 'O', 'O', 'R-1-50', 'R-1-2', 'R-2-5', 'R-2-5', 'R-5-4', 'R-5-50', 'R-5-50', 'R-1-50', 'R-6-50', 'R-5-50', 'R-1-50', 'R-5-50', 'R-3-50', 'R-1-50', 'R-5-50', 'R-3-50', 'R-3-50', 'R-1-50', 'R-5-50', 'R-1-50', 'R-1-2', 'R-1-2', 'O', 'O', 'O', 'R-1-50', 'R-3-50', 'R-1-2', 'R-2-5', 'R-5-50', 'R-6-50', 'R-11-50', 'O', 'O', 'O', 'O', 'O', 'R-1-3', 'R-1-2', 'R-2-50', 'R-3-50', 'R-3-50', 'R-2-50', 'O', 'R-3-4', 'R-5-50', 'O', 'O', 'O', 'R-6-50', 'O', 'O', 'R-3-50', 'R-3-50', 'R-2-3', 'R-2-50', 'R-5-6', 'R-3-6', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'R-3-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-3-5', 'R-5-50', 'R-3-4', 'R-2-3', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'O', 'R-1-2', 'O', 'O', 'O', 'O', 'O', 'R-4-5', 'R-5-50', 'R-1-2', 'R-2-3', 'R-3-5', 'R-5-50', 'R-3-5', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-2-50', 'R-2-50', 'R-1-2', 'R-2-4', 'R-5-50', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'R-1-3', 'R-3-4', 'O', 'R-11-50', 'R-5-50', 'R-3-50', 'R-11-50', 'R-2-50', 'R-5-6', 'R-6-50', 'R-5-6', 'R-6-50', 'O', 'O', 'R-11-12', 'R-12-3', 'R-3-50', 'R-2-3', 'O', 'R-11-12', 'R-12-3', 'R-1-2', 'O', 'O', 'R-5-50', 'R-1-50', 'R-1-2', 'R-1-50', 'R-5-6', 'R-4-5', 'R-5-6', 'O', 'O', 'O', 'R-5-50', 'R-5-50', 'O', 'O', 'R-1-50', 'R-1-2', 'O', 'R-1-2', 'R-1-50', 'R-1-2', 'R-2-50', 'R-1-50', 'R-6-50', 'R-5-6', 'R-5-6', 'R-6-50', 'R-4-6', 'R-5-6', 'R-6-50', 'R-6-50', 'O', 'O', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'R-2-50', 'R-1-2', 'R-2-4', 'O', 'O', 'O', 'O', 'R-4-5', 'R-5-6', 'R-2-4', 'O', 'R-5-6', 'R-6-50', 'R-5-6', 'R-5-50', 'R-5-50', 'R-11-12', 'R-12-3', 'O', 'R-11-12', 'R-12-3', 'O', 'O', 'O', 'R-2-50', 'R-5-50', 'O', 'O', 'O', 'R-1-50', 'O', 'O', 'R-1-3', 'O', 'R-3-4', 'O', 'O', 'O', 'O', 'O', 'R-3-50', 'R-2-50', 'R-1-2', 'R-1-50', 'O', 'O', 'O', 'R-1-2', 'R-3-4', 'R-2-3', 'R-3-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-2', 'R-1-2', 'O', 'R-3-50', 'R-2-3', 'R-1-5', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-12-3', 'O', 'O', 'R-11-12', 'R-12-3', 'O', 'O', 'R-1-3', 'R-1-2', 'R-1-3', 'R-4-5', 'O', 'O', 'O', 'R-6-50', 'R-5-50', 'R-5-50', 'O', 'R-3-50', 'R-1-50', 'R-2-50', 'R-5-50', 'R-1-50', 'R-2-50', 'R-5-50', 'R-3-50', 'R-1-50', 'R-2-50', 'R-1-2', 'R-1-2', 'R-2-50', 'R-5-50', 'R-5-50', 'R-5-50', 'R-5-6', 'R-6-50', 'O', 'R-3-50', 'R-2-3', 'R-5-50', 'R-5-6', 'R-4-5', 'R-5-6', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'R-5-50', 'R-3-50', 'R-5-50', 'R-3-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-50', 'R-2-4', 'R-5-50', 'R-5-6', 'R-6-50', 'R-5-4', 'R-2-3', 'R-3-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-50', 'R-2-3', 'R-1-50', 'R-1-2', 'R-1-50', 'R-12-3', 'R-11-12', 'R-12-3', 'O', 'R-11-12', 'R-12-3', 'R-11-12', 'R-12-3', 'R-5-50', 'O', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'R-1-50', 'R-1-2', 'R-2-50', 'R-1-2', 'R-2-50', 'R-3-50', 'O', 'R-3-50', 'R-5-50', 'O', 'O', 'R-5-6', 'R-6-50', 'R-6-50', 'R-5-50', 'R-2-50', 'R-2-50', 'R-5-50', 'O', 'R-1-2', 'O', 'R-2-50', 'O', 'O', 'R-2-5', 'O', 'O', 'O', 'R-2-5', 'O', 'O', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'R-1-2', 'R-2-50', 'O', 'O', 'R-12-3', 'R-3-4', 'O', 'O', 'R-5-50', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'R-5-50', 'R-4-5', 'O', 'O', 'R-5-50', 'O', 'O', 'O', 'O', 'R-1-50', 'O', 'O', 'R-1-50', 'R-2-3', 'R-3-50', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-1-2', 'O', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'R-2-5', 'R-4-5', 'O', 'R-12-3', 'O', 'O', 'O', 'R-2-50', 'R-2-50', 'O', 'R-2-50', 'R-1-50', 'R-5-50', 'R-3-50', 'R-5-50', 'R-4-5', 'O', 'R-6-50', 'R-3-50', 'R-3-50', 'R-12-3', 'R-11-12', 'R-12-3', 'R-11-12', 'R-12-3', 'R-3-50', 'R-1-50', 'R-1-50', 'R-1-2', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-11-12', 'R-12-3', 'R-4-5', 'R-5-6', 'O', 'O', 'R-5-6', 'R-6-50', 'R-1-50', 'R-5-50', 'R-1-50', 'R-1-3', 'R-3-50', 'R-5-50', 'R-5-50', 'R-5-50', 'R-5-50', 'R-5-50', 'R-1-50', 'O', 'O', 'R-2-50', 'R-2-50', 'O', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'R-2-3', 'R-3-4', 'O', 'R-11-12', 'R-12-3', 'R-11-12', 'R-11-12', 'R-12-3', 'R-4-5', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'R-1-50', 'R-1-2', 'R-2-50', 'R-2-50', 'R-3-50', 'R-11-12', 'R-11-12', 'R-12-3', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'R-5-50', 'R-1-50', 'R-2-50', 'R-1-50', 'R-5-50', 'R-2-5', 'R-1-2', 'O', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-2-50', 'R-2-3', 'R-1-2', 'R-2-3', 'R-3-4', 'R-4-6', 'R-12-3', 'O', 'R-11-12', 'R-12-3', 'R-11-50', 'R-2-50', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-5-50', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-2-50', 'O', 'R-1-2', 'R-1-2', 'O', 'R-3-50', 'O', 'O', 'R-2-50', 'O', 'R-3-4', 'O', 'R-6-50', 'R-5-6', 'O', 'O', 'O', 'O', 'R-2-50', 'R-2-4', 'R-4-50', 'O', 'O', 'O', 'R-2-50', 'R-1-2', 'O', 'R-1-5', 'R-5-50', 'R-5-6', 'R-6-50', 'R-2-5', 'O', 'R-1-2', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-12-3', 'R-11-12', 'R-11-12', 'R-12-3', 'R-4-5', 'R-5-6', 'R-5-6', 'R-6-50', 'R-4-5', 'R-4-5', 'O', 'O', 'O', 'O', 'R-4-5', 'O', 'O', 'O', 'R-12-3', 'O', 'O', 'R-2-50', 'R-2-5', 'R-11-5', 'O', 'O', 'O', 'R-2-50', 'R-1-2', 'O', 'O', 'O', 'R-11-12', 'R-12-2', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-5-50', 'R-3-50', 'R-1-2', 'R-3-4', 'R-4-5', 'R-5-6', 'R-5-6', 'R-6-50', 'R-5-50', 'R-5-50', 'R-5-50', 'R-1-50', 'O', 'R-5-50', 'R-4-5', 'O', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-12-3', 'O', 'O', 'O', 'O', 'O', 'R-12-3', 'O', 'R-5-50', 'O', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'O', 'R-5-50', 'O', 'O', 'O', 'R-3-4', 'O', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-1-2', 'R-1-2', 'R-1-50', 'R-1-50', 'R-1-2', 'O', 'O', 'R-4-5', 'R-5-6', 'R-5-50', 'R-5-50', 'R-3-50', 'R-3-50', 'R-2-3', 'R-5-50', 'R-2-5', 'O', 'R-12-3', 'O', 'O', 'R-2-50', 'R-1-2', 'R-2-3', 'O', 'R-1-50', 'R-5-50', 'R-5-50', 'R-1-5', 'R-6-50', 'R-5-6', 'O', 'R-5-50', 'R-2-50', 'O', 'O', 'O', 'R-3-4', 'R-11-12', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-5', 'R-1-2', 'R-2-50', 'R-2-50', 'O', 'R-2-4', 'R-5-50', 'R-6-50', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'O', 'O', 'R-2-50', 'R-2-5', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-5', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-2-5', 'R-1-2', 'O', 'O', 'O', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'R-1-50', 'O', 'R-12-2', 'O', 'O', 'O', 'R-3-50', 'R-5-4', 'R-5-50', 'O', 'R-12-4', 'O', 'O', 'O', 'R-1-50', 'R-2-50', 'O', 'R-3-50', 'O', 'R-11-50', 'R-11-12', 'R-12-3', 'R-1-50', 'R-1-2', 'R-1-2', 'R-2-3', 'R-2-3', 'O', 'R-1-50', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'R-1-50', 'R-3-50', 'R-3-6', 'R-3-6', 'R-6-50', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-11', 'R-5-11', 'R-2-5', 'R-4-5', 'O', 'R-2-5', 'O', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'O', 'R-5-50', 'R-5-50', 'O', 'R-3-50', 'R-4-50', 'O', 'O', 'R-2-50', 'O', 'R-4-5', 'R-5-50', 'O', 'R-3-50', 'R-4-6', 'R-6-50', 'R-5-50', 'R-1-3', 'R-1-2', 'R-3-50', 'R-2-50', 'O', 'R-3-4', 'R-4-6', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-1-50', 'R-1-2', 'O', 'R-1-2', 'R-1-2', 'R-1-50', 'R-1-2', 'O', 'O', 'R-2-5', 'O', 'O', 'O', 'R-3-50', 'R-3-5', 'R-3-5', 'R-5-6', 'R-5-50', 'O', 'O', 'R-1-50', 'O', 'O', 'R-1-50', 'R-1-2', 'R-1-50', 'R-3-50', 'O', 'O', 'R-1-2', 'R-2-50', 'O', 'R-5-50', 'R-2-50', 'O', 'R-5-50', 'R-1-50', 'R-2-50', 'R-2-50', 'R-1-50', 'R-1-50', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-2-3', 'R-3-4', 'O', 'R-4-5', 'O', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'R-3-50', 'R-2-3', 'R-3-50', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'R-11-12', 'R-12-3', 'O', 'R-2-4', 'R-4-5', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'R-2-50', 'R-1-50', 'R-2-50', 'R-1-50', 'O', 'R-2-50', 'O', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-50', 'O', 'R-2-50', 'R-1-50', 'R-5-6', 'R-5-6', 'R-6-50', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-4-5', 'O', 'R-3-50', 'R-2-3', 'O', 'R-3-50', 'O', 'O', 'O', 'O', 'R-3-50', 'R-2-3', 'R-3-50', 'R-1-3', 'R-1-50', 'R-1-2', 'R-1-50', 'R-5-50', 'R-4-5', 'O', 'R-5-50', 'R-3-50', 'R-3-50', 'R-3-4', 'O', 'O', 'R-5-50', 'O', 'R-2-50', 'R-12-2', 'R-1-50', 'R-2-50', 'O', 'R-2-50', 'R-1-2', 'O', 'R-1-2', 'R-1-3', 'R-12-3', 'R-2-5', 'R-5-50', 'R-6-50', 'R-5-50', 'R-3-50', 'R-2-50', 'O', 'O', 'R-4-50', 'O', 'O', 'O', 'R-1-50', 'R-1-50', 'R-1-50', 'R-12-3', 'O', 'R-5-6', 'R-4-5', 'O', 'O', 'O', 'O', 'R-2-5', 'R-5-50', 'R-5-50', 'R-4-5', 'O', 'O', 'O', 'R-1-2', 'O', 'O', 'O', 'O', 'O', 'R-5-4', 'R-5-50', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'R-1-50', 'R-1-2', 'R-2-50', 'O', 'R-3-50', 'R-4-50', 'R-5-50', 'R-3-50', 'R-1-50', 'O', 'O', 'O', 'R-2-50', 'O', 'R-12-5', 'R-2-50', 'R-5-4', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'R-50-4', 'O', 'O', 'O', 'O', 'O', 'R-2-4', 'R-3-4', 'O', 'R-3-4', 'R-2-3', 'R-2-3', 'R-3-50', 'O', 'R-11-12', 'R-12-3', 'R-11-12', 'O', 'R-3-50', 'R-3-50', 'R-1-50', 'R-1-2', 'R-2-3', 'O', 'R-1-50', 'R-1-2', 'R-2-50', 'R-1-50', 'R-2-50', 'R-5-50', 'R-2-5', 'R-5-50', 'O', 'R-6-50', 'O', 'R-11-3', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-11-12', 'R-12-3', 'R-5-50', 'R-4-5', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'R-1-2', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-2-50', 'R-1-3', 'R-3-50', 'R-1-2', 'R-2-3', 'O', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'R-12-3', 'R-3-4', 'R-1-2', 'R-1-50', 'R-5-6', 'R-6-50', 'O', 'O', 'R-2-50', 'R-2-50', 'O', 'R-1-2', 'R-2-50', 'R-1-50', 'O', 'R-11-12', 'R-12-3', 'R-3-50', 'R-2-50', 'R-1-2', 'R-1-2', 'R-2-50', 'R-2-50', 'R-2-50', 'O', 'R-5-50', 'R-5-4', 'R-4-6', 'O', 'R-3-4', 'R-3-50', 'O', 'R-3-4', 'R-6-3', 'R-1-50', 'R-2-50', 'R-1-2', 'R-1-50', 'O', 'O', 'O', 'O', 'R-2-50', 'R-3-50', 'R-3-6', 'R-3-4', 'R-1-2', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-2', 'R-2-3', 'R-2-3', 'O', 'R-3-4', 'O', 'R-11-12', 'R-11-12', 'R-12-3', 'O', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'R-5-6', 'O', 'R-1-2', 'R-2-3', 'R-3-6', 'R-3-6', 'R-3-6', 'R-3-50', 'R-3-50', 'O', 'O', 'O', 'R-3-50', 'O', 'R-12-3', 'R-3-4', 'R-5-50', 'O', 'O', 'R-2-50', 'O', 'O', 'O', 'R-2-50', 'R-5-6', 'R-4-5', 'R-5-6', 'R-6-50', 'O', 'R-5-6', 'R-5-50', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-12-3', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-1-50', 'R-1-50', 'O', 'O', 'O', 'R-3-4', 'R-11-12', 'R-11-12', 'R-12-3', 'O', 'R-5-50', 'R-1-2', 'R-2-5', 'R-4-5', 'R-5-6', 'R-6-50', 'R-4-50', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'R-4-5', 'R-5-6', 'O', 'O', 'R-11-50', 'R-2-50', 'R-1-50', 'R-1-2', 'R-2-50', 'R-11-12', 'R-12-3', 'R-3-50', 'R-2-50', 'R-4-6', 'R-6-50', 'R-2-50', 'R-12-2', 'R-12-2', 'R-2-50', 'O', 'O', 'R-5-50', 'R-5-6', 'R-5-50', 'R-6-50', 'R-2-50', 'R-2-3', 'R-3-50', 'O', 'R-4-50', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'R-4-6', 'R-4-5', 'R-5-6', 'R-5-50', 'R-1-50', 'R-1-2', 'R-1-3', 'R-2-3', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-4', 'O', 'O', 'O', 'O', 'O', 'R-2-5', 'O', 'R-2-50', 'O', 'O', 'R-2-50', 'R-1-50', 'R-1-50', 'R-2-50', 'R-5-4', 'R-5-4', 'R-4-50', 'R-1-2', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'O', 'O', 'R-5-50', 'R-11-5', 'R-11-12', 'R-12-3', 'R-11-12', 'O', 'O', 'O', 'R-1-50', 'O', 'R-1-2', 'O', 'R-3-50', 'O', 'R-3-4', 'R-5-50', 'R-5-50', 'R-5-50', 'R-2-50', 'R-1-50', 'R-5-50', 'R-3-50', 'R-5-50', 'O', 'R-5-50', 'R-5-50', 'R-5-50', 'R-5-6', 'R-5-50', 'R-1-50', 'R-1-2', 'R-2-50', 'O', 'O', 'O', 'R-2-5', 'R-1-2', 'R-3-5', 'R-5-50', 'R-2-50', 'R-1-2', 'R-1-2', 'O', 'R-1-2', 'R-2-50', 'R-1-50', 'R-3-50', 'R-3-50', 'R-11-3', 'R-3-4', 'R-3-50', 'R-4-50', 'R-2-50', 'R-4-50', 'R-5-6', 'R-6-50', 'R-2-50', 'R-1-2', 'O', 'O', 'R-2-5', 'R-5-6', 'R-6-50', 'O', 'O', 'R-1-50', 'R-1-2', 'R-2-3', 'R-2-50', 'R-1-50', 'O', 'O', 'R-2-50', 'O', 'R-2-50', 'R-1-3', 'O', 'R-2-4', 'R-4-6', 'O', 'R-5-50', 'O', 'R-5-50', 'O', 'R-5-4', 'R-4-6', 'R-4-6', 'O', 'O', 'R-4-6', 'O', 'R-1-50', 'R-2-50', 'R-1-2', 'O', 'O', 'R-5-50', 'R-4-5', 'R-5-6', 'R-6-50', 'R-5-50', 'R-5-50', 'O', 'R-1-50', 'O', 'O', 'R-1-2', 'R-2-5', 'R-5-50', 'R-4-50', 'R-5-4', 'O', 'O', 'O', 'O', 'O', 'R-11-12', 'R-12-3', 'R-11-12', 'R-12-3', 'O', 'R-1-5', 'R-1-50', 'R-5-50', 'R-1-50', 'O', 'R-2-50', 'R-2-5', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-6-50', 'O', 'R-2-6', 'R-6-50', 'O', 'O', 'O', 'O', 'R-12-3', 'O', 'R-5-50', 'R-6-50', 'O', 'R-5-6', 'O', 'R-5-6', 'R-4-5', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-1-2', 'O', 'O', 'O', 'O', 'O', 'R-4-5', 'O', 'R-5-6', 'R-6-50', 'O', 'O', 'R-1-2', 'R-3-50', 'R-1-50', 'R-3-5', 'R-3-50', 'R-3-5', 'R-5-6', 'R-3-5', 'R-5-6', 'O', 'O', 'O', 'R-2-50', 'R-1-2', 'R-1-50', 'O', 'R-1-50', 'R-3-50', 'R-1-2', 'R-2-3', 'O', 'R-2-50', 'R-1-2', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-1-2', 'R-1-3', 'R-1-3', 'R-1-2', 'O', 'R-2-50', 'R-3-4', 'R-2-3', 'O', 'R-5-50', 'R-5-50', 'R-5-50', 'O', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-2-50', 'R-1-50', 'R-1-2', 'R-1-2', 'R-2-3', 'R-3-4', 'R-4-50', 'R-1-50', 'O', 'R-5-50', 'R-11-50', 'O', 'R-1-50', 'O', 'O', 'O', 'O', 'R-1-2', 'O', 'R-4-5', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-4', 'R-4-50', 'R-4-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-3-4', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-50', 'R-2-3', 'O', 'O', 'R-1-2', 'R-2-50', 'O', 'R-2-4', 'R-3-4', 'R-4-50', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'R-3-50', 'R-5-50', 'R-5-50', 'O', 'O', 'R-5-50', 'R-5-50', 'R-1-50', 'R-1-50', 'R-1-2', 'R-1-2', 'O', 'O', 'R-2-50', 'R-1-2', 'O', 'R-1-50', 'O', 'R-5-6', 'O', 'R-5-6', 'R-6-50', 'O', 'R-12-3', 'R-11-12', 'R-3-50', 'R-1-50', 'R-3-4', 'R-1-2', 'R-2-3', 'R-4-5', 'O', 'R-4-5', 'R-5-6', 'R-3-5', 'R-1-3', 'R-5-50', 'R-1-50', 'R-1-50', 'R-5-50', 'R-5-50', 'R-1-50', 'R-5-50', 'R-5-50', 'O', 'R-4-5', 'R-5-50', 'R-1-50', 'R-1-2', 'R-2-3', 'R-3-50', 'R-1-50', 'R-1-50', 'O', 'O', 'R-3-50', 'R-2-3', 'O', 'R-5-50', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-4-5', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-3-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-1-2', 'R-1-2', 'R-2-3', 'O', 'O', 'R-3-50', 'R-3-4', 'R-3-4', 'R-12-3', 'R-3-5', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'O', 'R-1-2', 'R-2-50', 'R-3-4', 'O', 'R-11-12', 'R-12-3', 'R-11-12', 'R-12-3', 'R-11-12', 'R-11-12', 'R-12-3', 'R-5-50', 'R-5-5', 'R-5-6', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-4-5', 'R-5-50', 'R-4-5', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'R-5-50', 'R-5-50', 'R-1-2', 'R-2-50', 'R-2-50', 'R-4-50', 'R-2-50', 'R-3-4', 'R-4-50', 'O', 'O', 'R-2-4', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-2-5', 'O', 'O', 'R-5-6', 'R-6-50', 'R-2-50', 'R-1-50', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'R-3-4', 'R-3-6', 'O', 'O', 'O', 'O', 'R-2-5', 'R-2-4', 'O', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'O', 'R-1-2', 'O', 'O', 'O', 'R-4-50', 'R-3-4', 'R-2-3', 'R-5-50', 'R-4-5', 'R-5-6', 'R-6-50', 'R-5-50', 'R-1-2', 'R-1-50', 'O', 'R-3-4', 'R-11-12', 'R-12-3', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-4', 'R-4-50', 'O', 'R-4-50', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-2-50', 'O', 'O', 'O', 'O', 'R-5-50', 'R-5-4', 'R-5-6', 'R-2-6', 'O', 'R-1-50', 'O', 'R-1-2', 'R-5-50', 'O', 'R-6-50', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'O', 'R-3-4', 'R-2-4', 'O', 'O', 'O', 'O', 'R-4-50', 'R-3-50', 'R-4-50', 'R-3-50', 'R-2-4', 'O', 'O', 'O', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'R-3-50', 'R-1-3', 'R-1-2', 'O', 'R-5-4', 'R-4-6', 'R-5-6', 'R-6-50', 'O', 'R-1-50', 'O', 'O', 'R-12-3', 'R-11-12', 'O', 'R-11-12', 'R-11-12', 'R-12-3', 'R-11-12', 'R-12-50', 'R-11-50', 'R-2-50', 'O', 'R-2-50', 'R-4-50', 'R-4-50', 'R-4-50', 'O', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-4', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'O', 'O', 'O', 'R-2-50', 'R-5-50', 'R-1-50', 'R-4-50', 'O', 'O', 'O', 'R-3-50', 'R-1-2', 'R-1-50', 'R-5-50', 'R-4-5', 'O', 'R-5-50', 'R-5-6', 'O', 'O', 'O', 'O', 'R-4-5', 'O', 'O', 'O', 'O', 'R-1-50', 'R-2-50', 'R-1-50', 'R-2-50', 'O', 'R-1-50', 'R-1-2', 'O', 'R-1-50', 'O', 'R-2-50', 'O', 'R-2-50', 'R-1-50', 'R-1-2', 'R-1-50', 'R-1-50', 'O', 'O', 'O', 'R-5-50', 'R-3-50', 'R-2-3', 'R-5-50', 'R-1-3', 'R-1-2', 'R-1-50', 'R-1-3', 'R-1-2', 'R-1-50', 'O', 'R-4-5', 'O', 'R-5-6', 'R-6-50', 'O', 'R-3-50', 'R-5-50', 'R-2-3', 'R-1-2', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-4-5', 'R-5-6', 'O', 'O', 'R-5-6', 'R-6-50', 'R-6-50', 'O', 'R-5-50', 'R-2-50', 'R-1-50', 'R-1-2', 'R-2-50', 'R-2-4', 'R-4-50', 'R-6-50', 'O', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-5-50', 'O', 'R-3-50', 'R-2-50', 'O', 'O', 'R-1-50', 'R-1-2', 'R-3-4', 'R-11-12', 'R-12-3', 'R-11-12', 'R-12-3', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'R-4-5', 'O', 'O', 'R-1-2', 'R-2-50', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'R-12-3', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-2-50', 'R-2-3', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-2', 'R-2-3', 'R-3-50', 'R-1-2', 'R-2-50', 'O', 'R-11-12', 'R-12-3', 'R-3-4', 'R-5-6', 'R-6-50', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-2-5', 'R-5-4', 'R-5-6', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-4-5', 'R-5-6', 'R-6-50', 'O', 'R-1-50', 'R-4-50', 'R-5-50', 'R-1-50', 'O', 'O', 'O', 'O', 'R-4-5', 'R-4-5', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-3-4', 'R-4-5', 'O', 'R-4-6', 'O', 'O', 'O', 'O', 'R-3-4', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-6-50', 'R-5-6', 'R-5-6', 'R-5-50', 'R-2-50', 'R-5-50', 'R-1-50', 'R-3-50', 'R-1-50', 'R-5-50', 'R-2-50', 'R-1-2', 'R-2-5', 'O', 'O', 'O', 'R-2-5', 'O', 'O', 'O', 'R-4-5', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'R-5-6', 'O', 'O', 'R-3-50', 'O', 'O', 'O', 'R-6-50', 'R-1-2', 'R-2-50', 'R-1-50', 'O', 'O', 'O', 'O', 'R-3-50', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-1-2', 'R-2-50', 'O', 'O', 'R-3-4', 'O', 'O', 'R-1-50', 'R-5-50', 'R-1-50', 'R-1-2', 'O', 'R-2-3', 'R-2-4', 'R-4-5', 'R-4-5', 'R-5-6', 'R-4-6', 'O', 'R-4-50', 'R-4-50', 'R-5-50', 'R-4-11', 'R-12-3', 'O', 'R-1-50', 'R-1-2', 'R-2-50', 'O', 'R-1-2', 'R-1-50', 'O', 'R-1-50', 'R-11-50', 'R-2-50', 'R-5-50', 'R-5-50', 'R-5-6', 'O', 'R-2-50', 'R-1-50', 'R-5-50', 'R-4-50', 'R-2-50', 'R-1-50', 'R-5-50', 'R-4-50', 'R-11-5', 'O', 'R-4-5', 'R-5-6', 'R-4-5', 'R-4-5', 'R-12-3', 'O', 'R-11-12', 'R-12-3', 'O', 'R-11-12', 'R-12-3', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-1-2', 'R-1-2', 'O', 'R-5-50', 'R-4-5', 'R-5-6', 'O', 'O', 'R-5-6', 'R-6-50', 'R-5-6', 'R-5-50', 'R-5-50', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-1-50', 'O', 'R-2-3', 'R-5-50', 'O', 'O', 'R-5-6', 'R-5-6', 'R-6-50', 'R-6-50', 'O', 'O', 'O', 'O', 'R-5-50', 'O', 'O', 'O', 'R-4-5', 'R-4-5', 'O', 'O', 'R-2-50', 'R-3-50', 'R-1-50', 'O', 'R-3-50', 'R-1-50', 'R-2-3', 'R-1-50', 'O', 'O', 'R-1-2', 'O', 'R-2-3', 'R-3-50', 'R-1-2', 'R-2-50', 'R-2-3', 'O', 'O', 'R-3-5', 'O', 'R-6-50', 'R-3-50', 'R-5-6', 'R-6-50', 'R-4-50', 'O', 'R-6-50', 'R-2-50', 'O', 'R-12-3', 'R-3-4', 'R-11-12', 'R-12-3', 'R-2-50', 'R-5-50', 'O', 'O', 'O', 'O', 'R-3-50', 'R-2-3', 'R-5-6', 'R-6-50', 'O', 'R-2-50', 'O', 'R-3-5', 'R-2-3', 'O', 'O', 'O', 'R-2-50', 'R-2-50', 'O', 'R-5-6', 'R-6-50', 'R-6-50', 'O', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-50', 'R-3-4', 'R-11-12', 'O', 'O', 'O', 'R-4-5', 'R-5-6', 'O', 'R-2-50', 'R-1-50', 'R-1-50', 'R-2-50', 'O', 'O', 'O', 'R-11-12', 'R-12-3', 'R-11-12', 'R-12-3', 'R-5-50', 'R-5-6', 'R-5-6', 'R-6-50', 'R-5-50', 'R-1-50', 'R-5-50', 'O', 'O', 'O', 'O', 'R-3-50', 'R-2-50', 'R-3-50', 'R-2-50', 'O', 'O', 'R-3-4', 'R-12-3', 'R-5-50', 'O', 'O', 'R-5-50', 'R-6-50', 'O', 'O', 'O', 'R-1-2', 'R-1-50', 'R-3-5', 'R-5-50', 'R-1-2', 'O', 'O', 'O', 'R-4-5', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-12-3', 'O', 'R-2-50', 'R-5-6', 'R-5-6', 'R-6-50', 'O', 'O', 'R-2-50', 'R-5-50', 'O', 'R-2-50', 'R-1-50', 'R-1-50', 'R-1-50', 'O', 'O', 'O', 'R-1-50', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'R-2-50', 'R-1-50', 'R-2-1', 'O', 'O', 'R-1-50', 'R-1-2', 'R-2-4', 'R-4-50', 'R-2-50', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-5-50', 'R-1-50', 'R-5-50', 'O', 'R-1-2', 'R-1-2', 'R-2-4', 'R-1-50', 'R-1-2', 'R-2-3', 'R-3-4', 'R-5-50', 'R-5-50', 'R-5-4', 'R-4-50', 'O', 'R-5-6', 'R-6-50', 'R-1-50', 'R-5-50', 'R-2-50', 'O', 'R-1-50', 'R-2-50', 'O', 'O', 'O', 'O', 'R-1-50', 'O', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'R-1-50', 'R-1-50', 'R-1-2', 'R-2-3', 'O', 'R-12-3', 'R-11-12', 'O', 'O', 'R-11-50', 'R-5-50', 'R-3-5', 'R-5-6', 'R-5-6', 'R-6-50', 'O', 'R-5-50', 'R-5-4', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-4-50', 'R-3-50', 'O', 'R-4-50', 'R-3-4', 'O', 'O', 'R-5-50', 'R-2-6', 'R-2-6', 'R-6-50', 'O', 'O', 'R-2-50', 'R-3-50', 'R-3-50', 'R-2-50', 'O', 'O', 'O', 'R-2-50', 'R-4-6', 'O', 'R-11-12', 'R-12-2', 'R-11-12', 'R-12-2', 'R-4-5', 'R-5-6', 'R-5-6', 'O', 'R-5-6', 'R-6-50', 'R-4-6', 'R-5-50', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'O', 'O', 'R-2-50', 'R-1-2', 'R-2-3', 'R-2-3', 'R-3-4', 'R-5-50', 'R-4-5', 'R-6-5', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'O', 'R-5-50', 'R-5-4', 'O', 'R-5-6', 'R-6-50', 'O', 'R-2-4', 'O', 'R-5-6', 'R-11-50', 'R-11-5', 'R-12-50', 'R-12-5', 'R-3-50', 'R-3-4', 'R-2-3', 'R-2-50', 'R-1-2', 'R-3-4', 'R-4-5', 'R-5-50', 'R-1-2', 'O', 'R-1-50', 'R-5-50', 'R-3-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'O', 'O', 'O', 'R-3-4', 'O', 'R-1-3', 'R-1-50', 'R-1-50', 'O', 'R-2-3', 'R-1-50', 'O', 'R-5-50', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'R-1-50', 'R-1-2', 'R-2-50', 'R-2-5', 'O', 'R-1-50', 'O', 'O', 'R-4-5', 'O', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-2-3', 'O', 'O', 'R-12-3', 'O', 'O', 'O', 'O', 'R-1-2', 'R-1-2', 'R-1-2', 'R-6-50', 'R-3-6', 'R-2-3', 'R-1-2', 'R-2-5', 'R-5-50', 'O', 'R-5-50', 'R-1-5', 'R-2-5', 'R-5-50', 'R-2-50', 'R-1-50', 'O', 'R-2-50', 'R-1-50', 'O', 'O', 'R-5-50', 'R-5-6', 'R-5-50', 'R-5-50', 'R-5-50', 'O', 'O', 'R-1-50', 'R-1-50', 'O', 'O', 'R-1-50', 'R-2-50', 'R-1-50', 'R-3-50', 'R-3-4', 'R-3-50', 'R-11-12', 'R-11-12', 'R-12-3', 'R-3-50', 'R-5-50', 'R-4-5', 'O', 'O', 'R-6-50', 'R-5-6', 'R-1-50', 'R-3-50', 'R-5-50', 'R-3-50', 'R-2-3', 'O', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-11-12', 'R-12-3', 'O', 'R-4-5', 'R-5-6', 'R-6-50', 'O', 'R-4-5', 'R-1-50', 'R-4-50', 'R-2-50', 'R-4-50', 'O', 'O', 'R-5-50', 'O', 'O', 'O', 'R-5-50', 'O', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'R-2-3', 'R-4-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-11-12', 'R-12-3', 'R-2-1', 'R-1-5', 'R-5-50', 'R-2-1', 'R-4-50', 'O', 'O', 'O', 'R-5-50', 'R-5-50', 'R-4-5', 'R-5-50', 'R-5-50', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-1-50', 'R-3-50', 'R-3-50', 'R-2-3', 'R-3-4', 'R-3-4', 'R-2-50', 'R-2-5', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-2-50', 'R-1-2', 'R-1-50', 'O', 'O', 'O', 'O', 'R-3-50', 'R-2-3', 'R-3-5', 'R-1-3', 'R-1-2', 'R-2-50', 'R-11-50', 'R-2-50', 'R-4-50', 'O', 'O', 'O', 'O', 'R-12-3', 'R-2-50', 'R-1-50', 'R-1-2', 'O', 'O', 'R-2-50', 'R-3-4', 'R-3-4', 'R-2-4', 'R-4-50', 'O', 'O', 'R-5-6', 'R-3-50', 'O', 'O', 'O', 'O', 'R-2-50', 'R-2-50', 'O', 'R-1-50', 'R-5-50', 'O', 'R-6-50', 'R-5-6', 'R-2-5', 'R-1-5', 'R-4-5', 'R-5-6', 'O', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'O', 'R-1-2', 'R-2-50', 'O', 'R-2-3', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-6', 'R-3-6', 'R-5-4', 'O', 'O', 'R-5-6', 'O', 'O', 'R-5-50', 'R-5-6', 'R-4-5', 'O', 'O', 'O', 'O', 'R-1-50', 'R-2-50', 'R-1-2', 'R-2-3', 'O', 'R-11-12', 'R-12-3', 'R-3-5', 'R-5-6', 'R-4-5', 'O', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'R-3-50', 'R-2-3', 'R-5-50', 'O', 'R-2-50', 'O', 'O', 'R-2-50', 'O', 'R-2-3', 'R-2-3', 'R-3-50', 'R-5-50', 'R-5-6', 'R-6-50', 'O', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-4', 'R-2-3', 'R-4-50', 'R-4-5', 'R-5-6', 'R-6-50', 'O', 'R-1-2', 'R-3-50', 'R-2-3', 'R-5-50', 'R-2-50', 'R-1-50', 'R-1-2', 'R-2-3', 'R-2-3', 'R-3-4', 'R-4-6', 'R-2-4', 'R-5-4', 'O', 'O', 'R-5-6', 'R-6-50', 'O', 'R-5-50', 'R-50-5', 'R-50-5', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-6-50', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'R-2-5', 'R-2-50', 'O', 'R-1-5', 'R-1-5', 'R-5-6', 'R-6-50', 'O', 'R-5-6', 'R-5-50', 'R-50-5', 'R-50-5', 'O', 'R-4-5', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-1-2', 'R-1-50', 'R-1-2', 'O', 'O', 'O', 'R-3-4', 'O', 'R-11-12', 'R-12-3', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-2', 'R-2-50', 'R-5-4', 'R-5-50', 'O', 'O', 'R-5-50', 'R-2-50', 'R-5-50', 'R-2-50', 'R-5-50', 'R-4-5', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-2', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-2', 'R-2-3', 'R-2-50', 'R-11-12', 'R-12-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'R-5-50', 'R-3-50', 'O', 'O', 'O', 'R-2-50', 'R-1-2', 'R-2-5', 'R-2-5', 'R-5-50', 'R-5-6', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'R-11-12', 'R-12-3', 'R-11-12', 'R-12-3', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-1-50', 'R-1-2', 'R-2-50', 'R-2-3', 'O', 'R-3-4', 'R-4-50', 'R-5-50', 'O', 'R-4-6', 'R-6-50', 'R-5-6', 'R-5-50', 'R-5-50', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'R-1-50', 'R-1-2', 'R-2-3', 'R-3-50', 'R-2-50', 'R-1-3', 'R-2-3', 'R-11-12', 'R-12-3', 'R-11-12', 'R-12-3', 'R-11-50', 'R-3-50', 'R-1-50', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-5-4', 'R-3-50', 'R-2-3', 'R-5-50', 'R-4-5', 'R-2-50', 'R-1-2', 'R-2-3', 'R-3-50', 'R-2-50', 'R-2-5', 'R-4-6', 'R-6-50', 'R-5-50', 'R-5-50', 'O', 'R-1-50', 'R-1-50', 'O', 'O', 'R-1-50', 'R-11-50', 'R-1-50', 'R-1-2', 'R-2-3', 'R-3-4', 'R-3-6', 'R-11-12', 'R-11-12', 'R-12-3', 'R-1-2', 'O', 'R-1-2', 'R-11-12', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'O', 'R-1-2', 'R-1-2', 'R-2-3', 'O', 'O', 'O', 'O', 'R-12-3', 'R-3-4', 'O', 'R-12-3', 'R-11-12', 'R-5-4', 'R-5-6', 'R-5-6', 'R-5-6', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'R-3-50', 'R-3-4', 'R-5-50', 'R-5-6', 'R-6-50', 'R-5-50', 'R-5-50', 'R-5-50', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-50', 'R-1-50', 'R-2-50', 'R-1-50', 'R-1-2', 'R-2-50', 'R-1-50', 'O', 'R-3-4', 'R-2-50', 'R-2-50', 'R-2-50', 'R-2-4', 'R-4-5', 'O', 'O', 'R-3-50', 'R-2-3', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-50', 'R-5-6', 'R-6-50', 'R-5-6', 'R-6-50', 'O', 'R-3-4', 'R-12-3', 'O', 'O', 'O', 'R-3-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-50', 'R-2-3', 'R-3-4', 'O', 'O', 'O', 'R-3-50', 'R-3-50', 'R-3-4', 'O', 'R-3-4', 'R-3-50', 'R-4-5', 'R-3-4', 'O', 'O', 'R-5-50', 'R-5-50', 'R-3-50', 'R-5-50', 'R-3-50', 'R-5-50', 'R-6-50', 'R-5-50', 'R-3-50', 'R-2-3', 'R-3-6', 'R-6-50', 'R-5-4', 'R-3-4', 'R-4-50', 'O', 'R-5-6', 'R-12-2', 'R-2-50', 'R-5-50', 'R-1-2', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-1-2', 'R-1-2', 'R-2-3', 'O', 'R-5-6', 'R-4-5', 'R-5-6', 'O', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-5-50', 'R-4-5', 'R-5-6', 'O', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'R-5-6', 'O', 'R-4-5', 'R-5-50', 'R-5-50', 'R-5-50', 'R-5-6', 'R-5-4', 'R-5-4', 'R-5-6', 'O', 'O', 'O', 'R-4-5', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-4-5', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-2-50', 'O', 'R-3-4', 'R-3-4', 'R-11-12', 'R-11-12', 'R-12-3', 'O', 'R-4-5', 'O', 'O', 'R-2-4', 'R-5-6', 'O', 'R-4-5', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'O', 'O', 'O', 'R-1-2', 'R-3-6', 'R-11-12', 'R-12-3', 'O', 'R-5-4', 'R-5-6', 'R-5-6', 'R-6-50', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'R-2-3', 'R-1-2', 'O', 'R-4-5', 'R-5-6', 'O', 'R-5-50', 'R-2-50', 'R-2-5', 'R-5-6', 'R-4-6', 'O', 'O', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-5-6', 'R-4-5', 'O', 'O', 'O', 'O', 'R-4-5', 'O', 'R-2-50', 'R-1-2', 'R-1-2', 'R-2-3', 'R-2-3', 'O', 'R-2-50', 'R-5-50', 'R-3-50', 'R-2-50', 'R-5-50', 'R-3-50', 'O', 'R-2-50', 'O', 'R-4-5', 'O', 'O', 'O', 'O', 'R-1-50', 'R-1-50', 'O', 'O', 'R-5-50', 'O', 'O', 'O', 'R-2-50', 'R-2-5', 'R-5-50', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-2-50', 'R-2-50', 'R-5-50', 'O', 'R-2-50', 'O', 'O', 'R-5-50', 'R-5-50', 'R-2-5', 'R-2-4', 'R-3-4', 'R-5-50', 'R-1-50', 'R-3-50', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-2-50', 'R-5-6', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'R-5-50', 'R-3-50', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'R-5-50', 'R-2-50', 'R-1-2', 'R-1-2', 'R-2-3', 'R-3-50', 'R-3-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-50', 'O', 'R-5-6', 'R-4-5', 'R-5-6', 'O', 'O', 'R-6-50', 'R-5-5', 'R-12-3', 'R-3-50', 'R-5-50', 'R-2-50', 'R-2-50', 'R-3-50', 'R-3-4', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-50', 'R-1-50', 'R-2-50', 'R-2-50', 'R-2-3', 'R-5-50', 'R-4-5', 'R-5-6', 'R-4-50', 'R-6-50', 'R-5-50', 'R-5-50', 'O', 'R-2-50', 'O', 'O', 'O', 'R-1-2', 'R-2-3', 'R-3-50', 'O', 'R-11-12', 'R-12-3', 'O', 'R-2-50', 'R-11-50', 'R-11-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-4-50', 'O', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'R-11-12', 'R-11-12', 'R-12-3', 'O', 'O', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'O', 'R-1-50', 'R-1-2', 'O', 'R-11-12', 'R-12-3', 'R-11-12', 'R-11-12', 'R-12-3', 'R-11-3', 'R-11-3', 'R-11-12', 'R-12-3', 'R-12-5', 'R-5-50', 'R-5-50', 'R-5-50', 'R-4-5', 'R-4-5', 'R-5-50', 'R-4-5', 'R-2-4', 'O', 'R-1-2', 'R-3-50', 'R-2-50', 'R-3-50', 'R-4-5', 'R-5-6', 'R-6-50', 'R-4-6', 'R-2-50', 'R-1-2', 'O', 'O', 'O', 'O', 'R-1-2', 'R-1-3', 'R-3-50', 'R-2-50', 'O', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'R-5-50', 'R-5-4', 'R-4-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-11-3', 'R-1-3', 'R-11-12', 'R-12-3', 'R-11-5', 'R-5-6', 'R-6-50', 'R-2-5', 'R-5-50', 'R-1-50', 'R-1-2', 'R-1-50', 'R-1-2', 'R-1-50', 'R-1-3', 'R-3-50', 'O', 'O', 'O', 'R-11-50', 'R-1-50', 'O', 'R-1-50', 'R-11-50', 'R-1-50', 'R-11-50', 'O', 'R-1-50', 'R-11-50', 'R-12-3', 'O', 'O', 'R-3-50', 'R-2-3', 'R-1-2', 'R-1-50', 'O', 'R-11-12', 'R-11-12', 'R-12-3', 'R-1-50', 'R-11-50', 'O', 'R-1-2', 'R-1-2', 'R-2-5', 'R-2-5', 'R-5-50', 'R-5-50', 'R-5-50', 'R-4-5', 'O', 'R-5-6', 'R-6-50', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-50', 'R-2-50', 'R-1-50', 'O', 'R-1-2', 'R-2-50', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'R-3-4', 'O', 'R-11-12', 'R-11-12', 'R-12-3', 'R-5-50', 'R-5-6', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-4-5', 'R-5-6', 'R-2-50', 'R-3-4', 'R-3-6', 'R-1-2', 'R-2-50', 'R-1-50', 'O', 'O', 'R-11-12', 'R-12-3', 'R-11-3', 'R-5-50', 'O', 'O', 'O', 'O', 'R-1-2', 'R-12-50', 'R-12-50', 'R-12-3', 'R-12-2', 'R-3-4', 'R-5-50', 'O', 'O', 'R-5-50', 'R-4-5', 'R-3-50', 'R-5-50', 'R-3-5', 'R-3-50', 'O', 'O', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'O', 'O', 'O', 'R-3-4', 'O', 'O', 'R-3-50', 'R-3-4', 'R-3-4', 'R-4-6', 'O', 'O', 'O', 'R-3-50', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'O', 'R-2-4', 'O', 'O', 'O', 'R-5-50', 'R-3-50', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-2', 'O', 'R-3-50', 'R-5-50', 'O', 'R-3-50', 'R-5-50', 'R-2-3', 'R-4-5', 'R-5-50', 'R-6-50', 'R-2-3', 'R-3-50', 'R-1-2', 'O', 'O', 'R-12-3', 'R-1-50', 'R-2-50', 'R-5-50', 'R-2-50', 'R-1-2', 'R-1-2', 'R-5-50', 'R-4-5', 'R-2-4', 'R-2-4', 'O', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'R-4-5', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-2-50', 'R-2-50', 'R-1-3', 'R-1-2', 'R-2-3', 'R-3-4', 'R-1-4', 'R-5-50', 'R-4-5', 'R-5-6', 'R-6-50', 'R-5-50', 'R-5-50', 'R-5-50', 'R-2-50', 'R-1-50', 'R-1-2', 'R-3-50', 'R-2-3', 'R-2-50', 'R-5-50', 'R-5-6', 'R-6-50', 'R-1-50', 'R-1-50', 'R-1-50', 'R-5-50', 'R-5-6', 'R-6-50', 'O', 'R-5-50', 'O', 'R-5-50', 'R-5-50', 'R-5-50', 'O', 'R-1-2', 'R-1-50', 'R-2-50', 'R-2-50', 'R-1-2', 'R-1-2', 'R-1-3', 'R-2-3', 'O', 'R-3-4', 'O', 'R-11-12', 'R-11-12', 'R-12-3', 'R-1-50', 'R-2-3', 'O', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-1-50', 'R-1-2', 'R-2-50', 'R-2-50', 'O', 'O', 'O', 'R-5-50', 'R-5-50', 'R-1-50', 'O', 'O', 'R-12-3', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'O', 'O', 'O', 'O', 'R-1-50', 'R-2-50', 'R-1-2', 'R-2-50', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-2', 'R-2-5', 'R-5-50', 'R-5-50', 'R-1-5', 'R-2-4', 'O', 'R-2-3', 'R-3-4', 'R-2-4', 'R-4-50', 'O', 'O', 'R-4-5', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-6', 'R-5-50', 'R-5-50', 'R-2-50', 'R-1-2', 'O', 'O', 'O', 'R-1-50', 'R-5-50', 'R-5-4', 'R-5-6', 'R-5-6', 'R-6-50', 'R-3-4', 'R-11-12', 'R-12-3', 'R-5-50', 'R-3-50', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'O', 'R-3-4', 'R-3-6', 'R-3-50', 'O', 'R-1-50', 'R-1-2', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-11-50', 'R-3-50', 'R-1-2', 'R-1-3', 'O', 'O', 'R-5-6', 'R-5-6', 'R-6-50', 'R-5-50', 'R-11-12', 'R-11-12', 'R-12-3', 'R-11-12', 'R-11-12', 'R-3-50', 'R-1-2', 'O', 'R-1-2', 'O', 'R-2-4', 'O', 'R-1-50', 'R-1-2', 'R-2-50', 'O', 'R-12-3', 'O', 'R-4-50', 'R-4-50', 'O', 'O', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-3-4', 'R-2-3', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'R-5-6', 'R-5-50', 'O', 'O', 'O', 'R-6-50', 'R-5-4', 'R-2-5', 'R-4-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-4-5', 'O', 'O', 'R-1-2', 'R-1-2', 'O', 'R-1-2', 'O', 'R-1-2', 'O', 'R-1-50', 'R-1-50', 'R-1-50', 'R-3-50', 'R-2-3', 'R-2-5', 'R-2-4', 'R-2-5', 'R-2-4', 'R-4-50', 'R-5-50', 'R-3-50', 'R-3-50', 'R-2-3', 'R-1-2', 'R-1-4', 'R-1-2', 'R-12-50', 'R-3-50', 'R-1-2', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-11-12', 'R-12-3', 'R-3-50', 'O', 'R-5-50', 'R-4-5', 'O', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'R-1-50', 'R-1-2', 'R-2-5', 'R-2-5', 'R-5-6', 'R-6-50', 'R-1-2', 'R-5-50', 'R-2-5', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-3-50', 'R-4-50', 'R-1-50', 'R-1-2', 'R-2-50', 'R-1-2', 'R-5-50', 'R-1-2', 'R-3-50', 'R-1-3', 'R-1-3', 'R-3-4', 'R-4-50', 'R-5-50', 'R-4-50', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'O', 'R-5-50', 'O', 'O', 'O', 'R-3-50', 'R-3-4', 'O', 'R-5-50', 'R-4-5', 'R-6-50', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'R-3-5', 'R-1-5', 'R-5-50', 'O', 'R-12-3', 'O', 'R-3-4', 'O', 'R-12-3', 'R-11-3', 'O', 'O', 'R-1-3', 'O', 'R-2-50', 'R-1-50', 'R-12-50', 'R-2-50', 'O', 'R-2-4', 'R-1-50', 'R-1-50', 'R-1-2', 'R-1-50', 'R-2-3', 'R-3-50', 'R-12-50', 'O', 'R-11-12', 'R-12-3', 'O', 'O', 'R-3-50', 'R-3-50', 'R-3-50', 'R-5-50', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'R-2-50', 'R-3-50', 'R-5-50', 'R-5-50', 'R-1-50', 'R-1-2', 'R-2-50', 'R-1-50', 'O', 'O', 'R-6-50', 'R-5-6', 'O', 'R-4-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-2-3', 'R-3-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-5-50', 'R-1-2', 'R-1-2', 'R-2-50', 'R-5-50', 'R-5-6', 'R-5-50', 'O', 'R-5-6', 'O', 'O', 'R-3-50', 'R-2-3', 'R-1-2', 'R-1-50', 'R-2-3', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-12-3', 'O', 'R-3-50', 'R-2-50', 'R-11-12', 'R-12-3', 'R-5-50', 'O', 'O', 'O', 'R-2-50', 'O', 'O', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-50', 'R-1-2', 'R-1-50', 'R-3-50', 'O', 'R-4-5', 'R-5-50', 'R-6-50', 'O', 'O', 'R-3-50', 'R-2-5', 'R-4-5', 'R-5-6', 'O', 'R-6-50', 'R-5-6', 'R-5-50', 'O', 'R-12-3', 'R-1-2', 'R-2-50', 'R-3-50', 'R-3-50', 'O', 'R-5-6', 'R-5-6', 'R-6-50', 'O', 'O', 'R-2-50', 'R-1-2', 'R-2-50', 'R-3-50', 'O', 'R-2-50', 'R-5-50', 'R-4-5', 'R-5-6', 'R-6-50', 'R-5-50', 'R-5-50', 'O', 'O', 'R-4-5', 'O', 'R-5-6', 'R-6-50', 'R-3-4', 'O', 'O', 'R-2-50', 'O', 'R-2-4', 'R-5-50', 'R-2-5', 'R-5-6', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-2-3', 'R-5-50', 'R-5-6', 'O', 'O', 'R-4-50', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'O', 'R-3-4', 'R-3-4', 'R-5-50', 'O', 'O', 'R-2-50', 'R-3-50', 'R-2-50', 'R-3-50', 'O', 'R-1-3', 'R-3-50', 'R-3-50', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'R-5-6', 'R-6-4', 'R-6-50', 'O', 'O', 'R-5-6', 'R-6-50', 'O', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-2-50', 'R-2-3', 'R-3-50', 'R-2-3', 'R-11-12', 'R-12-3', 'R-11-12', 'R-11-12', 'R-12-3', 'R-5-50', 'O', 'O', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-3', 'R-3-4', 'R-3-5', 'O', 'R-6-50', 'R-6-50', 'R-5-50', 'R-3-5', 'R-1-2', 'R-2-3', 'R-3-5', 'R-3-5', 'R-5-50', 'R-11-12', 'R-11-50', 'R-5-50', 'R-2-50', 'R-5-50', 'R-5-50', 'O', 'R-5-50', 'R-5-50', 'R-5-50', 'R-2-4', 'R-2-5', 'O', 'R-5-50', 'O', 'O', 'R-1-50', 'O', 'R-1-50', 'R-1-2', 'R-2-50', 'O', 'R-1-50', 'R-11-12', 'R-12-3', 'R-11-12', 'R-12-3', 'O', 'O', 'R-12-3', 'O', 'O', 'R-4-6', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'R-6-50', 'O', 'R-1-50', 'R-5-50', 'R-5-50', 'R-5-6', 'R-1-50', 'R-1-3', 'R-1-2', 'O', 'O', 'R-12-3', 'R-5-50', 'R-5-6', 'R-6-50', 'R-5-6', 'R-5-50', 'R-5-50', 'O', 'O', 'R-1-50', 'R-1-50', 'O', 'R-1-2', 'R-12-3', 'O', 'O', 'O', 'O', 'R-3-50', 'R-1-2', 'R-1-2', 'R-12-3', 'R-11-12', 'R-11-12', 'R-12-3', 'R-2-3', 'R-12-3', 'R-5-50', 'R-5-6', 'R-4-5', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'R-1-50', 'R-1-2', 'O', 'O', 'R-5-50', 'O', 'R-5-6', 'R-6-50', 'O', 'O', 'R-5-50', 'O', 'O', 'O', 'R-3-50', 'R-2-3', 'R-11-12', 'R-12-3', 'R-3-4', 'R-3-4', 'R-2-3', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-2-50', 'R-6-50', 'R-5-6', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'O', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-4-5', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'O', 'R-2-3', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-3', 'R-3-50', 'R-1-50', 'R-1-50', 'R-5-50', 'R-5-6', 'R-6-50', 'R-5-50', 'R-1-50', 'R-2-50', 'R-5-50', 'R-1-50', 'R-2-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'R-2-5', 'R-1-5', 'O', 'O', 'R-4-5', 'R-5-6', 'O', 'O', 'O', 'O', 'R-1-50', 'R-3-50', 'R-3-50', 'R-2-50', 'R-1-50', 'R-1-2', 'R-2-50', 'R-2-5', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-50', 'R-2-50', 'R-1-50', 'O', 'O', 'R-2-50', 'R-5-50', 'O', 'R-2-50', 'R-5-50', 'O', 'R-2-5', 'O', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-4', 'R-4-6', 'R-5-50', 'R-4-5', 'O', 'O', 'R-12-3', 'R-12-2', 'O', 'R-12-50', 'O', 'O', 'R-3-50', 'R-5-50', 'R-1-50', 'O', 'O', 'O', 'R-2-5', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'O', 'R-6-50', 'R-5-6', 'O', 'R-2-50', 'R-2-50', 'R-1-2', 'R-2-50', 'R-5-6', 'R-5-50', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'O', 'O', 'R-2-50', 'O', 'R-2-50', 'O', 'R-1-2', 'R-2-50', 'R-5-6', 'R-6-50', 'R-6-50', 'R-5-50', 'O', 'R-1-2', 'O', 'O', 'R-2-50', 'O', 'R-12-3', 'O', 'R-2-4', 'R-5-6', 'R-6-50', 'R-2-50', 'R-1-50', 'R-3-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-4', 'R-5-5', 'O', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'R-5-50', 'R-2-50', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-1-3', 'R-3-50', 'R-3-50', 'R-3-5', 'R-4-5', 'R-5-50', 'R-5-4', 'O', 'O', 'R-1-50', 'R-2-50', 'R-4-50', 'R-5-50', 'R-2-50', 'R-4-50', 'R-1-50', 'R-5-50', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-2', 'R-3-4', 'R-5-4', 'R-4-50', 'R-5-50', 'R-2-5', 'O', 'O', 'O', 'O', 'R-1-50', 'R-1-50', 'R-1-50', 'R-1-2', 'R-2-3', 'R-3-50', 'R-1-50', 'R-11-50', 'O', 'R-2-50', 'R-1-50', 'R-1-2', 'O', 'R-2-3', 'R-3-50', 'O', 'R-5-6', 'O', 'O', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-12-3', 'O', 'O', 'R-5-50', 'R-2-50', 'R-1-2', 'R-1-50', 'R-3-50', 'O', 'R-5-6', 'R-3-6', 'R-11-12', 'R-12-3', 'R-11-12', 'O', 'O', 'R-2-50', 'R-3-50', 'R-5-50', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-12-3', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-12-3', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-4-5', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-2-50', 'R-1-50', 'R-1-2', 'O', 'O', 'O', 'O', 'R-12-3', 'O', 'R-4-5', 'O', 'O', 'O', 'O', 'R-5-50', 'O', 'R-1-50', 'R-4-50', 'R-1-50', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'R-4-5', 'R-5-50', 'O', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-50', 'R-3-50', 'O', 'R-3-4', 'R-5-50', 'R-5-50', 'R-2-50', 'R-1-50', 'R-1-50', 'R-2-5', 'R-2-3', 'R-5-50', 'R-3-50', 'O', 'O', 'R-1-50', 'R-1-2', 'R-5-50', 'R-4-5', 'R-5-6', 'R-5-6', 'R-6-50', 'O', 'O', 'R-4-5', 'R-4-5', 'R-5-50', 'R-3-4', 'R-4-50', 'R-4-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'R-1-3', 'R-1-2', 'R-1-3', 'R-1-3', 'R-5-50', 'R-3-50', 'R-2-50', 'O', 'R-1-2', 'O', 'R-2-50', 'R-3-50', 'R-3-4', 'R-3-4', 'R-5-6', 'R-6-50', 'R-4-5', 'R-5-6', 'R-6-50', 'O', 'O', 'R-1-50', 'R-1-4', 'R-1-2', 'R-1-4', 'R-1-2', 'R-1-2', 'R-2-3', 'R-1-2', 'R-3-50', 'O', 'O', 'R-1-50', 'O', 'O', 'R-3-4', 'R-3-4', 'O', 'R-4-5', 'R-5-50', 'R-3-50', 'R-2-50', 'R-3-50', 'R-2-50', 'R-1-50', 'R-1-50', 'R-1-2', 'R-1-2', 'O', 'R-5-6', 'O', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-2-50', 'R-5-50', 'R-5-6', 'R-6-50', 'R-1-50', 'O', 'R-2-50', 'O', 'O', 'O', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-2-50', 'R-12-4', 'R-12-3', 'O', 'R-3-4', 'R-4-5', 'R-5-6', 'O', 'R-6-50', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-1-2', 'R-5-50', 'R-5-4', 'R-4-6', 'O', 'O', 'O', 'R-5-50', 'O', 'O', 'R-5-50', 'R-11-5', 'R-11-12', 'R-12-3', 'R-11-12', 'R-12-3', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-1-2', 'R-2-50', 'O', 'O', 'R-2-3', 'R-3-50', 'R-11-12', 'R-5-6', 'R-6-50', 'O', 'R-2-50', 'O', 'R-1-50', 'O', 'R-3-4', 'R-4-6', 'R-3-50', 'O', 'R-5-6', 'R-6-50', 'O', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-4', 'R-4-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-11-12', 'R-12-3', 'O', 'R-4-5', 'O', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'R-4-5', 'R-12-2', 'R-2-5', 'R-5-50', 'R-5-50', 'R-2-50', 'R-3-50', 'O', 'R-1-2', 'O', 'R-1-50', 'O', 'R-1-50', 'O', 'R-4-5', 'O', 'O', 'O', 'R-4-50', 'R-5-4', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-5-6', 'R-5-50', 'R-5-6', 'O', 'R-2-50', 'O', 'R-1-3', 'O', 'O', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-5-50', 'R-1-2', 'R-5-50', 'O', 'R-1-2', 'O', 'R-1-3', 'R-3-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-4', 'R-3-6', 'R-3-6', 'O', 'R-5-50', 'R-5-50', 'R-5-4', 'R-5-6', 'R-6-50', 'R-4-6', 'R-3-5', 'O', 'R-1-2', 'R-1-3', 'R-1-2', 'R-1-3', 'R-1-2', 'R-3-50', 'R-1-3', 'R-3-50', 'R-2-50', 'R-3-50', 'O', 'O', 'O', 'O', 'R-3-5', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-2', 'R-2-3', 'R-5-50', 'O', 'O', 'O', 'O', 'R-5-50', 'R-2-5', 'R-2-50', 'R-3-6', 'R-6-50', 'R-1-3', 'R-3-50', 'O', 'O', 'R-5-50', 'O', 'R-2-50', 'R-1-2', 'R-1-2', 'R-12-50', 'R-3-4', 'R-3-50', 'R-2-5', 'R-5-6', 'R-6-50', 'R-5-6', 'R-2-50', 'R-5-50', 'R-2-4', 'R-5-50', 'O', 'O', 'R-1-2', 'R-1-2', 'R-2-3', 'R-1-2', 'R-3-50', 'R-2-3', 'R-2-3', 'R-3-50', 'R-3-4', 'R-4-6', 'R-3-6', 'O', 'R-11-12', 'R-12-3', 'R-11-12', 'R-12-3', 'R-3-4', 'R-3-5', 'R-5-6', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'R-5-50', 'O', 'O', 'R-5-50', 'R-6-50', 'R-5-6', 'R-12-2', 'O', 'R-1-2', 'R-2-4', 'R-1-2', 'R-2-50', 'R-2-4', 'O', 'O', 'O', 'O', 'R-3-50', 'O', 'O', 'O', 'R-3-4', 'R-4-5', 'R-5-6', 'O', 'O', 'R-5-6', 'R-6-50', 'O', 'R-2-50', 'R-12-3', 'R-50-3', 'R-2-50', 'R-4-50', 'R-2-4', 'O', 'O', 'R-2-50', 'R-1-2', 'R-1-2', 'O', 'R-5-50', 'R-2-50', 'O', 'O', 'R-12-50', 'R-3-50', 'O', 'R-5-50', 'R-3-50', 'R-2-50', 'R-1-2', 'R-1-3', 'R-1-2', 'R-1-2', 'R-2-3', 'R-3-50', 'O', 'O', 'R-2-50', 'R-2-3', 'R-1-2', 'R-3-50', 'R-3-4', 'O', 'O', 'R-5-4', 'R-5-50', 'O', 'R-5-6', 'O', 'R-5-50', 'R-6-50', 'R-5-6', 'R-6-50', 'O', 'O', 'R-4-5', 'O', 'R-3-50', 'R-2-3', 'R-1-2', 'R-1-50', 'R-1-50', 'R-12-3', 'O', 'R-12-3', 'R-5-12', 'O', 'R-6-50', 'O', 'R-5-50', 'R-5-50', 'R-4-5', 'R-3-4', 'R-5-50', 'R-1-50', 'R-2-50', 'O', 'O', 'O', 'R-5-50', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'R-3-50', 'R-1-50', 'R-1-2', 'R-1-3', 'R-3-50', 'R-5-6', 'R-5-6', 'R-6-50', 'O', 'O', 'R-12-3', 'O', 'R-1-50', 'R-2-50', 'R-2-50', 'O', 'O', 'R-5-6', 'R-4-5', 'O', 'O', 'O', 'R-2-50', 'R-2-50', 'R-2-3', 'R-2-11', 'R-2-3', 'R-3-11', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-12-3', 'R-4-5', 'R-4-5', 'O', 'R-6-50', 'R-5-50', 'O', 'O', 'O', 'O', 'R-4-5', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'O', 'R-1-3', 'R-1-2', 'R-2-3', 'R-5-6', 'R-6-50', 'R-5-50', 'R-5-50', 'R-3-50', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-2-50', 'R-1-50', 'R-2-50', 'R-1-2', 'R-1-2', 'R-1-50', 'R-5-50', 'O', 'R-5-50', 'O', 'O', 'R-2-50', 'R-1-2', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'O', 'R-1-50', 'R-1-50', 'R-1-2', 'O', 'O', 'O', 'O', 'O', 'R-12-3', 'R-1-50', 'R-2-50', 'R-2-50', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-2', 'O', 'R-1-5', 'O', 'R-12-3', 'O', 'O', 'O', 'O', 'R-1-50', 'R-1-2', 'R-1-50', 'R-1-5', 'R-5-50', 'R-5-6', 'R-6-50', 'R-3-5', 'R-2-5', 'R-1-2', 'O', 'O', 'O', 'R-3-50', 'R-2-50', 'R-3-50', 'R-2-50', 'R-1-50', 'R-1-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-2-50', 'O', 'R-5-50', 'R-2-50', 'R-5-50', 'R-1-50', 'R-2-50', 'R-1-50', 'R-1-2', 'O', 'R-2-3', 'R-5-50', 'R-4-5', 'O', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-50', 'R-3-4', 'R-2-50', 'R-1-2', 'R-1-2', 'R-1-2', 'R-2-3', 'O', 'O', 'R-3-50', 'R-3-50', 'R-2-3', 'R-1-50', 'R-1-2', 'R-2-3', 'R-3-4', 'R-3-2', 'R-4-50', 'R-4-50', 'R-5-50', 'R-5-50', 'R-5-4', 'R-5-6', 'R-6-50', 'O', 'R-1-50', 'R-2-50', 'R-1-50', 'R-1-2', 'O', 'O', 'O', 'O', 'R-2-3', 'R-3-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-12-3', 'O', 'R-2-50', 'O', 'R-2-50', 'R-1-2', 'R-1-2', 'R-2-50', 'O', 'O', 'R-5-6', 'O', 'R-2-50', 'R-3-50', 'R-3-50', 'R-2-3', 'R-1-3', 'R-3-50', 'O', 'R-5-50', 'O', 'R-5-6', 'O', 'O', 'R-5-6', 'R-6-50', 'O', 'R-2-3', 'O', 'R-5-6', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'R-2-50', 'O', 'O', 'O', 'O', 'R-2-5', 'R-4-5', 'O', 'R-5-50', 'O', 'O', 'O', 'O', 'R-2-5', 'R-6-50', 'R-4-50', 'R-2-50', 'R-1-50', 'R-6-50', 'R-4-50', 'R-2-50', 'R-1-50', 'R-1-2', 'R-2-3', 'R-2-3', 'R-3-50', 'R-3-4', 'R-12-3', 'R-12-3', 'R-3-4', 'R-6-50', 'O', 'O', 'R-6-50', 'O', 'O', 'R-12-50', 'R-2-50', 'O', 'O', 'R-1-2', 'R-12-2', 'R-12-3', 'R-3-4', 'R-4-50', 'O', 'O', 'O', 'O', 'R-11-12', 'R-12-3', 'R-5-6', 'R-6-50', 'O', 'R-1-2', 'R-1-2', 'R-1-2', 'R-2-3', 'O', 'R-1-50', 'R-5-50', 'O', 'O', 'R-1-50', 'R-1-50', 'R-1-2', 'R-1-3', 'R-2-50', 'O', 'R-5-50', 'R-5-4', 'R-11-12', 'R-12-5', 'O', 'R-2-50', 'R-1-2', 'R-1-2', 'R-1-50', 'O', 'O', 'R-5-50', 'O', 'R-5-6', 'R-6-50', 'R-6-50', 'O', 'O', 'O', 'R-3-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'O', 'O', 'O', 'O', 'R-4-5', 'O', 'O', 'O', 'R-2-50', 'R-2-50', 'O', 'O', 'R-2-50', 'O', 'R-2-50', 'R-1-50', 'R-1-2', 'R-1-2', 'R-2-50', 'R-2-5', 'O', 'R-2-5', 'R-5-6', 'R-6-50', 'O', 'R-5-6', 'R-5-50', 'R-4-5', 'R-5-6', 'O', 'O', 'R-12-3', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-5-4', 'R-2-50', 'R-3-4', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'O', 'O', 'R-5-6', 'R-6-50', 'R-6-50', 'R-5-5', 'R-2-50', 'R-1-50', 'R-1-2', 'R-3-50', 'R-3-50', 'O', 'R-5-50', 'R-3-5', 'O', 'O', 'R-5-50', 'R-2-50', 'R-5-50', 'R-5-50', 'R-2-50', 'R-1-2', 'O', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'R-2-50', 'R-2-50', 'R-2-50', 'O', 'O', 'O', 'O', 'R-3-4', 'R-11-12', 'R-12-3', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'R-3-50', 'O', 'O', 'R-5-50', 'R-5-4', 'R-5-6', 'O', 'O', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'R-5-6', 'R-5-50', 'R-5-50', 'R-5-50', 'R-2-50', 'R-3-50', 'O', 'O', 'O', 'O', 'R-1-2', 'R-2-3', 'O', 'R-12-3', 'R-11-12', 'R-12-3', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-4-5', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'O', 'O', 'O', 'R-5-50', 'R-4-5', 'R-4-5', 'O', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-50', 'R-3-4', 'R-3-4', 'R-5-6', 'R-6-50', 'R-1-3', 'R-3-50', 'R-1-2', 'R-2-50', 'R-1-2', 'R-1-50', 'R-1-50', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-11-12', 'R-12-3', 'O', 'R-11-12', 'R-12-3', 'R-11-12', 'R-12-3', 'R-3-5', 'O', 'R-5-6', 'R-6-50', 'O', 'R-3-50', 'R-12-3', 'R-11-12', 'R-11-50', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'O', 'O', 'R-3-50', 'R-1-3', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-2-50', 'O', 'R-1-3', 'R-1-2', 'O', 'O', 'O', 'O', 'R-1-50', 'R-3-50', 'R-2-3', 'R-3-50', 'R-2-3', 'O', 'O', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'O', 'R-2-50', 'R-5-50', 'R-5-50', 'R-2-50', 'R-1-50', 'R-2-50', 'R-1-50', 'O', 'R-2-1', 'R-1-2', 'R-2-50', 'R-1-2', 'R-2-50', 'R-1-50', 'R-1-50', 'R-1-2', 'R-2-3', 'R-4-50', 'O', 'R-4-50', 'R-12-3', 'R-3-50', 'R-5-50', 'R-5-4', 'R-5-6', 'R-6-50', 'R-5-50', 'R-5-50', 'R-5-50', 'R-5-50', 'R-1-50', 'R-1-2', 'R-2-5', 'O', 'O', 'O', 'R-6-50', 'O', 'O', 'R-2-50', 'O', 'O', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'R-2-4', 'R-4-5', 'R-5-6', 'R-5-6', 'R-6-50', 'R-5-50', 'R-3-50', 'R-2-4', 'R-4-50', 'R-3-50', 'R-3-4', 'R-11-12', 'R-12-3', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-6', 'R-6-50', 'R-6-50', 'R-3-50', 'R-5-6', 'R-3-50', 'R-3-50', 'R-1-2', 'R-2-3', 'O', 'O', 'O', 'O', 'R-2-4', 'R-4-6', 'R-11-12', 'R-12-3', 'R-3-4', 'O', 'O', 'R-2-50', 'R-5-50', 'O', 'R-2-50', 'O', 'O', 'O', 'R-1-2', 'O', 'O', 'R-2-50', 'R-5-50', 'R-2-50', 'R-5-50', 'O', 'R-1-50', 'R-1-50', 'R-1-2', 'R-1-2', 'R-2-3', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'O', 'R-1-2', 'R-2-3', 'O', 'O', 'R-5-50', 'R-5-6', 'R-5-6', 'R-6-50', 'R-11-12', 'R-12-3', 'O', 'R-1-3', 'R-1-2', 'R-1-2', 'R-1-3', 'R-3-50', 'O', 'O', 'R-1-50', 'R-1-5', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'O', 'O', 'R-2-50', 'R-1-50', 'R-1-2', 'R-2-50', 'R-5-50', 'R-2-5', 'R-5-50', 'O', 'R-2-50', 'R-2-50', 'R-1-50', 'R-1-2', 'R-2-50', 'R-1-2', 'O', 'R-2-5', 'O', 'R-1-3', 'O', 'O', 'O', 'R-3-50', 'R-2-3', 'R-1-2', 'R-5-50', 'R-2-4', 'R-4-5', 'O', 'R-6-50', 'R-2-50', 'O', 'O', 'R-2-50', 'O', 'R-2-3', 'R-12-3', 'O', 'R-3-4', 'R-4-50', 'R-5-50', 'R-5-6', 'R-6-50', 'O', 'R-4-6', 'R-5-6', 'R-2-50', 'R-3-50', 'R-5-50', 'O', 'O', 'O', 'R-5-50', 'R-4-5', 'R-6-5', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'R-2-50', 'R-3-50', 'R-5-50', 'R-2-50', 'R-3-50', 'R-5-50', 'O', 'O', 'R-5-50', 'O', 'O', 'R-5-50', 'R-3-50', 'R-1-3', 'R-2-3', 'R-3-4', 'O', 'R-2-50', 'O', 'O', 'R-2-4', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-3-50', 'R-2-3', 'R-1-2', 'R-2-3', 'R-3-50', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'O', 'O', 'R-2-3', 'R-3-4', 'R-2-50', 'R-2-50', 'R-3-4', 'R-5-50', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'R-3-50', 'R-5-50', 'R-3-50', 'R-5-50', 'R-5-6', 'R-5-50', 'R-2-50', 'R-1-50', 'R-1-2', 'R-2-50', 'O', 'R-5-50', 'R-4-50', 'R-2-5', 'R-5-50', 'R-50-1', 'R-4-50', 'R-1-50', 'O', 'R-2-50', 'O', 'R-5-50', 'R-5-6', 'R-6-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'O', 'O', 'O', 'R-1-50', 'R-1-2', 'R-2-50', 'R-2-50', 'R-1-2', 'R-1-50', 'R-1-2', 'R-2-3', 'O', 'R-12-3', 'O', 'R-3-5', 'R-11-12', 'R-11-12', 'R-12-3', 'R-11-12', 'R-12-3', 'R-5-50', 'R-5-6', 'O', 'R-5-5', 'R-5-50', 'R-5-50', 'R-5-50', 'R-11-50', 'R-1-50', 'R-1-50', 'R-11-50', 'R-5-50', 'O', 'O', 'O', 'O', 'R-5-4', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'R-3-50', 'R-1-50', 'R-12-3', 'R-3-4', 'O', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-2', 'O', 'O', 'R-12-3', 'O', 'R-4-5', 'R-5-6', 'R-5-6', 'R-11-12', 'R-12-3', 'O', 'R-5-6', 'R-5-50', 'R-5-50', 'R-4-5', 'R-5-6', 'O', 'O', 'R-5-6', 'R-6-50', 'O', 'R-2-50', 'O', 'R-5-50', 'O', 'R-1-2', 'R-2-50', 'O', 'O', 'R-2-50', 'R-2-50', 'R-1-2', 'O', 'O', 'R-12-3', 'R-50-5', 'O', 'R-5-50', 'R-1-50', 'O', 'O', 'O', 'R-2-5', 'R-2-50', 'O', 'O', 'R-2-4', 'O', 'R-1-2', 'R-2-3', 'O', 'O', 'O', 'R-1-50', 'R-3-50', 'R-5-50', 'R-5-50', 'R-3-50', 'R-1-50', 'R-5-50', 'R-6-50', 'R-1-50', 'R-1-2', 'R-2-3', 'R-3-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-3', 'R-3-4', 'R-4-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-5-50', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-5-6', 'O', 'O', 'O', 'R-3-50', 'O', 'R-1-50', 'R-5-50', 'R-1-2', 'R-5-50', 'O', 'O', 'R-5-6', 'R-6-50', 'O', 'O', 'R-2-3', 'R-3-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-2-50', 'O', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-1-3', 'R-1-2', 'R-2-3', 'R-2-3', 'R-3-50', 'R-1-2', 'R-1-3', 'O', 'O', 'O', 'R-3-4', 'O', 'O', 'O', 'R-11-12', 'R-11-12', 'R-12-3', 'R-3-50', 'R-3-50', 'O', 'R-6-50', 'R-5-6', 'O', 'R-5-50', 'R-6-50', 'O', 'O', 'O', 'O', 'O', 'R-5-50', 'R-1-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'R-12-50', 'R-5-50', 'R-5-50', 'R-5-6', 'R-6-50', 'O', 'O', 'O', 'R-2-5', 'R-2-4', 'R-4-50', 'R-12-50', 'R-1-50', 'R-1-2', 'R-2-4', 'R-4-50', 'O', 'O', 'R-6-50', 'O', 'R-5-50', 'O', 'R-4-5', 'R-6-50', 'O', 'R-3-50', 'R-3-4', 'R-11-12', 'R-12-3', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-2-50', 'R-1-2', 'R-2-4', 'R-1-2', 'R-1-2', 'O', 'R-3-4', 'O', 'R-11-12', 'R-11-12', 'R-12-3', 'O', 'O', 'O', 'O', 'O', 'R-5-6', 'R-4-5', 'R-5-6', 'R-2-50', 'O', 'O', 'O', 'O', 'O', 'O', 'R-1-50', 'R-3-50', 'R-5-50', 'O', 'R-1-2', 'R-2-50', 'R-3-50', 'R-1-3', 'R-1-2', 'R-1-50', 'R-1-3', 'R-1-2', 'R-3-50', 'R-3-5', 'R-5-50', 'O', 'R-5-50', 'R-5-4', 'R-5-4', 'O', 'O', 'R-3-50', 'R-2-3', 'R-1-3', 'R-3-50', 'O', 'R-5-50', 'R-2-50', 'O', 'O', 'O', 'R-3-50', 'R-3-50', 'R-2-3', 'R-1-3', 'R-1-3', 'R-3-50', 'R-1-50', 'R-3-4', 'R-4-50', 'R-5-50', 'R-4-5', 'O', 'R-6-50', 'R-5-50', 'R-5-50', 'O', 'O', 'R-5-50', 'R-5-50', 'O', 'O', 'O', 'O', 'R-2-50', 'R-1-50', 'R-2-50', 'R-2-3', 'R-3-4', 'R-4-50', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New labels:  [0, 0, 0, 0, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 4, 0, 5, 0, 6, 0, 0, 0, 0, 0, 7, 7, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 8, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 9, 0, 1, 10, 11, 0, 4, 0, 5, 0, 11, 0, 9, 3, 7, 0, 0, 0, 3, 0, 0, 0, 12, 3, 7, 0, 3, 7, 3, 11, 0, 11, 8, 0, 0, 0, 11, 9, 0, 6, 10, 0, 10, 1, 0, 5, 0, 4, 10, 0, 9, 11, 11, 11, 0, 0, 6, 13, 6, 0, 8, 8, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 1, 7, 14, 1, 11, 15, 0, 6, 13, 0, 0, 0, 3, 7, 1, 7, 4, 16, 17, 2, 16, 11, 6, 8, 8, 6, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 12, 0, 0, 0, 0, 1, 4, 5, 3, 0, 0, 0, 0, 0, 0, 11, 7, 4, 9, 5, 18, 5, 11, 11, 0, 7, 7, 7, 14, 3, 9, 0, 0, 0, 0, 11, 0, 0, 0, 7, 11, 1, 6, 13, 0, 11, 11, 7, 0, 7, 8, 6, 13, 11, 0, 0, 7, 0, 2, 0, 1, 7, 0, 4, 1, 11, 6, 8, 6, 0, 0, 6, 13, 11, 8, 0, 0, 11, 9, 0, 0, 0, 13, 0, 11, 11, 8, 0, 6, 13, 0, 0, 0, 0, 3, 9, 11, 4, 1, 4, 0, 11, 0, 0, 0, 0, 19, 6, 11, 3, 7, 11, 14, 20, 13, 6, 7, 0, 0, 1, 7, 7, 0, 7, 4, 0, 0, 0, 0, 0, 0, 1, 3, 5, 0, 11, 13, 0, 6, 13, 0, 11, 11, 0, 0, 0, 13, 6, 6, 0, 11, 0, 7, 1, 0, 0, 0, 0, 5, 11, 9, 0, 0, 7, 0, 0, 0, 0, 0, 11, 8, 6, 0, 0, 6, 13, 20, 11, 8, 11, 0, 9, 8, 0, 0, 0, 0, 3, 14, 12, 0, 0, 0, 11, 6, 13, 11, 19, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 11, 11, 8, 8, 11, 0, 0, 11, 19, 19, 10, 9, 0, 0, 0, 0, 0, 0, 7, 0, 7, 1, 1, 10, 21, 0, 0, 11, 10, 0, 0, 0, 0, 11, 6, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 12, 4, 5, 5, 1, 0, 0, 7, 7, 6, 13, 6, 10, 13, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 9, 5, 0, 0, 9, 6, 13, 0, 6, 13, 13, 0, 0, 0, 9, 11, 9, 7, 0, 9, 7, 0, 4, 0, 6, 0, 19, 5, 20, 0, 0, 5, 8, 12, 0, 0, 13, 6, 0, 11, 8, 6, 13, 6, 11, 0, 0, 0, 0, 0, 0, 1, 22, 13, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 2, 8, 6, 0, 0, 0, 0, 7, 9, 0, 0, 0, 5, 11, 11, 6, 13, 11, 0, 16, 11, 3, 3, 3, 16, 11, 11, 16, 16, 0, 0, 0, 0, 0, 0, 1, 3, 7, 0, 0, 0, 6, 13, 0, 0, 0, 11, 6, 13, 6, 11, 11, 9, 5, 0, 3, 1, 0, 0, 0, 9, 7, 7, 13, 0, 1, 0, 0, 0, 1, 7, 4, 2, 6, 13, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 11, 6, 13, 6, 0, 0, 0, 0, 0, 3, 11, 11, 23, 8, 0, 0, 6, 13, 0, 11, 3, 1, 1, 0, 4, 5, 0, 11, 3, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 24, 4, 0, 1, 24, 1, 25, 11, 13, 20, 1, 24, 7, 0, 6, 13, 0, 11, 10, 4, 1, 3, 0, 3, 9, 11, 0, 3, 9, 11, 3, 9, 1, 4, 9, 11, 9, 4, 5, 11, 19, 20, 6, 6, 11, 6, 0, 0, 0, 0, 1, 1, 3, 7, 7, 0, 7, 9, 0, 0, 0, 0, 13, 11, 0, 0, 0, 0, 0, 0, 4, 1, 1, 4, 23, 8, 0, 0, 0, 6, 13, 0, 0, 0, 0, 0, 0, 0, 0, 8, 6, 0, 0, 0, 0, 0, 8, 0, 7, 1, 1, 6, 13, 3, 7, 11, 11, 11, 0, 0, 3, 24, 1, 5, 20, 11, 0, 6, 13, 0, 0, 0, 0, 7, 0, 0, 0, 0, 3, 5, 24, 4, 1, 7, 23, 5, 6, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 2, 17, 17, 2, 0, 0, 6, 8, 6, 0, 0, 0, 6, 13, 6, 0, 7, 4, 0, 0, 0, 0, 7, 1, 0, 1, 1, 1, 7, 0, 17, 17, 2, 3, 3, 0, 0, 0, 0, 2, 0, 5, 0, 7, 7, 9, 0, 5, 0, 7, 6, 8, 6, 13, 0, 0, 0, 1, 0, 1, 3, 1, 17, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 24, 0, 0, 0, 0, 0, 0, 13, 7, 3, 7, 0, 0, 7, 1, 1, 7, 0, 1, 11, 6, 13, 0, 0, 9, 0, 7, 1, 0, 11, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0, 5, 22, 6, 13, 0, 6, 7, 12, 0, 20, 13, 7, 7, 1, 0, 11, 0, 0, 0, 1, 0, 7, 4, 5, 0, 5, 20, 13, 0, 0, 0, 0, 0, 0, 17, 2, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 11, 17, 2, 23, 6, 6, 13, 14, 8, 11, 26, 0, 3, 3, 7, 4, 5, 12, 0, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 0, 8, 14, 14, 0, 0, 0, 11, 11, 11, 0, 0, 0, 3, 0, 3, 16, 1, 10, 10, 6, 3, 2, 0, 0, 3, 0, 0, 16, 11, 3, 9, 7, 3, 0, 0, 0, 0, 9, 5, 0, 11, 19, 19, 11, 0, 0, 0, 3, 7, 14, 0, 5, 0, 0, 0, 0, 0, 0, 11, 6, 0, 0, 0, 0, 0, 6, 13, 0, 6, 11, 11, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 5, 8, 0, 0, 0, 0, 8, 6, 3, 7, 1, 1, 1, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 9, 9, 0, 1, 4, 0, 0, 0, 0, 0, 3, 27, 14, 1, 11, 0, 2, 17, 11, 0, 9, 0, 5, 0, 11, 6, 13, 11, 9, 0, 0, 0, 0, 0, 0, 0, 0, 2, 17, 28, 0, 0, 8, 6, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 8, 6, 0, 0, 6, 13, 3, 1, 7, 3, 4, 5, 13, 29, 23, 9, 0, 4, 5, 2, 0, 0, 7, 3, 11, 5, 11, 0, 0, 3, 9, 7, 3, 1, 24, 0, 0, 0, 0, 0, 0, 0, 11, 6, 13, 0, 1, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 11, 16, 3, 16, 11, 0, 7, 17, 7, 21, 2, 30, 0, 15, 0, 1, 31, 10, 11, 11, 0, 13, 0, 16, 3, 11, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 32, 11, 11, 3, 0, 0, 0, 0, 11, 0, 0, 6, 13, 11, 6, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 10, 8, 0, 6, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 6, 13, 11, 16, 3, 3, 3, 16, 17, 2, 16, 11, 11, 11, 16, 3, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 11, 6, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 6, 13, 8, 6, 11, 0, 0, 0, 9, 11, 5, 5, 20, 9, 5, 11, 6, 13, 13, 0, 0, 4, 24, 5, 0, 5, 22, 10, 11, 6, 8, 6, 0, 6, 13, 6, 11, 7, 9, 4, 5, 10, 0, 13, 7, 11, 11, 11, 11, 3, 3, 3, 9, 7, 11, 0, 0, 0, 9, 2, 4, 17, 20, 0, 0, 3, 1, 4, 14, 8, 6, 6, 13, 11, 0, 0, 0, 11, 6, 0, 11, 6, 13, 3, 7, 12, 1, 3, 8, 0, 6, 0, 0, 0, 0, 0, 11, 16, 7, 1, 29, 9, 1, 4, 5, 12, 6, 13, 0, 7, 9, 0, 3, 7, 1, 3, 17, 32, 17, 2, 16, 19, 19, 13, 11, 7, 7, 0, 0, 0, 0, 0, 0, 0, 17, 2, 0, 0, 16, 17, 2, 16, 16, 11, 11, 13, 0, 0, 1, 1, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 11, 13, 6, 1, 7, 0, 0, 0, 0, 0, 9, 9, 24, 3, 2, 5, 0, 0, 0, 1, 1, 0, 0, 10, 8, 8, 0, 6, 13, 7, 33, 1, 33, 4, 24, 1, 7, 9, 0, 0, 0, 8, 5, 6, 13, 0, 4, 1, 5, 20, 13, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0, 0, 2, 17, 17, 2, 6, 11, 6, 0, 11, 11, 0, 0, 0, 0, 0, 0, 0, 1, 34, 0, 0, 5, 17, 2, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 13, 0, 0, 0, 0, 1, 7, 7, 0, 5, 17, 2, 0, 8, 6, 6, 13, 0, 0, 0, 0, 0, 0, 8, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 5, 1, 3, 4, 0, 17, 2, 16, 35, 13, 12, 0, 0, 0, 0, 11, 11, 11, 0, 0, 7, 0, 11, 4, 5, 9, 14, 11, 0, 0, 0, 7, 1, 0, 14, 8, 6, 3, 9, 24, 16, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 14, 7, 6, 13, 0, 11, 0, 1, 1, 0, 0, 2, 0, 0, 11, 3, 10, 11, 12, 14, 6, 13, 3, 9, 9, 4, 0, 7, 3, 0, 0, 0, 0, 0, 0, 0, 0, 13, 0, 0, 0, 7, 1, 0, 0, 2, 0, 11, 6, 13, 8, 11, 0, 3, 1, 1, 4, 11, 8, 6, 13, 0, 0, 0, 0, 0, 0, 8, 0, 0, 9, 9, 9, 2, 16, 7, 1, 11, 12, 0, 0, 0, 0, 0, 5, 0, 36, 13, 13, 0, 0, 0, 0, 1, 0, 11, 0, 11, 0, 1, 7, 10, 0, 17, 2, 0, 11, 13, 6, 0, 7, 3, 3, 7, 11, 0, 0, 1, 0, 0, 9, 11, 3, 7, 7, 1, 0, 0, 0, 7, 5, 11, 23, 13, 7, 4, 0, 5, 22, 25, 11, 11, 11, 11, 0, 6, 13, 6, 0, 7, 7, 7, 9, 5, 9, 29, 0, 11, 9, 0, 5, 0, 0, 0, 0, 0, 19, 6, 13, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 8, 6, 4, 9, 4, 11, 10, 11, 0, 4, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 29, 9, 1, 11, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 8, 20, 0, 20, 13, 13, 11, 11, 9, 11, 9, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 17, 17, 2, 17, 2, 11, 0, 8, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 7, 1, 10, 8, 0, 0, 6, 13, 6, 7, 7, 1, 0, 0, 10, 6, 13, 0, 22, 11, 9, 0, 9, 4, 10, 0, 0, 0, 0, 19, 14, 0, 0, 0, 0, 0, 3, 7, 1, 15, 1, 4, 9, 1, 0, 2, 17, 2, 17, 2, 11, 8, 0, 6, 13, 11, 11, 6, 13, 0, 0, 0, 0, 0, 0, 1, 0, 9, 7, 7, 3, 0, 17, 17, 2, 13, 20, 19, 11, 0, 0, 0, 0, 0, 1, 11, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 8, 6, 13, 0, 2, 0, 6, 13, 0, 0, 0, 0, 0, 0, 0, 0, 11, 7, 12, 0, 0, 1, 34, 0, 0, 6, 13, 11, 11, 0, 10, 11, 10, 0, 3, 1, 1, 3, 0, 0, 3, 7, 7, 1, 7, 7, 11, 7, 3, 0, 0, 0, 0, 7, 1, 0, 0, 0, 0, 0, 0, 7, 3, 0, 1, 1, 1, 7, 11, 0, 19, 20, 6, 13, 11, 11, 8, 0, 0, 7, 0, 9, 5, 4, 4, 24, 1, 7, 11, 19, 12, 12, 8, 13, 9, 4, 0, 9, 3, 11, 9, 3, 11, 1, 5, 6, 13, 11, 9, 3, 0, 0, 0, 0, 0, 8, 6, 19, 5, 5, 12, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 9, 9, 0, 0, 0, 23, 23, 10, 0, 4, 9, 23, 16, 0, 16, 7, 0, 0, 3, 3, 11, 3, 3, 11, 11, 11, 3, 11, 7, 1, 7, 7, 0, 1, 4, 5, 9, 17, 32, 15, 11, 6, 13, 9, 3, 0, 4, 3, 17, 2, 17, 2, 6, 13, 0, 33, 14, 9, 5, 0, 0, 0, 0, 11, 8, 0, 0, 6, 11, 11, 11, 0, 0, 1, 7, 11, 0, 17, 21, 0, 11, 0, 0, 0, 0, 0, 0, 0, 7, 9, 9, 4, 1, 0, 0, 0, 0, 2, 17, 2, 0, 0, 0, 0, 0, 11, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 1, 4, 9, 11, 11, 8, 14, 13, 6, 11, 0, 0, 3, 7, 11, 0, 3, 7, 11, 1, 0, 1, 4, 9, 11, 0, 0, 0, 13, 11, 0, 5, 4, 20, 6, 6, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 3, 1, 4, 11, 6, 13, 11, 0, 0, 7, 11, 0, 0, 0, 0, 7, 9, 5, 8, 6, 9, 7, 0, 0, 0, 0, 0, 0, 0, 0, 11, 13, 25, 23, 5, 0, 3, 0, 0, 0, 0, 9, 0, 0, 13, 11, 8, 9, 0, 0, 11, 0, 0, 0, 0, 1, 0, 0, 8, 14, 11, 6, 13, 0, 0, 0, 0, 0, 11, 16, 7, 3, 11, 16, 7, 3, 3, 0, 16, 11, 11, 11, 11, 0, 0, 0, 0, 0, 6, 13, 0, 0, 0, 11, 11, 0, 0, 0, 0, 0, 0, 0, 0, 10, 11, 24, 1, 24, 1, 4, 0, 0, 0, 0, 16, 3, 3, 1, 9, 0, 17, 17, 2, 9, 4, 9, 5, 0, 11, 20, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 2, 8, 6, 0, 0, 0, 0, 0, 1, 7, 3, 7, 11, 6, 11, 0, 7, 0, 7, 4, 5, 0, 17, 21, 3, 1, 7, 0, 0, 11, 9, 3, 6, 13, 0, 11, 5, 0, 1, 7, 4, 5, 3, 0, 0, 1, 1, 7, 5, 12, 12, 17, 2, 0, 6, 13, 13, 0, 0, 0, 0, 7, 0, 23, 0, 6, 13, 0, 0, 0, 0, 0, 3, 1, 7, 0, 0, 0, 11, 0, 0, 0, 11, 6, 13, 4, 0, 0, 0, 0, 4, 0, 29, 29, 17, 17, 2, 0, 0, 11, 11, 11, 11, 11, 3, 24, 5, 1, 1, 0, 0, 0, 0, 0, 12, 5, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 6, 13, 0, 0, 0, 8, 14, 14, 12, 0, 3, 1, 14, 12, 1, 0, 13, 11, 0, 0, 7, 10, 37, 19, 3, 7, 3, 14, 12, 0, 0, 0, 0, 3, 1, 10, 10, 19, 11, 11, 3, 13, 11, 3, 11, 9, 3, 11, 9, 9, 3, 11, 3, 1, 1, 0, 0, 0, 3, 9, 1, 10, 11, 13, 16, 0, 0, 0, 0, 0, 24, 1, 7, 9, 9, 7, 0, 5, 11, 0, 0, 0, 13, 0, 0, 9, 9, 4, 7, 6, 22, 0, 11, 6, 13, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 23, 11, 5, 4, 0, 0, 0, 6, 13, 0, 1, 0, 0, 0, 0, 0, 8, 11, 1, 4, 23, 11, 23, 0, 0, 0, 0, 0, 3, 7, 7, 1, 14, 11, 6, 13, 0, 0, 0, 24, 5, 0, 16, 11, 9, 16, 7, 6, 13, 6, 13, 0, 0, 17, 2, 9, 4, 0, 17, 2, 1, 0, 0, 11, 3, 1, 3, 6, 8, 6, 0, 0, 0, 11, 11, 0, 0, 3, 1, 0, 1, 3, 1, 7, 3, 13, 6, 6, 13, 20, 6, 13, 13, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 6, 13, 0, 0, 0, 7, 1, 14, 0, 0, 0, 0, 8, 6, 14, 0, 6, 13, 6, 11, 11, 17, 2, 0, 17, 2, 0, 0, 0, 7, 11, 0, 0, 0, 3, 0, 0, 24, 0, 5, 0, 0, 0, 0, 0, 9, 7, 1, 3, 0, 0, 0, 1, 5, 4, 9, 0, 0, 0, 0, 0, 0, 7, 1, 1, 0, 9, 4, 15, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 17, 2, 0, 0, 24, 1, 24, 8, 0, 0, 0, 13, 11, 11, 0, 9, 3, 7, 11, 3, 7, 11, 9, 3, 7, 1, 1, 7, 11, 11, 11, 6, 13, 0, 9, 4, 11, 6, 8, 6, 6, 13, 0, 0, 0, 11, 9, 11, 9, 0, 0, 0, 0, 0, 0, 0, 0, 9, 14, 11, 6, 13, 19, 4, 9, 0, 0, 0, 0, 0, 0, 0, 9, 4, 3, 1, 3, 2, 17, 2, 0, 17, 2, 17, 2, 11, 0, 11, 11, 0, 0, 0, 3, 1, 7, 1, 7, 9, 0, 9, 11, 0, 0, 6, 13, 13, 11, 7, 7, 11, 0, 1, 0, 7, 0, 0, 10, 0, 0, 0, 10, 0, 0, 0, 7, 0, 0, 0, 0, 1, 7, 0, 0, 2, 5, 0, 0, 11, 11, 11, 0, 0, 0, 0, 0, 0, 0, 0, 6, 13, 0, 0, 0, 0, 0, 0, 0, 11, 11, 0, 0, 0, 11, 8, 0, 0, 11, 0, 0, 0, 0, 3, 0, 0, 3, 4, 9, 6, 13, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 11, 6, 13, 10, 8, 0, 2, 0, 0, 0, 7, 7, 0, 7, 3, 11, 9, 11, 8, 0, 13, 9, 9, 2, 17, 2, 17, 2, 9, 3, 3, 1, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 2, 8, 6, 0, 0, 6, 13, 3, 11, 3, 24, 9, 11, 11, 11, 11, 11, 3, 0, 0, 7, 7, 0, 11, 0, 0, 0, 0, 0, 0, 11, 11, 0, 0, 0, 0, 0, 4, 5, 0, 17, 2, 17, 17, 2, 8, 6, 13, 0, 0, 0, 3, 1, 7, 7, 9, 17, 17, 2, 0, 6, 13, 11, 11, 3, 7, 3, 11, 10, 1, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 7, 4, 1, 4, 5, 20, 2, 0, 17, 2, 16, 7, 3, 0, 0, 0, 0, 0, 11, 11, 6, 0, 0, 0, 0, 0, 0, 7, 7, 0, 1, 1, 0, 9, 0, 0, 7, 0, 5, 0, 13, 6, 0, 0, 0, 0, 7, 14, 12, 0, 0, 0, 7, 1, 0, 15, 11, 6, 13, 10, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 17, 17, 2, 8, 6, 6, 13, 8, 8, 0, 0, 0, 0, 8, 0, 0, 0, 2, 0, 0, 7, 10, 31, 0, 0, 0, 7, 1, 0, 0, 0, 17, 21, 11, 11, 0, 0, 0, 0, 0, 3, 11, 9, 1, 5, 8, 6, 6, 13, 11, 11, 11, 3, 0, 11, 8, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 11, 0, 0, 0, 0, 6, 13, 0, 11, 0, 0, 0, 5, 0, 13, 0, 0, 0, 0, 0, 3, 1, 1, 3, 3, 1, 0, 0, 8, 6, 11, 11, 9, 9, 4, 11, 10, 0, 2, 0, 0, 7, 1, 4, 0, 3, 11, 11, 15, 13, 6, 0, 11, 7, 0, 0, 0, 5, 17, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 1, 7, 7, 0, 14, 11, 13, 0, 7, 0, 0, 0, 0, 0, 11, 6, 0, 0, 0, 0, 0, 7, 0, 0, 7, 10, 0, 0, 0, 0, 0, 0, 10, 0, 0, 0, 0, 0, 11, 10, 1, 0, 0, 0, 11, 11, 0, 0, 0, 3, 0, 21, 0, 0, 0, 9, 19, 11, 0, 38, 0, 0, 0, 3, 7, 0, 9, 0, 16, 17, 2, 3, 1, 1, 4, 4, 0, 3, 0, 0, 0, 6, 13, 3, 9, 22, 22, 13, 6, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 39, 10, 8, 0, 10, 0, 0, 7, 0, 0, 0, 0, 0, 7, 0, 11, 11, 0, 9, 12, 0, 0, 7, 0, 8, 11, 0, 9, 20, 13, 11, 24, 1, 9, 7, 0, 5, 20, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 1, 0, 1, 1, 3, 1, 0, 0, 10, 0, 0, 0, 9, 23, 23, 6, 11, 0, 0, 3, 0, 0, 3, 1, 3, 9, 0, 0, 1, 7, 0, 11, 7, 0, 11, 3, 7, 7, 3, 3, 3, 0, 0, 0, 0, 0, 1, 4, 5, 0, 8, 0, 0, 11, 6, 13, 9, 4, 9, 7, 0, 0, 0, 0, 0, 17, 2, 0, 14, 8, 0, 6, 13, 11, 7, 3, 7, 3, 0, 7, 0, 3, 0, 0, 0, 0, 0, 0, 0, 7, 3, 0, 7, 3, 6, 6, 13, 6, 0, 0, 0, 0, 0, 0, 0, 8, 0, 9, 4, 0, 9, 0, 0, 0, 0, 9, 4, 9, 24, 3, 1, 3, 11, 8, 0, 11, 9, 9, 5, 0, 0, 11, 0, 7, 21, 3, 7, 0, 7, 1, 0, 1, 24, 2, 10, 11, 13, 11, 9, 7, 0, 0, 12, 0, 0, 0, 3, 3, 3, 2, 0, 6, 8, 0, 0, 0, 0, 10, 11, 11, 8, 0, 0, 0, 1, 0, 0, 0, 0, 0, 19, 11, 0, 6, 13, 11, 3, 1, 7, 0, 9, 12, 11, 9, 3, 0, 0, 0, 7, 0, 30, 7, 19, 6, 13, 0, 0, 0, 0, 0, 40, 0, 0, 0, 0, 0, 14, 5, 0, 5, 4, 4, 9, 0, 17, 2, 17, 0, 9, 9, 3, 1, 4, 0, 3, 1, 7, 3, 7, 11, 10, 11, 0, 13, 0, 29, 0, 0, 0, 0, 0, 0, 0, 0, 17, 2, 11, 8, 6, 13, 11, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 7, 24, 9, 1, 4, 0, 6, 13, 0, 0, 0, 2, 5, 1, 3, 6, 13, 0, 0, 7, 7, 0, 1, 7, 3, 0, 17, 2, 9, 7, 1, 1, 7, 7, 7, 0, 11, 19, 20, 0, 5, 9, 0, 5, 41, 3, 7, 1, 3, 0, 0, 0, 0, 7, 9, 22, 5, 1, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 1, 4, 4, 0, 5, 0, 17, 17, 2, 0, 6, 0, 0, 0, 0, 0, 6, 0, 1, 4, 22, 22, 22, 9, 9, 0, 0, 0, 9, 0, 2, 5, 11, 0, 0, 7, 0, 0, 0, 7, 6, 8, 6, 13, 0, 6, 11, 7, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 3, 3, 0, 0, 0, 5, 17, 17, 2, 0, 11, 1, 10, 8, 6, 13, 12, 11, 11, 0, 0, 0, 0, 0, 8, 6, 0, 0, 16, 7, 3, 1, 7, 17, 2, 9, 7, 20, 13, 7, 21, 21, 7, 0, 0, 11, 6, 11, 13, 7, 4, 9, 0, 12, 0, 11, 6, 13, 20, 8, 6, 11, 3, 1, 24, 4, 0, 0, 0, 0, 0, 0, 0, 0, 11, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 10, 0, 7, 0, 0, 7, 3, 3, 7, 19, 19, 12, 1, 0, 0, 0, 0, 0, 11, 0, 0, 11, 31, 17, 2, 17, 0, 0, 0, 3, 0, 1, 0, 9, 0, 5, 11, 11, 11, 7, 3, 11, 9, 11, 0, 11, 11, 11, 6, 11, 3, 1, 7, 0, 0, 0, 10, 1, 23, 11, 7, 1, 1, 0, 1, 7, 3, 9, 9, 29, 5, 9, 12, 7, 12, 6, 13, 7, 1, 0, 0, 10, 6, 13, 0, 0, 3, 1, 4, 7, 3, 0, 0, 7, 0, 7, 24, 0, 14, 20, 0, 11, 0, 11, 0, 19, 20, 20, 0, 0, 20, 0, 3, 7, 1, 0, 0, 11, 8, 6, 13, 11, 11, 0, 3, 0, 0, 1, 10, 11, 12, 19, 0, 0, 0, 0, 0, 17, 2, 17, 2, 0, 15, 3, 11, 3, 0, 7, 10, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 13, 0, 42, 13, 0, 0, 0, 0, 2, 0, 11, 13, 0, 6, 0, 6, 8, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 8, 0, 6, 13, 0, 0, 1, 9, 3, 23, 9, 23, 6, 23, 6, 0, 0, 0, 7, 1, 3, 0, 3, 9, 1, 4, 0, 7, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 24, 24, 1, 0, 7, 5, 4, 0, 11, 11, 11, 0, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 7, 3, 1, 1, 4, 5, 12, 3, 0, 11, 16, 0, 3, 0, 0, 0, 0, 1, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 12, 12, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 6, 13, 0, 0, 0, 0, 0, 0, 0, 3, 11, 0, 0, 0, 0, 0, 0, 0, 9, 4, 0, 0, 1, 7, 0, 14, 5, 12, 0, 0, 0, 6, 13, 11, 0, 0, 0, 0, 0, 9, 11, 11, 0, 0, 11, 11, 3, 3, 1, 1, 0, 0, 7, 1, 0, 3, 0, 6, 0, 6, 13, 0, 2, 17, 9, 3, 5, 1, 4, 8, 0, 8, 6, 23, 24, 11, 3, 3, 11, 11, 3, 11, 11, 0, 8, 11, 3, 1, 4, 9, 3, 3, 0, 0, 9, 4, 0, 11, 3, 0, 0, 0, 0, 0, 0, 11, 8, 6, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 9, 11, 0, 0, 0, 0, 0, 3, 1, 1, 4, 0, 0, 9, 5, 5, 2, 23, 11, 11, 0, 0, 0, 0, 1, 7, 5, 0, 17, 2, 17, 2, 17, 17, 2, 11, 26, 6, 11, 11, 0, 0, 0, 0, 0, 0, 0, 0, 8, 11, 8, 0, 6, 13, 11, 11, 11, 1, 7, 7, 12, 7, 5, 12, 0, 0, 14, 0, 0, 0, 0, 0, 0, 0, 11, 10, 0, 0, 6, 13, 7, 3, 3, 0, 0, 0, 0, 0, 5, 22, 0, 0, 0, 0, 10, 14, 0, 11, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 12, 5, 4, 11, 8, 6, 13, 11, 1, 3, 0, 5, 17, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 12, 0, 12, 11, 11, 0, 0, 0, 6, 13, 13, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 11, 19, 6, 42, 0, 3, 0, 1, 11, 0, 13, 0, 6, 13, 11, 11, 0, 0, 0, 0, 5, 14, 0, 0, 0, 0, 12, 9, 12, 9, 14, 0, 0, 0, 0, 7, 0, 0, 0, 0, 9, 24, 1, 0, 19, 20, 6, 13, 0, 3, 0, 0, 2, 17, 0, 17, 17, 2, 17, 32, 16, 7, 0, 7, 12, 12, 12, 0, 13, 0, 0, 0, 0, 0, 0, 5, 0, 11, 6, 13, 11, 0, 0, 0, 0, 7, 11, 3, 12, 0, 0, 0, 9, 1, 3, 11, 8, 0, 11, 6, 0, 0, 0, 0, 8, 0, 0, 0, 0, 3, 7, 3, 7, 0, 3, 1, 0, 3, 0, 7, 0, 7, 3, 1, 3, 3, 0, 0, 0, 11, 9, 4, 11, 24, 1, 3, 24, 1, 3, 0, 8, 0, 6, 13, 0, 9, 11, 4, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 8, 6, 0, 0, 6, 13, 13, 0, 11, 7, 3, 1, 7, 14, 12, 13, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 11, 0, 9, 7, 0, 0, 3, 1, 5, 17, 2, 17, 2, 0, 6, 13, 11, 8, 0, 0, 1, 7, 6, 13, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 7, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 1, 4, 9, 1, 7, 0, 17, 2, 5, 6, 13, 6, 13, 0, 0, 0, 0, 0, 0, 0, 0, 11, 10, 19, 6, 6, 13, 0, 0, 0, 0, 0, 0, 8, 6, 13, 0, 3, 12, 11, 3, 0, 0, 0, 0, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 5, 8, 0, 20, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 6, 6, 11, 7, 11, 3, 9, 3, 11, 7, 1, 10, 0, 0, 0, 10, 0, 0, 0, 8, 0, 0, 0, 6, 13, 6, 0, 0, 9, 0, 0, 0, 13, 1, 7, 3, 0, 0, 0, 0, 9, 7, 0, 0, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 11, 1, 7, 0, 0, 5, 0, 0, 3, 11, 3, 1, 0, 4, 14, 8, 8, 6, 20, 0, 12, 12, 11, 43, 2, 0, 3, 1, 7, 0, 1, 3, 0, 3, 16, 7, 11, 11, 6, 0, 7, 3, 11, 12, 7, 3, 11, 12, 31, 0, 8, 6, 8, 8, 2, 0, 17, 2, 0, 17, 2, 0, 0, 0, 0, 0, 3, 1, 1, 0, 11, 8, 6, 0, 0, 6, 13, 6, 11, 11, 3, 0, 0, 0, 0, 0, 1, 3, 0, 4, 11, 0, 0, 6, 6, 13, 13, 0, 0, 0, 0, 11, 0, 0, 0, 8, 8, 0, 0, 7, 9, 3, 0, 9, 3, 4, 3, 0, 0, 1, 0, 4, 9, 1, 7, 4, 0, 0, 23, 0, 13, 9, 6, 13, 12, 0, 13, 7, 0, 2, 5, 17, 2, 7, 11, 0, 0, 0, 0, 9, 4, 6, 13, 0, 7, 0, 23, 4, 0, 0, 0, 7, 7, 0, 6, 13, 13, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 5, 17, 0, 0, 0, 8, 6, 0, 7, 3, 3, 7, 0, 0, 0, 17, 2, 17, 2, 11, 6, 6, 13, 11, 3, 11, 0, 0, 0, 0, 9, 7, 9, 7, 0, 0, 5, 2, 11, 0, 0, 11, 13, 0, 0, 0, 1, 3, 23, 11, 1, 0, 0, 0, 8, 6, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 7, 6, 6, 13, 0, 0, 7, 11, 0, 7, 3, 3, 3, 0, 0, 0, 3, 11, 11, 0, 0, 0, 7, 3, 44, 0, 0, 3, 1, 14, 12, 7, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 3, 11, 3, 11, 0, 1, 1, 14, 3, 1, 4, 5, 11, 11, 19, 12, 0, 6, 13, 3, 11, 7, 0, 3, 7, 0, 0, 0, 0, 3, 0, 6, 13, 0, 0, 0, 3, 3, 1, 4, 0, 2, 17, 0, 0, 16, 11, 23, 6, 6, 13, 0, 11, 19, 0, 0, 0, 0, 0, 0, 0, 12, 9, 0, 12, 5, 0, 0, 11, 42, 42, 13, 0, 0, 7, 9, 9, 7, 0, 0, 0, 7, 20, 0, 17, 21, 17, 21, 8, 6, 6, 0, 6, 13, 20, 11, 11, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 0, 0, 7, 1, 4, 4, 5, 11, 8, 25, 0, 6, 13, 11, 0, 0, 11, 19, 0, 6, 13, 0, 14, 0, 6, 16, 31, 32, 30, 9, 5, 4, 7, 1, 5, 8, 11, 1, 0, 3, 11, 9, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 5, 0, 24, 3, 3, 0, 4, 3, 0, 11, 0, 11, 6, 13, 0, 0, 0, 3, 1, 7, 10, 0, 3, 0, 0, 8, 0, 13, 0, 0, 0, 0, 0, 0, 0, 1, 4, 0, 0, 2, 0, 0, 0, 0, 1, 1, 1, 13, 22, 4, 1, 10, 11, 0, 11, 15, 10, 11, 7, 3, 0, 7, 3, 0, 0, 11, 6, 11, 11, 11, 0, 0, 3, 3, 0, 0, 3, 7, 3, 9, 5, 9, 17, 17, 2, 9, 11, 8, 0, 0, 13, 6, 3, 9, 11, 9, 4, 0, 6, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 2, 0, 8, 6, 13, 0, 8, 3, 12, 7, 12, 0, 0, 11, 0, 0, 0, 11, 0, 0, 11, 6, 13, 11, 0, 4, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 2, 44, 15, 11, 44, 12, 0, 0, 0, 11, 11, 8, 11, 11, 6, 13, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 9, 9, 4, 5, 5, 7, 10, 11, 0, 0, 0, 0, 0, 0, 3, 7, 1, 3, 0, 0, 0, 0, 9, 4, 23, 24, 1, 7, 16, 7, 12, 0, 0, 0, 0, 2, 7, 3, 1, 0, 0, 7, 5, 5, 14, 12, 0, 0, 6, 9, 0, 0, 0, 0, 7, 7, 0, 3, 11, 0, 13, 6, 10, 15, 8, 6, 0, 0, 6, 13, 11, 11, 0, 0, 0, 0, 0, 3, 0, 1, 7, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 22, 22, 19, 0, 0, 6, 0, 0, 11, 6, 8, 0, 0, 0, 0, 3, 7, 1, 4, 0, 17, 2, 23, 6, 8, 0, 0, 6, 13, 11, 11, 0, 0, 0, 9, 4, 11, 0, 7, 0, 0, 7, 0, 4, 4, 9, 11, 6, 13, 0, 0, 6, 13, 11, 0, 0, 0, 0, 0, 0, 5, 4, 12, 8, 6, 13, 0, 1, 9, 4, 11, 7, 3, 1, 4, 4, 5, 20, 14, 19, 0, 0, 6, 13, 0, 11, 37, 37, 0, 0, 0, 0, 0, 0, 0, 7, 13, 6, 13, 0, 0, 0, 0, 10, 7, 0, 15, 15, 6, 13, 0, 6, 11, 37, 37, 0, 8, 0, 0, 0, 0, 0, 0, 0, 3, 1, 3, 1, 0, 0, 0, 5, 0, 17, 2, 6, 0, 0, 0, 0, 0, 0, 0, 7, 1, 7, 19, 11, 0, 0, 11, 7, 11, 7, 11, 8, 6, 0, 0, 0, 0, 0, 11, 0, 0, 0, 0, 7, 1, 0, 0, 0, 0, 0, 0, 7, 1, 4, 7, 17, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 6, 13, 11, 9, 0, 0, 0, 7, 1, 10, 10, 11, 6, 6, 13, 0, 0, 0, 17, 2, 17, 2, 11, 0, 0, 0, 0, 0, 0, 0, 3, 3, 1, 7, 4, 0, 5, 12, 11, 0, 20, 13, 6, 11, 11, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 13, 3, 1, 4, 9, 7, 24, 4, 17, 2, 17, 2, 16, 9, 3, 11, 11, 0, 0, 0, 0, 0, 0, 11, 19, 9, 4, 11, 8, 7, 1, 4, 9, 7, 10, 20, 13, 11, 11, 0, 3, 3, 0, 0, 3, 16, 3, 1, 4, 5, 22, 17, 17, 2, 1, 0, 1, 17, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 4, 0, 0, 0, 0, 2, 5, 0, 2, 17, 19, 6, 6, 6, 11, 0, 0, 0, 0, 0, 9, 5, 11, 6, 13, 11, 11, 11, 6, 13, 0, 0, 0, 0, 7, 3, 3, 7, 3, 1, 7, 3, 0, 5, 7, 7, 7, 14, 8, 0, 0, 9, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 3, 6, 13, 6, 13, 0, 5, 2, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 9, 4, 5, 0, 0, 0, 9, 9, 5, 0, 5, 9, 8, 5, 0, 0, 11, 11, 9, 11, 9, 11, 13, 11, 9, 4, 22, 13, 19, 5, 12, 0, 6, 21, 7, 11, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 4, 0, 6, 8, 6, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 11, 8, 6, 0, 0, 0, 0, 6, 13, 6, 0, 8, 11, 11, 11, 6, 19, 19, 6, 0, 0, 0, 8, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 1, 7, 0, 5, 5, 17, 17, 2, 0, 8, 0, 0, 14, 6, 0, 8, 6, 13, 11, 0, 0, 0, 0, 1, 22, 17, 2, 0, 19, 6, 6, 13, 6, 0, 0, 0, 0, 0, 4, 1, 0, 8, 6, 0, 11, 7, 10, 6, 20, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 3, 6, 8, 0, 0, 0, 0, 8, 0, 7, 1, 1, 4, 4, 0, 7, 11, 9, 7, 11, 9, 0, 7, 0, 8, 0, 0, 0, 0, 3, 3, 0, 0, 11, 0, 0, 0, 7, 10, 11, 11, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 11, 0, 7, 0, 0, 11, 11, 10, 14, 5, 11, 3, 9, 7, 0, 0, 0, 0, 0, 0, 1, 7, 6, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 13, 11, 0, 11, 9, 0, 11, 6, 13, 11, 7, 1, 1, 4, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 6, 8, 6, 0, 0, 13, 26, 2, 9, 11, 7, 7, 9, 5, 11, 0, 0, 0, 0, 0, 0, 7, 3, 3, 7, 7, 4, 11, 8, 6, 12, 13, 11, 11, 0, 7, 0, 0, 0, 1, 4, 9, 0, 17, 2, 0, 7, 16, 16, 0, 0, 0, 0, 0, 0, 0, 12, 0, 0, 11, 6, 13, 11, 0, 17, 17, 2, 0, 0, 11, 0, 0, 0, 0, 0, 1, 0, 3, 1, 0, 17, 2, 17, 17, 2, 29, 29, 17, 2, 30, 11, 11, 11, 8, 8, 11, 8, 14, 0, 1, 9, 7, 9, 8, 6, 13, 20, 7, 1, 0, 0, 0, 0, 1, 24, 9, 7, 0, 6, 13, 0, 0, 0, 11, 19, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 29, 24, 17, 2, 31, 6, 13, 10, 11, 3, 1, 3, 1, 3, 24, 9, 0, 0, 0, 16, 3, 0, 3, 16, 3, 16, 0, 3, 16, 2, 0, 0, 9, 4, 1, 3, 0, 17, 17, 2, 3, 16, 0, 1, 1, 10, 10, 11, 11, 11, 8, 0, 6, 13, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 3, 7, 3, 0, 1, 7, 7, 0, 0, 0, 0, 0, 5, 0, 17, 17, 2, 11, 6, 6, 13, 0, 0, 0, 0, 0, 0, 11, 8, 6, 7, 5, 22, 1, 7, 3, 0, 0, 17, 2, 29, 11, 0, 0, 0, 0, 1, 32, 32, 2, 21, 5, 11, 0, 0, 11, 8, 9, 11, 23, 9, 0, 0, 0, 0, 0, 6, 13, 11, 0, 0, 0, 0, 5, 0, 0, 9, 5, 5, 20, 0, 0, 0, 9, 0, 0, 0, 0, 0, 11, 0, 14, 0, 0, 0, 11, 9, 0, 0, 0, 0, 0, 7, 1, 0, 9, 11, 0, 9, 11, 4, 8, 11, 13, 4, 9, 1, 0, 0, 2, 3, 7, 11, 7, 1, 1, 11, 8, 14, 14, 0, 0, 0, 0, 6, 13, 8, 0, 0, 0, 0, 0, 11, 7, 7, 24, 1, 4, 5, 27, 11, 8, 6, 13, 11, 11, 11, 7, 3, 1, 9, 4, 7, 11, 6, 13, 3, 3, 3, 11, 6, 13, 0, 11, 0, 11, 11, 11, 0, 1, 3, 7, 7, 1, 1, 24, 4, 0, 5, 0, 17, 17, 2, 3, 4, 0, 3, 0, 0, 0, 0, 0, 0, 3, 3, 1, 7, 7, 0, 0, 0, 11, 11, 3, 0, 0, 2, 6, 13, 0, 0, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 0, 3, 7, 1, 7, 0, 0, 0, 0, 7, 1, 10, 11, 11, 15, 14, 0, 4, 5, 14, 12, 0, 0, 8, 6, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 6, 11, 11, 7, 1, 0, 0, 0, 3, 11, 19, 6, 6, 13, 5, 17, 2, 11, 9, 3, 0, 0, 0, 0, 0, 11, 11, 0, 0, 0, 0, 5, 22, 9, 0, 3, 1, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 9, 1, 24, 0, 0, 6, 6, 13, 11, 17, 17, 2, 17, 17, 9, 1, 0, 1, 0, 14, 0, 3, 1, 7, 0, 2, 0, 12, 12, 0, 0, 11, 11, 0, 0, 0, 0, 0, 0, 1, 5, 4, 0, 0, 0, 0, 0, 0, 11, 6, 13, 6, 11, 0, 0, 0, 13, 19, 10, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 1, 1, 0, 1, 0, 1, 0, 3, 3, 3, 9, 4, 10, 14, 10, 14, 12, 11, 9, 9, 4, 1, 27, 1, 32, 9, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 2, 9, 0, 11, 8, 0, 6, 13, 0, 0, 0, 0, 3, 1, 10, 10, 6, 13, 1, 11, 10, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 9, 12, 3, 1, 7, 1, 11, 1, 9, 24, 24, 5, 12, 11, 12, 6, 13, 0, 0, 0, 0, 0, 0, 0, 11, 0, 11, 0, 0, 0, 9, 5, 0, 11, 8, 13, 0, 0, 0, 6, 13, 23, 15, 11, 0, 2, 0, 5, 0, 2, 29, 0, 0, 24, 0, 7, 3, 32, 7, 0, 14, 3, 3, 1, 3, 4, 9, 32, 0, 17, 2, 0, 0, 9, 9, 9, 11, 0, 7, 0, 0, 0, 0, 7, 9, 11, 11, 3, 1, 7, 3, 0, 0, 13, 6, 0, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 4, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 11, 1, 1, 7, 11, 6, 11, 0, 6, 0, 0, 9, 4, 1, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 9, 7, 17, 2, 11, 0, 0, 0, 7, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 7, 3, 1, 3, 9, 0, 8, 11, 13, 0, 0, 9, 10, 8, 6, 0, 13, 6, 11, 0, 2, 1, 7, 9, 9, 0, 6, 6, 13, 0, 0, 7, 1, 7, 9, 0, 7, 11, 8, 6, 13, 11, 11, 0, 0, 8, 0, 6, 13, 5, 0, 0, 7, 0, 14, 11, 10, 6, 6, 13, 11, 0, 0, 0, 0, 0, 0, 0, 3, 4, 11, 6, 0, 0, 12, 3, 0, 0, 0, 0, 0, 0, 0, 3, 0, 5, 5, 11, 0, 0, 7, 9, 7, 9, 0, 24, 9, 9, 6, 13, 0, 0, 0, 0, 6, 36, 13, 0, 0, 6, 13, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 7, 4, 9, 4, 17, 2, 17, 17, 2, 11, 0, 0, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 5, 23, 0, 13, 13, 11, 23, 1, 4, 23, 23, 11, 17, 16, 11, 7, 11, 11, 0, 11, 11, 11, 14, 10, 0, 11, 0, 0, 3, 0, 3, 1, 7, 0, 3, 17, 2, 17, 2, 0, 0, 2, 0, 0, 20, 0, 11, 6, 13, 13, 0, 3, 11, 11, 6, 3, 24, 1, 0, 0, 2, 11, 6, 13, 6, 11, 11, 0, 0, 3, 3, 0, 1, 2, 0, 0, 0, 0, 9, 1, 1, 2, 17, 17, 2, 4, 2, 11, 6, 8, 6, 0, 0, 0, 0, 0, 6, 13, 11, 11, 0, 0, 0, 3, 1, 0, 0, 11, 0, 6, 13, 0, 0, 11, 0, 0, 0, 9, 4, 17, 2, 5, 5, 4, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 13, 6, 6, 13, 0, 0, 0, 0, 0, 11, 6, 13, 0, 13, 0, 0, 0, 0, 0, 0, 11, 8, 6, 13, 11, 0, 6, 0, 0, 0, 0, 0, 0, 7, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 9, 3, 3, 11, 6, 13, 11, 3, 7, 11, 3, 7, 11, 0, 0, 0, 0, 0, 10, 15, 0, 0, 8, 6, 0, 0, 0, 0, 3, 9, 9, 7, 3, 1, 7, 10, 11, 11, 0, 0, 0, 0, 0, 7, 3, 7, 3, 0, 0, 7, 11, 0, 7, 11, 0, 10, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 5, 20, 11, 8, 0, 0, 2, 21, 0, 32, 0, 0, 9, 11, 3, 0, 0, 0, 10, 0, 0, 0, 0, 0, 0, 0, 7, 0, 13, 6, 0, 7, 7, 1, 7, 6, 11, 6, 13, 11, 0, 0, 0, 7, 0, 7, 0, 1, 7, 6, 13, 13, 11, 0, 1, 0, 0, 7, 0, 2, 0, 14, 6, 13, 7, 3, 9, 0, 0, 0, 0, 0, 0, 0, 0, 5, 26, 0, 0, 0, 0, 6, 13, 11, 11, 7, 7, 0, 0, 0, 0, 0, 0, 3, 24, 9, 9, 23, 8, 11, 19, 0, 0, 3, 7, 12, 11, 7, 12, 3, 11, 0, 0, 0, 0, 7, 1, 5, 19, 12, 11, 10, 0, 0, 0, 0, 3, 3, 3, 1, 4, 9, 3, 16, 0, 7, 3, 1, 0, 4, 9, 0, 6, 0, 0, 6, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 2, 0, 0, 11, 7, 1, 3, 9, 0, 6, 22, 17, 2, 17, 0, 0, 7, 9, 11, 11, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 11, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 7, 3, 1, 0, 0, 0, 0, 2, 0, 8, 0, 0, 0, 0, 11, 0, 3, 12, 3, 3, 0, 0, 0, 0, 0, 8, 11, 0, 6, 13, 0, 0, 0, 0, 0, 0, 0, 0, 9, 9, 0, 5, 11, 11, 7, 3, 3, 10, 4, 11, 9, 0, 0, 3, 1, 11, 8, 6, 6, 13, 0, 0, 8, 8, 11, 5, 12, 12, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 24, 1, 24, 24, 11, 9, 7, 0, 1, 0, 7, 9, 5, 5, 6, 13, 8, 6, 13, 0, 0, 3, 27, 1, 27, 1, 1, 4, 1, 9, 0, 0, 3, 0, 0, 5, 5, 0, 8, 11, 9, 7, 9, 7, 3, 3, 1, 1, 0, 6, 0, 0, 6, 13, 11, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 11, 6, 13, 3, 0, 7, 0, 0, 0, 11, 0, 0, 0, 0, 0, 0, 0, 0, 1, 7, 38, 2, 0, 5, 8, 6, 0, 13, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 11, 19, 20, 0, 0, 0, 11, 0, 0, 11, 31, 17, 2, 17, 2, 0, 0, 0, 0, 0, 1, 1, 7, 0, 0, 4, 9, 17, 6, 13, 0, 7, 0, 3, 0, 5, 20, 9, 0, 6, 13, 0, 11, 0, 0, 0, 0, 0, 0, 0, 5, 12, 0, 0, 0, 0, 0, 0, 0, 0, 17, 2, 0, 8, 0, 0, 6, 13, 11, 8, 21, 10, 11, 11, 7, 9, 0, 1, 0, 3, 0, 3, 0, 8, 0, 0, 0, 12, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 6, 11, 6, 0, 7, 0, 24, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 11, 1, 11, 0, 1, 0, 24, 9, 0, 0, 0, 0, 0, 0, 5, 22, 22, 0, 11, 11, 19, 6, 13, 20, 23, 0, 1, 24, 1, 24, 1, 9, 24, 9, 7, 9, 0, 0, 0, 0, 23, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 7, 1, 4, 11, 0, 0, 0, 0, 11, 10, 7, 22, 13, 24, 9, 0, 0, 11, 0, 7, 1, 1, 32, 5, 9, 10, 6, 13, 6, 7, 11, 14, 11, 0, 0, 1, 1, 4, 1, 9, 4, 4, 9, 5, 20, 22, 0, 17, 2, 17, 2, 5, 23, 6, 0, 6, 13, 11, 11, 0, 0, 11, 13, 6, 21, 0, 1, 14, 1, 7, 14, 0, 0, 0, 0, 9, 0, 0, 0, 5, 8, 6, 0, 0, 6, 13, 0, 7, 2, 45, 7, 12, 14, 0, 0, 7, 1, 1, 0, 11, 7, 0, 0, 32, 9, 0, 11, 9, 7, 1, 24, 1, 1, 4, 9, 0, 0, 7, 4, 1, 9, 5, 0, 0, 19, 11, 0, 6, 0, 11, 13, 6, 13, 0, 0, 8, 0, 9, 4, 1, 3, 3, 2, 0, 2, 46, 0, 13, 0, 11, 11, 8, 5, 11, 3, 7, 0, 0, 0, 11, 11, 11, 0, 0, 0, 0, 0, 9, 3, 1, 24, 9, 6, 6, 13, 0, 0, 2, 0, 3, 7, 7, 0, 0, 6, 8, 0, 0, 0, 7, 7, 4, 47, 4, 48, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 8, 8, 0, 13, 11, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 6, 13, 0, 24, 1, 4, 6, 13, 11, 11, 9, 0, 0, 0, 0, 0, 3, 7, 3, 7, 1, 1, 3, 11, 0, 11, 0, 0, 7, 1, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 3, 3, 1, 0, 0, 0, 0, 0, 2, 3, 7, 7, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 1, 0, 15, 0, 2, 0, 0, 0, 0, 3, 1, 3, 15, 11, 6, 13, 23, 10, 1, 0, 0, 0, 9, 7, 9, 7, 3, 3, 11, 0, 0, 0, 0, 0, 0, 0, 1, 7, 0, 11, 7, 11, 3, 7, 3, 1, 0, 4, 11, 8, 0, 11, 0, 0, 0, 0, 0, 0, 0, 9, 5, 7, 1, 1, 1, 4, 0, 0, 9, 9, 4, 3, 1, 4, 5, 49, 12, 12, 11, 11, 19, 6, 13, 0, 3, 7, 3, 1, 0, 0, 0, 0, 4, 9, 0, 0, 0, 0, 0, 0, 2, 0, 7, 0, 7, 1, 1, 7, 0, 0, 6, 0, 7, 9, 9, 4, 24, 9, 0, 11, 0, 6, 0, 0, 6, 13, 0, 4, 0, 6, 0, 0, 0, 6, 13, 7, 0, 0, 0, 0, 10, 8, 0, 11, 0, 0, 0, 0, 10, 13, 12, 7, 3, 13, 12, 7, 3, 1, 4, 4, 9, 5, 2, 2, 5, 13, 0, 0, 13, 0, 0, 32, 7, 0, 0, 1, 21, 2, 5, 12, 0, 0, 0, 0, 17, 2, 6, 13, 0, 1, 1, 1, 4, 0, 3, 11, 0, 0, 3, 3, 1, 24, 7, 0, 11, 19, 17, 30, 0, 7, 1, 1, 3, 0, 0, 11, 0, 6, 13, 13, 0, 0, 0, 9, 11, 0, 0, 0, 0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 0, 8, 0, 0, 0, 7, 7, 0, 0, 7, 0, 7, 3, 1, 1, 7, 10, 0, 10, 6, 13, 0, 6, 11, 8, 6, 0, 0, 2, 0, 0, 0, 0, 0, 11, 19, 7, 5, 0, 0, 0, 0, 0, 0, 0, 0, 11, 0, 0, 6, 13, 13, 26, 7, 3, 1, 9, 9, 0, 11, 23, 0, 0, 11, 7, 11, 11, 7, 1, 0, 11, 11, 0, 0, 0, 7, 7, 7, 0, 0, 0, 0, 5, 17, 2, 0, 0, 0, 0, 0, 0, 7, 9, 0, 0, 11, 19, 6, 0, 0, 0, 0, 0, 6, 13, 6, 11, 11, 11, 7, 9, 0, 0, 0, 0, 1, 4, 0, 2, 17, 2, 0, 0, 0, 0, 0, 0, 11, 8, 0, 6, 13, 11, 0, 0, 0, 0, 11, 8, 8, 0, 6, 13, 0, 0, 0, 0, 0, 0, 0, 9, 5, 5, 6, 13, 24, 9, 1, 7, 1, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 2, 0, 17, 2, 17, 2, 23, 0, 6, 13, 0, 9, 2, 17, 16, 7, 0, 0, 0, 0, 0, 0, 11, 0, 6, 13, 11, 0, 0, 0, 9, 24, 0, 0, 0, 0, 0, 1, 7, 0, 24, 1, 0, 0, 0, 0, 3, 9, 4, 9, 4, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 7, 11, 11, 7, 3, 7, 3, 0, 44, 1, 7, 1, 7, 3, 3, 1, 4, 12, 0, 12, 2, 9, 11, 19, 6, 13, 11, 11, 11, 11, 3, 1, 10, 0, 0, 0, 13, 0, 0, 7, 0, 0, 6, 13, 11, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 1, 14, 8, 6, 6, 13, 11, 9, 14, 12, 9, 5, 17, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 13, 13, 9, 6, 9, 9, 1, 4, 0, 0, 0, 0, 14, 20, 17, 2, 5, 0, 0, 7, 11, 0, 7, 0, 0, 0, 1, 0, 0, 7, 11, 7, 11, 0, 3, 3, 1, 1, 4, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 1, 4, 0, 0, 11, 6, 6, 13, 17, 2, 0, 24, 1, 1, 24, 9, 0, 0, 3, 15, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 7, 3, 1, 7, 11, 10, 11, 0, 7, 7, 3, 1, 7, 1, 0, 10, 0, 24, 0, 0, 0, 9, 4, 1, 11, 14, 8, 0, 13, 7, 0, 0, 7, 0, 4, 2, 0, 5, 12, 11, 6, 13, 0, 20, 6, 7, 9, 11, 0, 0, 0, 11, 8, 25, 6, 13, 11, 0, 7, 9, 11, 7, 9, 11, 0, 0, 11, 0, 0, 11, 9, 24, 4, 5, 0, 7, 0, 0, 14, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 4, 1, 4, 9, 6, 13, 11, 0, 0, 0, 4, 5, 7, 7, 5, 11, 13, 0, 0, 0, 0, 0, 9, 11, 9, 11, 6, 11, 7, 3, 1, 7, 0, 11, 12, 10, 11, 50, 12, 3, 0, 7, 0, 11, 6, 13, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 1, 7, 7, 1, 3, 1, 4, 0, 2, 0, 23, 17, 17, 2, 17, 2, 11, 6, 0, 26, 11, 11, 11, 16, 3, 3, 16, 11, 0, 0, 0, 0, 19, 6, 13, 0, 0, 0, 9, 3, 2, 5, 0, 11, 11, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 8, 6, 6, 17, 2, 0, 6, 11, 11, 8, 6, 0, 0, 6, 13, 0, 7, 0, 11, 0, 1, 7, 0, 0, 7, 7, 1, 0, 0, 2, 37, 0, 11, 3, 0, 0, 0, 10, 7, 0, 0, 14, 0, 1, 4, 0, 0, 0, 3, 9, 11, 11, 9, 3, 11, 13, 3, 1, 4, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 5, 12, 0, 0, 0, 0, 0, 0, 0, 0, 11, 11, 6, 13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 9, 0, 3, 11, 1, 11, 0, 0, 6, 13, 0, 0, 4, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 3, 24, 1, 4, 4, 9, 1, 24, 0, 0, 0, 5, 0, 0, 0, 17, 17, 2, 9, 9, 0, 13, 6, 0, 11, 13, 0, 0, 0, 0, 0, 11, 3, 0, 0, 0, 0, 0, 0, 0, 32, 11, 11, 6, 13, 0, 0, 0, 10, 14, 12, 32, 3, 1, 14, 12, 0, 0, 13, 0, 11, 0, 8, 13, 0, 9, 5, 17, 2, 0, 0, 0, 0, 0, 0, 3, 7, 1, 14, 1, 1, 0, 5, 0, 17, 17, 2, 0, 0, 0, 0, 0, 6, 8, 6, 7, 0, 0, 0, 0, 0, 0, 3, 9, 11, 0, 1, 7, 9, 24, 1, 3, 24, 1, 9, 23, 11, 0, 11, 19, 19, 0, 0, 9, 4, 24, 9, 0, 11, 7, 0, 0, 0, 9, 9, 4, 24, 24, 9, 3, 5, 12, 11, 8, 0, 13, 11, 11, 0, 0, 11, 11, 0, 0, 0, 0, 7, 3, 7, 4, 5, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Now map each label to its corresponding integer\n",
    "old_labels = labels\n",
    "print(\"Old labels: \",str(labels))\n",
    "labels = [label_types.get(l) for l in labels]\n",
    "print(\"New labels: \",str(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a new train_test_split that isn't random, but uses a function to determine if the set is train, validation or test \n",
    "# based on causal reasoning chains.\n",
    "\n",
    "coral_bleaching_chains = [['1', '2', '3', '4', '5', '5b', '14', '6', '7', '50'], ['11', '12', '13', '14', '6', '7', '50']]\n",
    "skin_cancer_chains = [['1', '2', '3', '4', '5', '6', '50'], ['11', '12', '6', '50']]\n",
    "\n",
    "# This function examines the label to determin if a proper causal reasoning chain exists.  \n",
    "# If it is of proper format and order, a causal-reasoning chain exists.\n",
    "def causal_reasoning_chain_exists(chains, label):\n",
    "    retVal = False\n",
    "    if (isinstance(label, int)):\n",
    "        return retVal\n",
    "    else:\n",
    "        index = [0, 0]\n",
    "        label_values = label.split(\"-\")\n",
    "        #print(\"Label values: {}\".format(label_values))\n",
    "        \n",
    "        if (len(label_values) < 2):\n",
    "            return retVal\n",
    "\n",
    "        for i, cr_chain in enumerate(chains):\n",
    "            if (label_values[1] in cr_chain):\n",
    "                index[i] = cr_chain.index(label_values[1])\n",
    "\n",
    "        #print(\"Index: {}\".format(index))\n",
    "        # see if there exists a chain such that the second label is contained in the subset after the first causation was found.\n",
    "        for i, cr_chain in enumerate(chains):\n",
    "            #print(\"Checking for {} in {}\".format(label_values[2], cr_chain[index[i]+1:]))\n",
    "            if (label_values[2] in cr_chain[index[i]+1:]):\n",
    "                retVal = True   \n",
    "                \n",
    "    return retVal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain exists for R-1-2? True\n",
      "Chain exists for R-1-3? True\n",
      "Chain exists for R-2-1? False\n",
      "Chain exists for R-1-50? True\n",
      "Chain exists for R-11-50? True\n"
     ]
    }
   ],
   "source": [
    "# Test out the logic in causal_reasoning_chain_exists\n",
    "print(\"Chain exists for R-1-2? {}\".format(causal_reasoning_chain_exists(skin_cancer_chains, \"R-1-2\")))\n",
    "print(\"Chain exists for R-1-3? {}\".format(causal_reasoning_chain_exists(skin_cancer_chains, \"R-1-3\")))\n",
    "print(\"Chain exists for R-2-1? {}\".format(causal_reasoning_chain_exists(skin_cancer_chains, \"R-2-1\")))\n",
    "print(\"Chain exists for R-1-50? {}\".format(causal_reasoning_chain_exists(skin_cancer_chains, \"R-1-50\")))\n",
    "print(\"Chain exists for R-11-50? {}\".format(causal_reasoning_chain_exists(skin_cancer_chains, \"R-11-50\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids[0]: [  101  1142 10400  1110  1164  2241  3290   117 18579  1105  2904  9673\n",
      "   117  2241  4182  1105 18579   117  1240  2241 19819  1128  1105  1164\n",
      "  3336  6715  1116   119   102     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "input_ids.shape\n",
    "print(\"input_ids[0]: {}\".format(input_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data up into sentences who have proper causal reasoning chains, and those that don't\n",
    "def crc_split(input_ids, labels):\n",
    "    crc_inputs = []\n",
    "    crc_labels = []\n",
    "    non_crc_inputs = []\n",
    "    non_crc_labels = []\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        if causal_reasoning_chain_exists(skin_cancer_chains, label):\n",
    "            crc_inputs.append(input_ids[i])\n",
    "            crc_labels.append(1) # encode a 1 as true, there exists a causal reasoning chain\n",
    "            #print(\"Found one: {}\".format(label))\n",
    "        else:\n",
    "            non_crc_inputs.append(input_ids[i])\n",
    "            non_crc_labels.append(0) # encoded a 0 as false, there does not exist a valid causal reasoning chain\n",
    "    \n",
    "    return crc_inputs, crc_labels, non_crc_inputs, non_crc_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRC qty found: 5342\n",
      "NonCRC qty found: 4690\n",
      "Total: 10032\n"
     ]
    }
   ],
   "source": [
    "crc_inputs, crc_labels, non_crc_inputs, non_crc_labels = crc_split(input_ids, old_labels)\n",
    "\n",
    "print(\"CRC qty found: {}\".format(len(crc_inputs)))\n",
    "print(\"NonCRC qty found: {}\".format(len(non_crc_inputs)))\n",
    "print(\"Total: {}\".format(len(crc_inputs) + len(non_crc_inputs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_inputs len: 9028\n",
      "train_labels len: 9028\n",
      "train_masks len: 9028\n",
      "validation_inputs len: 1004\n",
      "validation_labels len: 1004\n",
      "validation_masks len: 1004\n"
     ]
    }
   ],
   "source": [
    "# create training, validation and test sets\n",
    "\n",
    "# Create attention masks\n",
    "attention_masks_crc = []\n",
    "attention_masks_non_crc = []\n",
    "\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in crc_inputs:\n",
    "  seq_mask_crc = [float(i>0) for i in seq]\n",
    "  attention_masks_crc.append(seq_mask_crc)\n",
    "    \n",
    "for seq in non_crc_inputs:\n",
    "  seq_mask_non_crc = [float(i>0) for i in seq]\n",
    "  attention_masks_non_crc.append(seq_mask_non_crc)   \n",
    "\n",
    "train_inputs_crc, validation_inputs_crc, train_labels_crc, validation_labels_crc = \\\n",
    "    train_test_split(crc_inputs, crc_labels, random_state=2018, test_size=0.1)\n",
    "train_masks_crc, validation_masks_crc, _, _ = train_test_split(attention_masks_crc, crc_inputs, \\\n",
    "                                             random_state=2018, test_size=0.1)\n",
    "\n",
    "train_inputs_non_crc, validation_inputs_non_crc, train_labels_non_crc, validation_labels_non_crc = \\\n",
    "    train_test_split(non_crc_inputs, non_crc_labels, random_state=2018, test_size=0.1)\n",
    "train_masks_non_crc, validation_masks_non_crc, _, _ = train_test_split(attention_masks_non_crc, non_crc_inputs, \\\n",
    "                                             random_state=2018, test_size=0.1)\n",
    "\n",
    "train_inputs = train_inputs_crc + train_inputs_non_crc\n",
    "print(\"train_inputs len: {}\".format(len(train_inputs)))\n",
    "\n",
    "train_labels = train_labels_crc + train_labels_non_crc\n",
    "print(\"train_labels len: {}\".format(len(train_labels)))\n",
    "\n",
    "train_masks = train_masks_crc + train_masks_non_crc\n",
    "print(\"train_masks len: {}\".format(len(train_masks)))\n",
    "\n",
    "validation_inputs = validation_inputs_crc + validation_inputs_non_crc\n",
    "print(\"validation_inputs len: {}\".format(len(validation_inputs)))\n",
    "\n",
    "validation_labels = validation_labels_crc + validation_labels_non_crc\n",
    "print(\"validation_labels len: {}\".format(len(validation_labels)))\n",
    "\n",
    "validation_masks = validation_masks_crc + validation_masks_non_crc\n",
    "print(\"validation_masks len: {}\".format(len(validation_masks)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "htRjVQyojbgN"
   },
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for training\n",
    "\n",
    "#train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "#                                                            random_state=2018, test_size=0.1)\n",
    "#train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "#                                             random_state=2018, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UKpWMj-EjboB"
   },
   "outputs": [],
   "source": [
    "# Convert all of our data into torch tensors, the required datatype for our model\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KIlXwhh67BXS"
   },
   "outputs": [],
   "source": [
    "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
    "# with an iterator the entire dataset does not need to be loaded into memory\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use PyTorch to create a pytorch_model.bin for BioBert\n",
    "import os\n",
    "from pytorch_pretrained_bert.convert_tf_checkpoint_to_pytorch import convert_tf_checkpoint_to_pytorch\n",
    "\n",
    "path_bert = 'pre-trained_models/biobert_v1.1_pubmed/'\n",
    "path_bin = path_bert + 'pytorch_model.bin'\n",
    "\n",
    "if (not os.path.exists(path_bin)):\n",
    "    convert_tf_checkpoint_to_pytorch(path_bert + \"model.ckpt-1000000\", \n",
    "                                     path_bert + \"bert_config.json\", \n",
    "                                     path_bert + \"pytorch_model.bin\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 137205,
     "status": "ok",
     "timestamp": 1587144360114,
     "user": {
      "displayName": "Clayton Cohn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiR5T0VrYZ_A0_satvSE1jZbcVxmApPyylw8Q-uxoo=s64",
      "userId": "10103672487987981310"
     },
     "user_tz": 300
    },
    "id": "MWbESUZsjblO",
    "outputId": "d61f7603-3a8a-4c92-ce76-7ee694e308db",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=10032, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is where the fine-tuning comes in. We must train the model for our specific task.\n",
    "\n",
    "# We will first modify pre-trained BERT for our specific task, then continue training on our data until the entire model\n",
    "#   is well-suited for our task.\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(BERT_PATH, num_labels=len(labels))\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-W9_IQfjbiu"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
    "\n",
    "For the purposes of fine-tuning, the authors recommend the following hyperparameter ranges:\n",
    "\n",
    "Batch size: 16, 32\n",
    "Learning rate (Adam): 5e-5, 3e-5, 2e-5\n",
    "Number of epochs: 2, 3, 4\n",
    "'''\n",
    "\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 137145,
     "status": "ok",
     "timestamp": 1587144360116,
     "user": {
      "displayName": "Clayton Cohn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiR5T0VrYZ_A0_satvSE1jZbcVxmApPyylw8Q-uxoo=s64",
      "userId": "10103672487987981310"
     },
     "user_tz": 300
    },
    "id": "VJJ0yOIZtOpr",
    "outputId": "af71d5ca-7614-47ba-8b1a-afbb38072b64"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t_total value of -1 results in schedule not being applied\n"
     ]
    }
   ],
   "source": [
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                     lr=LEARNING_RATE,\n",
    "                     warmup=WARMUP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GANGNKH7jbd2"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 468855,
     "status": "ok",
     "timestamp": 1587144691892,
     "user": {
      "displayName": "Clayton Cohn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiR5T0VrYZ_A0_satvSE1jZbcVxmApPyylw8Q-uxoo=s64",
      "userId": "10103672487987981310"
     },
     "user_tz": 300
    },
    "id": "DKr36ugQ6qZn",
    "outputId": "4709e68d-a40f-4223-9d77-04aab7fec063"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                                                                     | 0/2 [00:00<?, ?it/s]C:\\Users\\Keith\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "..\\torch\\csrc\\utils\\python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7549851267160881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Keith\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\ipykernel_launcher.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9124348958333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|                                      | 1/2 [02:50<02:50, 170.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.18278028613265748\n",
      "Validation Accuracy: 0.9147135416666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|| 2/2 [05:39<00:00, 169.99s/it]\n"
     ]
    }
   ],
   "source": [
    "t = [] \n",
    "\n",
    "# Store our loss and accuracy for plotting\n",
    "train_loss_set = []\n",
    "\n",
    "# trange is a tqdm wrapper around the normal python range\n",
    "for _ in trange(EPOCHS, desc=\"Epoch\"):\n",
    "  \n",
    "  # Training\n",
    "  \n",
    "  # Set our model to training mode (as opposed to evaluation mode)\n",
    "  model.train()\n",
    "  \n",
    "  # Tracking variables\n",
    "  tr_loss = 0\n",
    "  nb_tr_examples, nb_tr_steps = 0, 0\n",
    "  \n",
    "  # Train the data for one epoch\n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    b_input_ids = torch.tensor(b_input_ids).to(torch.int64) # from https://github.com/huggingface/transformers/issues/2952\n",
    "    # Clear out the gradients (by default they accumulate)\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "    train_loss_set.append(loss.item())    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Update parameters and take a step using the computed gradient\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Update tracking variables\n",
    "    tr_loss += loss.item()\n",
    "    nb_tr_examples += b_input_ids.size(0)\n",
    "    nb_tr_steps += 1\n",
    "\n",
    "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    \n",
    "    \n",
    "  # Validation\n",
    "\n",
    "  # Put model in evaluation mode to evaluate loss on the validation set\n",
    "  model.eval()\n",
    "\n",
    "  # Tracking variables \n",
    "  eval_loss, eval_accuracy = 0, 0\n",
    "  nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "  # Evaluate data for one epoch\n",
    "  for batch in validation_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    b_input_ids = torch.tensor(b_input_ids).to(torch.int64) # from https://github.com/huggingface/transformers/issues/2952\n",
    "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "    with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "    \n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    \n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "  print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bqqQCDEWs0oN"
   },
   "outputs": [],
   "source": [
    "STATS_FILE = \"skin_cancer_fine_tuning_stats.csv\"\n",
    "\n",
    "def getLastModelNumber():\n",
    "  try:\n",
    "    with open(STATS_PATH + \"/\" + STATS_FILE, \"r\") as f:\n",
    "      f_list = list(f)\n",
    "      latest = f_list[-1].split(',')\n",
    "      return int(latest[0])\n",
    "  except:\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k50fbgDqbai2"
   },
   "outputs": [],
   "source": [
    "# Will take a break from saving models - takes up too much space\n",
    "\n",
    "# import os\n",
    "# import itertools\n",
    "\n",
    "# MODEL_PATH = \"drive/My Drive/colab/models/\" \n",
    "# MODEL_SAVE_NAME = 'skin_cancer_fine_tuning'\n",
    "\n",
    "# # Helper function for auto-saving model incrementally\n",
    "\n",
    "# # This code is originally from StackExchange via \"Tanner,\" but I altered it for use here\n",
    "# # https://gis.stackexchange.com/questions/27410/how-auto-increment-output-file-names-in-python-script\n",
    "\n",
    "# # Modified with code from Gareth Latty via StackOverflow\n",
    "# # https://stackoverflow.com/questions/13673781/splitting-a-string-where-it-switches-between-numeric-and-alphabetic-characters\n",
    "# def getNextFileInt(output_folder):\n",
    "#     highest_num = 0\n",
    "#     for f in os.listdir(output_folder):\n",
    "#       temp = \"\"\n",
    "#       for c in f:\n",
    "#         if c.isdigit():\n",
    "#           temp += c\n",
    "#         if len(temp) > 0 and int(temp) > highest_num:\n",
    "#           highest_num = int(temp)\n",
    "#     return highest_num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 469105,
     "status": "ok",
     "timestamp": 1587144692225,
     "user": {
      "displayName": "Clayton Cohn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiR5T0VrYZ_A0_satvSE1jZbcVxmApPyylw8Q-uxoo=s64",
      "userId": "10103672487987981310"
     },
     "user_tz": 300
    },
    "id": "6W-xZT7ybtzL",
    "outputId": "2341c807-f698-4bb8-8f70-7ab38b72c316"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use this in the future to refer to the current model\n",
    "current_file_n_str = str(getLastModelNumber() + 1)\n",
    "current_file_n_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M8-hHD9R6qj1"
   },
   "outputs": [],
   "source": [
    "# # We save the model so that we can access it later\n",
    "\n",
    "# if not os.path.isfile(MODEL_PATH + MODEL_SAVE_NAME):\n",
    "#   torch.save(model.state_dict(), MODEL_PATH + MODEL_SAVE_NAME)\n",
    "# else:\n",
    "#   # Get the model number to save\n",
    "#   current_file_n_str = str(getNextFileInt(MODEL_PATH))\n",
    "#   print(\"This will be file\",current_file_n_str)\n",
    "#   torch.save(model.state_dict(), MODEL_PATH + MODEL_SAVE_NAME + current_file_n_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 470357,
     "status": "ok",
     "timestamp": 1587144693528,
     "user": {
      "displayName": "Clayton Cohn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiR5T0VrYZ_A0_satvSE1jZbcVxmApPyylw8Q-uxoo=s64",
      "userId": "10103672487987981310"
     },
     "user_tz": 300
    },
    "id": "YDoGoe4V6qtf",
    "outputId": "b88b934a-a8d7-4ea4-f55f-86dd3f2286f4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's take a look!\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(train_loss_set)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yORLUkJzBwgq"
   },
   "outputs": [],
   "source": [
    "# Now we will validate on our testing data\n",
    "DATA_NAME_TEST = \"EBA1415-SkinCancer-little-sentences.tsv\"\n",
    "df_test = pd.read_csv(DATA_PATH + \"/\" + DATA_NAME_TEST, delimiter='\\t', header=0, names=['file', 'relation', 's_num', 'sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jMbMYLuQBwdt"
   },
   "outputs": [],
   "source": [
    "# Create sentence and label lists\n",
    "sentences_test = df_test.sentence.values\n",
    "\n",
    "# We need to add special tokens at the beginning and end of each sentence for BERT to work properly\n",
    "sentences_test = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences_test]\n",
    "\n",
    "tokenized_texts_test = [tokenizer.tokenize(sentence) for sentence in sentences_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "544FbxSkBwa7"
   },
   "outputs": [],
   "source": [
    "# Get labels\n",
    "labels_test = df_test.relation.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 470881,
     "status": "ok",
     "timestamp": 1587144694170,
     "user": {
      "displayName": "Clayton Cohn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiR5T0VrYZ_A0_satvSE1jZbcVxmApPyylw8Q-uxoo=s64",
      "userId": "10103672487987981310"
     },
     "user_tz": 300
    },
    "id": "7FQmuOIsYI8h",
    "outputId": "6088b808-8a1a-4bc1-99cf-c2a9c81a3bb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: size: 2614, values [0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to ints\n",
    "\n",
    "#print(\"Pre-changed test labels: \",str(labels_test))\n",
    "#labels_test = [label_types.get(l) for l in labels_test]\n",
    "#print(\"Changed test labels: \",str(labels_test))\n",
    "\n",
    "test_labels = []\n",
    "for i, label in enumerate(labels_test):\n",
    "    value = 0\n",
    "    if (causal_reasoning_chain_exists(skin_cancer_chains, label) == True):\n",
    "        value = 1\n",
    "    test_labels.append(value)\n",
    "\n",
    "#labels_test = test_labels\n",
    "print(\"Labels: size: {}, values {}\".format(len(test_labels), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 470856,
     "status": "ok",
     "timestamp": 1587144694171,
     "user": {
      "displayName": "Clayton Cohn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiR5T0VrYZ_A0_satvSE1jZbcVxmApPyylw8Q-uxoo=s64",
      "userId": "10103672487987981310"
     },
     "user_tz": 300
    },
    "id": "VyBKS_7wYJaD",
    "outputId": "b75dab50-7fa3-41c9-90dc-8301bde40fd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 labels of type None\n"
     ]
    }
   ],
   "source": [
    "# Get rid of labels that were not in the training data\n",
    "\n",
    "labels_test = test_labels\n",
    "original_test_label_length = len(labels_test)\n",
    "\n",
    "tokenized_texts_test = [tokenized_texts_test[i] for i in range(len(tokenized_texts_test)) if labels_test[i] != None]\n",
    "labels_test = [labels_test[i] for i in range(len(labels_test)) if labels_test[i] != None]\n",
    "\n",
    "print(\"Removed {0} labels of type None\".format(original_test_label_length - len(labels_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tkK_ps6OYJd0"
   },
   "outputs": [],
   "source": [
    "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
    "input_ids_test = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts_test]\n",
    "# Pad our input tokens\n",
    "input_ids_test = pad_sequences(input_ids_test, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "# Create attention masks\n",
    "attention_masks_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XvnUu4_nYI5d"
   },
   "outputs": [],
   "source": [
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids_test:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks_test.append(seq_mask) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LZrcStjUYI29"
   },
   "outputs": [],
   "source": [
    "prediction_inputs = torch.tensor(input_ids_test)\n",
    "prediction_masks = torch.tensor(attention_masks_test)\n",
    "prediction_labels = torch.tensor(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HCKdVMkAYI0U"
   },
   "outputs": [],
   "source": [
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CS0A_XWaZdHm"
   },
   "outputs": [],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions_test, true_labels_test = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VgBPyZtDZdFU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Keith\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  b_input_ids = torch.tensor(b_input_ids).to(torch.int64) # from https://github.com/huggingface/transformers/issues/2952\n",
    "  # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n",
    "  with torch.no_grad():\n",
    "    # Forward pass, calculate logit predictions\n",
    "    logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits_test = logits.detach().cpu().numpy()\n",
    "  label_ids_test = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions_test.append(logits_test)\n",
    "  true_labels_test.append(label_ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t8fq6nxAaPr9"
   },
   "outputs": [],
   "source": [
    "# Flatten the predictions and true values\n",
    "flat_predictions_test = [item for sublist in predictions_test for item in sublist]\n",
    "flat_predictions_test = np.argmax(flat_predictions_test, axis=1).flatten()\n",
    "flat_true_labels_test = [item for sublist in true_labels_test for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nsBINcTnaPmJ"
   },
   "outputs": [],
   "source": [
    "# # At this point we must create a binary array to determine which answers were answered correctly\n",
    "# test_results_array = np.array(flat_predictions_test == flat_true_labels_test)\n",
    "# test_results_array = test_results_array.astype(int)\n",
    "# test_results_array[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fd6ezWE1L62i"
   },
   "outputs": [],
   "source": [
    "# Create the file to store the stats of the model if it doesn't already exist\n",
    "\n",
    "import os\n",
    "f = None\n",
    "if not os.path.isfile(STATS_PATH + \"/\" + STATS_FILE):\n",
    "  f = open(STATS_PATH + \"/\" + STATS_FILE, \"w\")\n",
    "  f.write(\"number,datetime,bert_model,hugging_face,max_len,epochs,batch_size,\\\n",
    "            optimizer,learning_rate,warmup,pretraining_model_id,pretraining_model_type,\\\n",
    "            cost_sensitivity,accuracy,macro_prec,macro_recall,macro_f1,macro_support,\\\n",
    "            weighted_prec,weighted_recall,weighted_f1,weighted_support,kfold,notes\\n\")\n",
    "  print(\"skin_cancer_stats.csv NOT found - creating\")\n",
    "  f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6cDn8BNf-hWn"
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# y_pred = flat_predictions_test\n",
    "# y = flat_true_labels_test\n",
    "\n",
    "# classification_dict = classification_report(y, y_pred, labels=None, target_names=None, \\\n",
    "#                       sample_weight=None, digits=2, output_dict=True, zero_division=1)\n",
    "\n",
    "# # Create arrays of precisions, recalls, f1s to recalculate average\n",
    "# precisions = []\n",
    "# recalls = []\n",
    "# f1s = []\n",
    "# supports = []\n",
    "\n",
    "# # We must alter the classification dictionary to update the f1_score and recall keys to be 1 instead of 0\n",
    "# # In this example, precision/recall/f1 scores of 0 are set to 1\n",
    "\n",
    "# classification_dict_converted = {}\n",
    "\n",
    "# for k,v in classification_dict.items():\n",
    "#   if k.isdigit():\n",
    "\n",
    "#     if float(v['recall']) == 0.0: v['recall'] = 1.0\n",
    "#     recalls.append(v['recall'])\n",
    "\n",
    "#     if float(v['f1-score']) == 0.0: v['f1-score'] = 1.0\n",
    "#     f1s.append(v['f1-score'])\n",
    "\n",
    "#     if float(v['precision']) == 0.0: v['precision'] = 1.0\n",
    "#     precisions.append(v['precision'])\n",
    "\n",
    "#     supports.append(v['support'])\n",
    "\n",
    "#     # Convert dictionary keys back to our original labels\n",
    "#     original_key = next((key for key in label_types if label_types[key] == int(k)), None)\n",
    "#     classification_dict_converted.update({ original_key : v })\n",
    "\n",
    "#     print(original_key + \" : \" + str(classification_dict_converted[original_key]))\n",
    "\n",
    "#   # Otherwise, we are at the end of the dict and edit the averages to account for the newly replaced 0s\n",
    "#   else:\n",
    "#     if k == 'macro avg':\n",
    "#       precision = sum(precisions)/len(precisions)\n",
    "#       recall = sum(recalls)/len(recalls)\n",
    "#       f1 = sum(f1s)/len(f1s)\n",
    "\n",
    "#       v['precision'] = precision\n",
    "#       v['recall'] = recall\n",
    "#       v['f1-score'] = f1\n",
    "\n",
    "#     if k == 'weighted avg':\n",
    "#       weighted_precisions = [precisions[i]*supports[i] for i in range(len(precisions))]\n",
    "#       weighted_recalls = [recalls[i]*supports[i] for i in range(len(recalls))]\n",
    "#       weighted_f1s = [f1s[i]*supports[i] for i in range(len(f1s))]\n",
    "\n",
    "#       total_supports = v['support']\n",
    "\n",
    "#       precision = sum(weighted_precisions)/total_supports\n",
    "#       recall = sum(weighted_recalls)/total_supports\n",
    "#       f1 = sum(weighted_f1s)/total_supports\n",
    "\n",
    "#       v['precision'] = precision\n",
    "#       v['recall'] = recall\n",
    "#       v['f1-score'] = f1\n",
    "\n",
    "#     classification_dict_converted.update({ k : v })\n",
    "#     print(\"\\n\" + k + \" : \" + str(classification_dict_converted[k]))\n",
    "\n",
    "# accuracy = classification_dict_converted['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 483138,
     "status": "ok",
     "timestamp": 1587144706706,
     "user": {
      "displayName": "Clayton Cohn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiR5T0VrYZ_A0_satvSE1jZbcVxmApPyylw8Q-uxoo=s64",
      "userId": "10103672487987981310"
     },
     "user_tz": 300
    },
    "id": "CMdbx8GDt4hr",
    "outputId": "e01e6832-2e2b-4ec7-e2e0-0ae2c3cf5213"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O : {'precision': 0.887223974763407, 'recall': 0.9124087591240876, 'f1-score': 0.899640143942423, 'support': 1233}\n",
      "R-1-2 : {'precision': 0.9197622585438335, 'recall': 0.8964518464880521, 'f1-score': 0.9079574624129079, 'support': 1381}\n",
      "\n",
      "accuracy : 0.9039785768936496\n",
      "\n",
      "macro avg : {'precision': 0.9034931166536202, 'recall': 0.9044303028060698, 'f1-score': 0.9037988031776654, 'support': 2614}\n",
      "\n",
      "weighted avg : {'precision': 0.9044142463398298, 'recall': 0.9039785768936496, 'f1-score': 0.9040342590180693, 'support': 2614}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = flat_predictions_test\n",
    "y = flat_true_labels_test\n",
    "\n",
    "classification_dict = classification_report(y, y_pred, labels=None, target_names=None, \\\n",
    "                      sample_weight=None, digits=2, output_dict=True, zero_division=1)\n",
    "\n",
    "# Create arrays of precisions, recalls, f1s to recalculate average\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "supports = []\n",
    "\n",
    "# We must alter the classification dictionary to update the f1_score and recall keys to be 1 instead of 0\n",
    "# In this example, precision/recall/f1 scores of 0 are ignored\n",
    "\n",
    "classification_dict_stripped = {}\n",
    "\n",
    "for k,v in classification_dict.items():\n",
    "  if k.isdigit():\n",
    "\n",
    "    if float(v['precision']) != 0.0 and float(v['recall']) != 0.0 and float(v['f1-score']) != 0.0:\n",
    "      recalls.append(v['recall'])\n",
    "      f1s.append(v['f1-score'])\n",
    "      precisions.append(v['precision'])\n",
    "      supports.append(v['support'])\n",
    "\n",
    "      # Convert dictionary keys back to our original labels\n",
    "      original_key = next((key for key in label_types if label_types[key] == int(k)), None)\n",
    "      classification_dict_stripped.update({ original_key : v })\n",
    "\n",
    "      print(original_key + \" : \" + str(classification_dict_stripped[original_key]))\n",
    "      \n",
    "  # Otherwise, we are at the end of the dict and edit the averages to account for the newly replaced 0s\n",
    "  else:\n",
    "    if k == 'macro avg':\n",
    "      precision = sum(precisions)/len(precisions)\n",
    "      recall = sum(recalls)/len(recalls)\n",
    "      f1 = sum(f1s)/len(f1s)\n",
    "\n",
    "      v['precision'] = precision\n",
    "      v['recall'] = recall\n",
    "      v['f1-score'] = f1\n",
    "\n",
    "    if k == 'weighted avg':\n",
    "      weighted_precisions = [precisions[i]*supports[i] for i in range(len(precisions))]\n",
    "      weighted_recalls = [recalls[i]*supports[i] for i in range(len(recalls))]\n",
    "      weighted_f1s = [f1s[i]*supports[i] for i in range(len(f1s))]\n",
    "\n",
    "      total_supports = sum(supports)\n",
    "\n",
    "      precision = sum(weighted_precisions)/total_supports\n",
    "      recall = sum(weighted_recalls)/total_supports\n",
    "      f1 = sum(weighted_f1s)/total_supports\n",
    "\n",
    "      v['precision'] = precision\n",
    "      v['recall'] = recall\n",
    "      v['f1-score'] = f1\n",
    "      v['support'] = total_supports\n",
    "\n",
    "    classification_dict_stripped.update({ k : v })\n",
    "\n",
    "    print(\"\\n\" + k + \" : \" + str(classification_dict_stripped[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zMMAANxB3pYQ"
   },
   "outputs": [],
   "source": [
    "ACCURACY = classification_dict_stripped['accuracy']\n",
    "\n",
    "macro = classification_dict_stripped[\"macro avg\"]\n",
    "MACRO_F1 = macro[\"f1-score\"]\n",
    "MACRO_PREC = macro[\"precision\"]\n",
    "MACRO_RECALL = macro[\"recall\"]\n",
    "MACRO_SUPPORT = macro[\"support\"]\n",
    "\n",
    "weighted = classification_dict_stripped[\"weighted avg\"]\n",
    "WEIGHTED_F1 = weighted[\"f1-score\"]\n",
    "WEIGHTED_PREC = weighted[\"precision\"]\n",
    "WEIGHTED_RECALL = weighted[\"recall\"]\n",
    "WEIGHTED_SUPPORT = weighted[\"support\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 483078,
     "status": "ok",
     "timestamp": 1587144706707,
     "user": {
      "displayName": "Clayton Cohn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiR5T0VrYZ_A0_satvSE1jZbcVxmApPyylw8Q-uxoo=s64",
      "userId": "10103672487987981310"
     },
     "user_tz": 300
    },
    "id": "-jhdyo1kAA8r",
    "outputId": "eb786c02-d23c-4bc2-d26f-a0aeed825837"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BertForSequenceClassification'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Capture HuggingFace type\n",
    "\n",
    "hf_arr = str(type(model)).split('.')\n",
    "HF_TYPE = hf_arr[2]\n",
    "HF_TYPE = ''.join(filter(str.isalnum, HF_TYPE))\n",
    "HF_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 483055,
     "status": "ok",
     "timestamp": 1587144706708,
     "user": {
      "displayName": "Clayton Cohn",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiR5T0VrYZ_A0_satvSE1jZbcVxmApPyylw8Q-uxoo=s64",
      "userId": "10103672487987981310"
     },
     "user_tz": 300
    },
    "id": "4rwyzetq_8bY",
    "outputId": "16f3d368-f543-4b97-b372-6b3aec557082"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BertAdam'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Capture optimizer type\n",
    "\n",
    "opt_arr = str(type(optimizer)).split('.')\n",
    "OPTIMIZER_TYPE = opt_arr[2]\n",
    "OPTIMIZER_TYPE = ''.join(filter(str.isalnum, OPTIMIZER_TYPE))\n",
    "OPTIMIZER_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "osyohy5pZXUh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-09 23:33 CT\n",
      "minutes 20.0: seconds 52.131073000000015\n"
     ]
    }
   ],
   "source": [
    "# Get date and time\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "date_raw = datetime.datetime.now(tz = pytz.timezone('US/Central'))\n",
    "date = str(date_raw)\n",
    "date = date.split(' ')\n",
    "time = date[1]\n",
    "date = date[0]\n",
    "h, m = [time.split(':')[0], time.split(':')[1]]\n",
    "\n",
    "DATE_TIME = date + ' ' + h + ':' + m + \" CT\"\n",
    "print(DATE_TIME)\n",
    "\n",
    "elapsedTime = date_raw - start_date_raw\n",
    "minutes, seconds = divmod(elapsedTime.total_seconds(), 60)\n",
    "print(\"minutes {}: seconds {}\".format(minutes, seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JfdYfNFkbdnD"
   },
   "outputs": [],
   "source": [
    "NUM = int(current_file_n_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZADeWA6NdWNE"
   },
   "outputs": [],
   "source": [
    "# Add line to stats, then save and close\n",
    "with open(STATS_PATH + \"/\" + STATS_FILE, \"a\") as f:\n",
    "  f.write(\"{0},{1},{2},{3},{4},{5},{6},{7},{8},\\\n",
    "  {9},{10},{11},{12},{13},{14},{15},{16},{17},\\\n",
    "  {18},{19},{20},{21},{22},{23}\\n\".format(NUM,DATE_TIME,MODEL_TYPE,HF_TYPE,MAX_LEN,EPOCHS,BATCH_SIZE,\n",
    "                                          OPTIMIZER_TYPE,LEARNING_RATE,WARMUP,PRETRAINING_MODEL_ID,PRETRAINING_MODEL_TYPE,\n",
    "                                          COST_SENSITIVITY,ACCURACY,MACRO_PREC,MACRO_RECALL,MACRO_F1,MACRO_SUPPORT,\n",
    "                                          WEIGHTED_PREC,WEIGHTED_RECALL,WEIGHTED_F1,WEIGHTED_SUPPORT,KFOLD,NOTES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN4zHUSrA3c97XwpVIADdwZ",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Fine-Tuning Skin Cancer",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
